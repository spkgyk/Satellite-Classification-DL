{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.006784,
     "end_time": "2020-12-30T10:57:09.984936",
     "exception": false,
     "start_time": "2020-12-30T10:57:09.978152",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ResNeXt-29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.005324,
     "end_time": "2020-12-30T10:57:09.997590",
     "exception": false,
     "start_time": "2020-12-30T10:57:09.992266",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Get and unzip dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-12-30T10:57:10.020640Z",
     "iopub.status.busy": "2020-12-30T10:57:10.019922Z",
     "iopub.status.idle": "2020-12-30T10:58:06.582010Z",
     "shell.execute_reply": "2020-12-30T10:58:06.581458Z"
    },
    "papermill": {
     "duration": 56.578897,
     "end_time": "2020-12-30T10:58:06.582122",
     "exception": false,
     "start_time": "2020-12-30T10:57:10.003225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyunpack\r\n",
      "  Downloading pyunpack-0.2.2-py2.py3-none-any.whl (3.8 kB)\r\n",
      "Collecting entrypoint2\r\n",
      "  Downloading entrypoint2-0.2.3-py2.py3-none-any.whl (8.7 kB)\r\n",
      "Collecting easyprocess\r\n",
      "  Downloading EasyProcess-0.3-py2.py3-none-any.whl (7.9 kB)\r\n",
      "Collecting argparse\r\n",
      "  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\r\n",
      "Installing collected packages: argparse, entrypoint2, easyprocess, pyunpack\r\n",
      "Successfully installed argparse-1.4.0 easyprocess-0.3 entrypoint2-0.2.3 pyunpack-0.2.2\r\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 20.3.3 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n",
      "Collecting patool\r\n",
      "  Downloading patool-1.12-py2.py3-none-any.whl (77 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 77 kB 357 kB/s \r\n",
      "\u001b[?25hInstalling collected packages: patool\r\n",
      "Successfully installed patool-1.12\r\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 20.3.3 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "!pip install pyunpack\n",
    "!pip install patool\n",
    "os.system('apt-get install p7zip')\n",
    "from pyunpack import Archive\n",
    "import shutil\n",
    "\n",
    "if not os.path.exists('/kaggle/working/data'):\n",
    "    os.makedirs('/kaggle/working/data')\n",
    "Archive('/kaggle/input/statoil-iceberg-classifier-challenge/test.json.7z').extractall('/kaggle/working/data/')\n",
    "Archive('/kaggle/input/statoil-iceberg-classifier-challenge/train.json.7z').extractall('/kaggle/working/data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.207528,
     "end_time": "2020-12-30T10:58:06.802071",
     "exception": false,
     "start_time": "2020-12-30T10:58:06.594543",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## ResNeXt-29 model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-30T10:58:06.936522Z",
     "iopub.status.busy": "2020-12-30T10:58:06.834755Z",
     "iopub.status.idle": "2020-12-30T10:58:20.576944Z",
     "shell.execute_reply": "2020-12-30T10:58:20.576322Z"
    },
    "papermill": {
     "duration": 13.762616,
     "end_time": "2020-12-30T10:58:20.577051",
     "exception": false,
     "start_time": "2020-12-30T10:58:06.814435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras_applications\r\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 50 kB 269 kB/s \r\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras_applications) (1.18.5)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras_applications) (2.10.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->keras_applications) (1.14.0)\r\n",
      "Installing collected packages: keras-applications\r\n",
      "Successfully installed keras-applications-1.0.8\r\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 20.3.3 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "!pip install keras_applications\n",
    "\n",
    "# from keras.models import Model\n",
    "from tensorflow.python.keras.models import Model\n",
    "from keras.layers.core import Dense, Lambda, Activation\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import GlobalAveragePooling2D, GlobalMaxPooling2D\n",
    "from keras.layers import Input, GaussianNoise\n",
    "from keras.layers.merge import concatenate, add\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.engine.topology import get_source_inputs\n",
    "from keras_applications.imagenet_utils import _obtain_input_shape\n",
    "import keras.backend as K\n",
    "\n",
    "\n",
    "def ResNext(input_shape=None, depth=29, cardinality=8, width=64, weight_decay=5e-4,\n",
    "            include_top=True, weights=None, input_tensor=None,\n",
    "            pooling=None, classes=10):\n",
    "\n",
    "    if type(depth) == int:\n",
    "        if (depth - 2) % 9 != 0:\n",
    "            raise ValueError('Depth of the network must be such that (depth - 2)'\n",
    "                             'should be divisible by 9.')\n",
    "\n",
    "    # Determine proper input shape\n",
    "    input_shape = _obtain_input_shape(input_shape,\n",
    "                                      default_size=32,\n",
    "                                      min_size=8,\n",
    "                                      data_format=K.image_data_format(),\n",
    "                                      require_flatten=include_top)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    x = __create_res_next(classes, img_input, include_top, depth, cardinality, width,\n",
    "                          weight_decay, pooling)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='resnext')\n",
    "\n",
    "    # load weights\n",
    "    if weights:\n",
    "        model.load_weights(weights)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def __initial_conv_block(input, weight_decay=5e-4):\n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "\n",
    "    x = Conv2D(32, (3, 3), padding='same', use_bias=True, kernel_initializer='he_normal',\n",
    "               kernel_regularizer=l2(weight_decay))(input)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = Activation('elu')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def __grouped_convolution_block(input, grouped_channels, cardinality, strides, weight_decay=5e-4):\n",
    "    init = input\n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "\n",
    "    group_list = []\n",
    "\n",
    "    if cardinality == 1:\n",
    "        # with cardinality 1, it is a standard convolution\n",
    "        x = Conv2D(grouped_channels, (3, 3), padding='same', use_bias=True, strides=(strides, strides),\n",
    "                   kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay))(init)\n",
    "        x = BatchNormalization(axis=channel_axis)(x)\n",
    "        x = Activation('elu')(x)\n",
    "        return x\n",
    "\n",
    "    for c in range(cardinality):\n",
    "        x = Lambda(lambda z: z[:, :, :, c * grouped_channels:(c + 1) * grouped_channels]\n",
    "        if K.image_data_format() == 'channels_last' else\n",
    "        lambda z: z[:, c * grouped_channels:(c + 1) * grouped_channels, :, :])(input)\n",
    "\n",
    "        x = Conv2D(grouped_channels, (3, 3), padding='same', use_bias=True, strides=(strides, strides),\n",
    "                   kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay))(x)\n",
    "\n",
    "        group_list.append(x)\n",
    "\n",
    "    group_merge = concatenate(group_list, axis=channel_axis)\n",
    "    x = BatchNormalization(axis=channel_axis)(group_merge)\n",
    "    x = Activation('elu')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def __bottleneck_block(input, filters=64, cardinality=8, strides=1, weight_decay=5e-4):\n",
    "    init = input\n",
    "\n",
    "    grouped_channels = int(filters / cardinality)\n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "\n",
    "    # Check if input number of filters is same as 16 * k, else create convolution2d for this input\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        if init.shape[1] != 2 * filters:\n",
    "            init = Conv2D(filters * 2, (1, 1), padding='same', strides=(strides, strides),\n",
    "                          use_bias=True, kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay))(init)\n",
    "            init = BatchNormalization(axis=channel_axis)(init)\n",
    "    else:\n",
    "        if init.shape[-1] != 2 * filters:\n",
    "            init = Conv2D(filters * 2, (1, 1), padding='same', strides=(strides, strides),\n",
    "                          use_bias=True, kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay))(init)\n",
    "            init = BatchNormalization(axis=channel_axis)(init)\n",
    "\n",
    "    x = Conv2D(filters, (1, 1), padding='same', use_bias=False,\n",
    "               kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay))(input)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = Activation('elu')(x)\n",
    "\n",
    "    x = __grouped_convolution_block(x, grouped_channels, cardinality, strides, weight_decay)\n",
    "\n",
    "    x = Conv2D(filters * 2, (1, 1), padding='same', use_bias=True, kernel_initializer='he_normal',\n",
    "               kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "\n",
    "    x = add([init, x])\n",
    "    x = Activation('elu')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def __create_res_next(nb_classes, img_input, include_top, depth=29, cardinality=8, width=4,\n",
    "                      weight_decay=5e-4, pooling=None):\n",
    "    if type(depth) is list or type(depth) is tuple:\n",
    "        # If a list is provided, defer to user how many blocks are present\n",
    "        N = list(depth)\n",
    "    else:\n",
    "        # Otherwise, default to 3 blocks each of default number of group convolution blocks\n",
    "        N = [(depth - 2) // 9 for _ in range(3)]\n",
    "\n",
    "    filters = cardinality * width\n",
    "    filters_list = []\n",
    "\n",
    "    for i in range(len(N)):\n",
    "        filters_list.append(filters)\n",
    "        filters *= 2  # double the size of the filters\n",
    "\n",
    "    x = Lambda(lambda x: x[:, :, :, 0:2]\n",
    "                         if K.image_data_format() == 'channels_last'\n",
    "                         else x[:, 0:2, :, :])(img_input)\n",
    "\n",
    "    angle = Lambda(lambda x: x[:, :, :, 2:]\n",
    "                             if K.image_data_format() == 'channels_last'\n",
    "                             else x[:, 2:, :, :])(img_input)\n",
    "\n",
    "    x_noise = GaussianNoise(5e-2)(x)\n",
    "    angle_noise = GaussianNoise(5e-3)(angle)\n",
    "\n",
    "    noise_input = concatenate([x_noise, angle_noise], axis=-1)\n",
    "\n",
    "    x = __initial_conv_block(noise_input, weight_decay)\n",
    "\n",
    "    # block 1 (no pooling)\n",
    "    for i in range(N[0]):\n",
    "        x = __bottleneck_block(x, filters_list[0], cardinality, strides=1, weight_decay=weight_decay)\n",
    "\n",
    "    N = N[1:]  # remove the first block from block definition list\n",
    "    filters_list = filters_list[1:]  # remove the first filter from the filter list\n",
    "\n",
    "    # block 2 to N\n",
    "    for block_idx, n_i in enumerate(N):\n",
    "        for i in range(n_i):\n",
    "            if i == 0:\n",
    "                x = __bottleneck_block(x, filters_list[block_idx], cardinality, strides=2,\n",
    "                                       weight_decay=weight_decay)\n",
    "            else:\n",
    "                x = __bottleneck_block(x, filters_list[block_idx], cardinality, strides=1,\n",
    "                                       weight_decay=weight_decay)\n",
    "\n",
    "    if include_top:\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(nb_classes, use_bias=True, kernel_regularizer=l2(weight_decay),\n",
    "                  kernel_initializer='he_normal', activation='softmax')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = GlobalMaxPooling2D()(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014051,
     "end_time": "2020-12-30T10:58:20.605265",
     "exception": false,
     "start_time": "2020-12-30T10:58:20.591214",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Utils\n",
    "There are a few functions here.\n",
    "1. load_data - Read json data file into pandas dataframe.\n",
    "2. preprocess - Convert band_1, band_2 and inc_angle data into 75x75 array\n",
    "3. prepare_data_cv - Split data for cross-validation\n",
    "4. prepare_data_full - Preprocess data and label\n",
    "5. logloss_softmax - \n",
    "6. get_model_callbacks - perform early stopping and reduce learning rate when a metric has stopped improving.\n",
    "7. load_model - load training model\n",
    "8. get_resnext - configure ResNeXt model\n",
    "9. prepare_submission - create csv submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-12-30T10:58:20.672745Z",
     "iopub.status.busy": "2020-12-30T10:58:20.666198Z",
     "iopub.status.idle": "2020-12-30T10:58:21.268206Z",
     "shell.execute_reply": "2020-12-30T10:58:21.268633Z"
    },
    "papermill": {
     "duration": 0.650084,
     "end_time": "2020-12-30T10:58:21.268849",
     "exception": false,
     "start_time": "2020-12-30T10:58:20.618765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def load_data(path):\n",
    "    train = pd.read_json(os.path.join(path, \"train.json\"))\n",
    "    test = pd.read_json(os.path.join(path, \"test.json\"))\n",
    "    return (train, test)\n",
    "\n",
    "\n",
    "def preprocess(df, \n",
    "               means=(-22.159262, -24.953745, 40.021883465782651),\n",
    "               stds=(5.33146, 4.5463958, 4.0815391476694414)):\n",
    "    X_band_1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) \n",
    "                         for band in df[\"band_1\"]])\n",
    "    X_band_2 = np.array([np.array(band).astype(np.float32).reshape(75, 75)\n",
    "                         for band in df[\"band_2\"]])\n",
    "\n",
    "    angl = df['inc_angle'].map(lambda x: np.cos(x * np.pi / 180) if x != 'na' else means[2])\n",
    "    angl = np.array([np.full(shape=(75, 75), fill_value=angel).astype(np.float32)\n",
    "                     for angel in angl])\n",
    "\n",
    "    X_band_1 = (X_band_1 - means[0]) / stds[0]\n",
    "    X_band_2 = (X_band_2 - means[1]) / stds[1]\n",
    "    angl = (angl - means[2]) / stds[2]\n",
    "\n",
    "    images = np.concatenate([X_band_1[:, :, :, np.newaxis],\n",
    "                             X_band_2[:, :, :, np.newaxis],\n",
    "                             angl[:, :, :, np.newaxis]],\n",
    "                            axis=-1)\n",
    "    return images\n",
    "\n",
    "def prepare_data_cv(path):\n",
    "    train, test = load_data(path)\n",
    "    X_train, y_train = (preprocess(train),\n",
    "                        to_categorical(train['is_iceberg'].to_numpy().reshape(-1, 1)))\n",
    "\n",
    "    kfold_data = []\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=0xCAFFE)\n",
    "\n",
    "    for train_indices, val_indices in kf.split(y_train):\n",
    "        print(train_indices)\n",
    "        X_train_cv = X_train[train_indices]\n",
    "        y_train_cv = y_train[train_indices]\n",
    "\n",
    "        X_val = X_train[val_indices]\n",
    "        y_val = y_train[val_indices]\n",
    "\n",
    "        kfold_data.append((X_train_cv, y_train_cv, X_val, y_val))\n",
    "\n",
    "    X_test = preprocess(test)\n",
    "\n",
    "    return (kfold_data, X_test)\n",
    "\n",
    "def prepare_data_full(path):\n",
    "    train, test = load_data(path)\n",
    "    return (preprocess(train), to_categorical(train['is_iceberg'].to_numpy().reshape(-1, 1)))\n",
    "\n",
    "def logloss_softmax(y_true, y_pred, eps=1e-15):\n",
    "    proba = y_pred[np.arange(len(y_pred)), np.argmax(y_true, axis=1)]\n",
    "    proba = np.clip(proba, eps, 1 - eps)\n",
    "    return -np.mean(np.log(proba))\n",
    "\n",
    "\n",
    "def get_model_callbacks(save_dir):\n",
    "    stopping = EarlyStopping(monitor='val_loss',\n",
    "                             min_delta=1e-3,\n",
    "                             patience=45,\n",
    "                             verbose=False,\n",
    "                             mode='min')\n",
    "\n",
    "    board_path = os.path.join(save_dir, 'board')\n",
    "    if not os.path.exists(board_path):\n",
    "        os.makedirs(board_path)\n",
    "\n",
    "    board = TensorBoard(log_dir=board_path)\n",
    "\n",
    "    lr_scheduler = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                    factor=0.3,\n",
    "                                    patience=15,\n",
    "                                    verbose=True,\n",
    "                                    mode='min',\n",
    "                                    epsilon=5e-3,\n",
    "                                    min_lr=1e-5)\n",
    "\n",
    "    model_path = os.path.join(save_dir, 'model/model_weights.hdf5')\n",
    "    if not os.path.exists(os.path.dirname(model_path)):\n",
    "        os.makedirs(os.path.dirname(model_path))\n",
    "\n",
    "    model_checkpoint = ModelCheckpoint(model_path,\n",
    "                                       monitor='val_loss',\n",
    "                                       verbose=False,\n",
    "                                       save_best_only=True,\n",
    "                                       save_weights_only=False,\n",
    "                                       mode='min',\n",
    "                                       period=1)\n",
    "\n",
    "    callbacks = [stopping, board, lr_scheduler, model_checkpoint]\n",
    "    return callbacks\n",
    "\n",
    "\n",
    "def load_model(model_loader_fn, weights=None):\n",
    "    from keras.optimizers import RMSprop, Adam\n",
    "    \n",
    "    ## load model using function name\n",
    "    model = model_loader_fn()\n",
    "\n",
    "    if weights:\n",
    "        model.load_weights(weights)\n",
    "\n",
    "    # optimizer\n",
    "    opt = RMSprop(lr=1e-3)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_resnext():\n",
    "\n",
    "    model = ResNext(\n",
    "        input_shape=(75, 75, 3),\n",
    "        depth=29,\n",
    "        cardinality=4,\n",
    "        width=8,\n",
    "        weight_decay=0.,\n",
    "        include_top=True,\n",
    "        weights=None,\n",
    "        classes=2)\n",
    "\n",
    "    return model\n",
    "\n",
    "def prepare_submission(models_proba, path, high_thr=0.9, low_thr=0.1):\n",
    "    _, test = load_data('./data/data/processed')\n",
    "    models_proba = np.array(models_proba)\n",
    "    proba = np.where(np.all(models_proba > high_thr, axis=0),\n",
    "                     np.max(models_proba, axis=0),\n",
    "                     np.where(np.all(models_proba < low_thr, axis=0),\n",
    "                              np.min(models_proba, axis=0),\n",
    "                              np.median(models_proba, axis=0))\n",
    "                     )\n",
    "\n",
    "    submission = pd.DataFrame()\n",
    "    submission['id'] = test['id']\n",
    "    submission['is_iceberg'] = proba.reshape((proba.shape[0]))\n",
    "    submission.to_csv(path, index=False)\n",
    "    \n",
    "## data augmentation\n",
    "def get_data_generator(X, y, batch_size=32):\n",
    "    img_gen = ImageDataGenerator(\n",
    "        rotation_range=0.,\n",
    "        width_shift_range=0.5,\n",
    "        height_shift_range=0.5,\n",
    "        shear_range=0.,\n",
    "        zoom_range=0.,\n",
    "        fill_mode='wrap',\n",
    "        horizontal_flip=False,\n",
    "        vertical_flip=True,\n",
    "        data_format='channels_last')\n",
    "\n",
    "    img_gen.fit(X)\n",
    "\n",
    "    return img_gen.flow(X, y, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013745,
     "end_time": "2020-12-30T10:58:21.296658",
     "exception": false,
     "start_time": "2020-12-30T10:58:21.282913",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-30T10:58:21.349196Z",
     "iopub.status.busy": "2020-12-30T10:58:21.342999Z",
     "iopub.status.idle": "2020-12-30T11:43:50.147689Z",
     "shell.execute_reply": "2020-12-30T11:43:50.146454Z"
    },
    "papermill": {
     "duration": 2728.837758,
     "end_time": "2020-12-30T11:43:50.148522",
     "exception": false,
     "start_time": "2020-12-30T10:58:21.310764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    1    3 ... 1600 1601 1602]\n",
      "[   0    1    2 ... 1601 1602 1603]\n",
      "[   1    2    3 ... 1601 1602 1603]\n",
      "[   0    1    2 ... 1597 1600 1603]\n",
      "[   0    2    3 ... 1601 1602 1603]\n",
      "Model: \"resnext\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 75, 75, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 75, 75, 2)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 75, 75, 1)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 75, 75, 2)    0           lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_1 (GaussianNoise (None, 75, 75, 1)    0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 75, 75, 3)    0           gaussian_noise[0][0]             \n",
      "                                                                 gaussian_noise_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 75, 75, 32)   896         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 75, 75, 32)   128         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 75, 75, 32)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 75, 75, 32)   1024        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 75, 75, 32)   128         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 75, 75, 32)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 75, 75, 8)    0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 75, 75, 8)    0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 75, 75, 8)    0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 75, 75, 8)    0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 75, 75, 8)    584         lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 75, 75, 8)    584         lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 75, 75, 8)    584         lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 75, 75, 8)    584         lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 75, 75, 32)   0           conv2d_3[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 75, 75, 32)   128         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 75, 75, 32)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 75, 75, 64)   2112        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 75, 75, 64)   2112        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 75, 75, 64)   256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 75, 75, 64)   256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 75, 75, 64)   0           batch_normalization_1[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 75, 75, 64)   0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 75, 75, 32)   2048        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 75, 75, 32)   128         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 75, 75, 32)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 75, 75, 8)    0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 75, 75, 8)    0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 75, 75, 8)    0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 75, 75, 8)    0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 75, 75, 8)    584         lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 75, 75, 8)    584         lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 75, 75, 8)    584         lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 75, 75, 8)    584         lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 75, 75, 32)   0           conv2d_9[0][0]                   \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "                                                                 conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 75, 75, 32)   128         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 75, 75, 32)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 75, 75, 64)   2112        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 75, 75, 64)   256         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 75, 75, 64)   0           activation_3[0][0]               \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 75, 75, 64)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 75, 75, 32)   2048        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 75, 75, 32)   128         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 75, 75, 32)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 75, 75, 8)    0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 75, 75, 8)    0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 75, 75, 8)    0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 75, 75, 8)    0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 75, 75, 8)    584         lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 75, 75, 8)    584         lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 75, 75, 8)    584         lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 75, 75, 8)    584         lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 75, 75, 32)   0           conv2d_15[0][0]                  \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 75, 75, 32)   128         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 75, 75, 32)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 75, 75, 64)   2112        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 75, 75, 64)   256         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 75, 75, 64)   0           activation_6[0][0]               \n",
      "                                                                 batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 75, 75, 64)   0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 75, 75, 64)   4096        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 75, 75, 64)   256         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 75, 75, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 75, 75, 16)   0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 75, 75, 16)   0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 75, 75, 16)   0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 75, 75, 16)   0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 38, 38, 16)   2320        lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 38, 38, 16)   2320        lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 38, 38, 16)   2320        lambda_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 38, 38, 16)   2320        lambda_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 38, 38, 64)   0           conv2d_22[0][0]                  \n",
      "                                                                 conv2d_23[0][0]                  \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "                                                                 conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 38, 38, 64)   256         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 38, 38, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 38, 38, 128)  8320        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 38, 38, 128)  8320        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 38, 38, 128)  512         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 38, 38, 128)  512         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 38, 38, 128)  0           batch_normalization_11[0][0]     \n",
      "                                                                 batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 38, 38, 128)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 38, 38, 64)   8192        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 38, 38, 64)   256         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 38, 38, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 38, 38, 16)   0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 38, 38, 16)   0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (None, 38, 38, 16)   0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 38, 38, 16)   0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 38, 38, 16)   2320        lambda_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 38, 38, 16)   2320        lambda_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 38, 38, 16)   2320        lambda_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 38, 38, 16)   2320        lambda_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 38, 38, 64)   0           conv2d_28[0][0]                  \n",
      "                                                                 conv2d_29[0][0]                  \n",
      "                                                                 conv2d_30[0][0]                  \n",
      "                                                                 conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 38, 38, 64)   256         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 38, 38, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 38, 38, 128)  8320        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 38, 38, 128)  512         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 38, 38, 128)  0           activation_12[0][0]              \n",
      "                                                                 batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 38, 38, 128)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 38, 38, 64)   8192        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 38, 38, 64)   256         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 38, 38, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 38, 38, 16)   0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 38, 38, 16)   0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)              (None, 38, 38, 16)   0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_25 (Lambda)              (None, 38, 38, 16)   0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 38, 38, 16)   2320        lambda_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 38, 38, 16)   2320        lambda_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 38, 38, 16)   2320        lambda_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 38, 38, 16)   2320        lambda_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 38, 38, 64)   0           conv2d_34[0][0]                  \n",
      "                                                                 conv2d_35[0][0]                  \n",
      "                                                                 conv2d_36[0][0]                  \n",
      "                                                                 conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 38, 38, 64)   256         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 38, 38, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 38, 38, 128)  8320        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 38, 38, 128)  512         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 38, 38, 128)  0           activation_15[0][0]              \n",
      "                                                                 batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 38, 38, 128)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 38, 38, 128)  16384       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 38, 38, 128)  512         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 38, 38, 128)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_26 (Lambda)              (None, 38, 38, 32)   0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_27 (Lambda)              (None, 38, 38, 32)   0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_28 (Lambda)              (None, 38, 38, 32)   0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_29 (Lambda)              (None, 38, 38, 32)   0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 19, 19, 32)   9248        lambda_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 19, 19, 32)   9248        lambda_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 19, 19, 32)   9248        lambda_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 19, 19, 32)   9248        lambda_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 19, 19, 128)  0           conv2d_41[0][0]                  \n",
      "                                                                 conv2d_42[0][0]                  \n",
      "                                                                 conv2d_43[0][0]                  \n",
      "                                                                 conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 19, 19, 128)  512         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 19, 19, 128)  0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 19, 19, 256)  33024       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 19, 19, 256)  33024       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 19, 19, 256)  1024        conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 19, 19, 256)  1024        conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 19, 19, 256)  0           batch_normalization_21[0][0]     \n",
      "                                                                 batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 19, 19, 256)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 19, 19, 128)  32768       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 19, 19, 128)  512         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 19, 19, 128)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_30 (Lambda)              (None, 19, 19, 32)   0           activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_31 (Lambda)              (None, 19, 19, 32)   0           activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_32 (Lambda)              (None, 19, 19, 32)   0           activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_33 (Lambda)              (None, 19, 19, 32)   0           activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 19, 19, 32)   9248        lambda_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 19, 19, 32)   9248        lambda_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 19, 19, 32)   9248        lambda_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 19, 19, 32)   9248        lambda_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 19, 19, 128)  0           conv2d_47[0][0]                  \n",
      "                                                                 conv2d_48[0][0]                  \n",
      "                                                                 conv2d_49[0][0]                  \n",
      "                                                                 conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 19, 19, 128)  512         concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 19, 19, 128)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 19, 19, 256)  33024       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 19, 19, 256)  1024        conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 19, 19, 256)  0           activation_21[0][0]              \n",
      "                                                                 batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 19, 19, 256)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 19, 19, 128)  32768       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 19, 19, 128)  512         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 19, 19, 128)  0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_34 (Lambda)              (None, 19, 19, 32)   0           activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_35 (Lambda)              (None, 19, 19, 32)   0           activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_36 (Lambda)              (None, 19, 19, 32)   0           activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_37 (Lambda)              (None, 19, 19, 32)   0           activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 19, 19, 32)   9248        lambda_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 19, 19, 32)   9248        lambda_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 19, 19, 32)   9248        lambda_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 19, 19, 32)   9248        lambda_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 19, 19, 128)  0           conv2d_53[0][0]                  \n",
      "                                                                 conv2d_54[0][0]                  \n",
      "                                                                 conv2d_55[0][0]                  \n",
      "                                                                 conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 19, 19, 128)  512         concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 19, 19, 128)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 19, 19, 256)  33024       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 19, 19, 256)  1024        conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 19, 19, 256)  0           activation_24[0][0]              \n",
      "                                                                 batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 19, 19, 256)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 256)          0           activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2)            514         global_average_pooling2d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 441,250\n",
      "Trainable params: 434,914\n",
      "Non-trainable params: 6,336\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/1000\n",
      "10/10 [==============================] - 5s 545ms/step - loss: 0.9999 - accuracy: 0.5671 - val_loss: 7.5013 - val_accuracy: 0.5109\n",
      "Epoch 2/1000\n",
      "10/10 [==============================] - 4s 370ms/step - loss: 0.6739 - accuracy: 0.6173 - val_loss: 7.5013 - val_accuracy: 0.5109\n",
      "Epoch 3/1000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6996 - accuracy: 0.6251 - val_loss: 7.5013 - val_accuracy: 0.5109\n",
      "Epoch 4/1000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.7026 - accuracy: 0.6329 - val_loss: 7.5013 - val_accuracy: 0.5109\n",
      "Epoch 5/1000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.5969 - accuracy: 0.6701 - val_loss: 7.5013 - val_accuracy: 0.5109\n",
      "Epoch 6/1000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.5441 - accuracy: 0.7004 - val_loss: 7.5013 - val_accuracy: 0.5109\n",
      "Epoch 7/1000\n",
      "10/10 [==============================] - 3s 283ms/step - loss: 0.6603 - accuracy: 0.6416 - val_loss: 7.5013 - val_accuracy: 0.5109\n",
      "Epoch 8/1000\n",
      "10/10 [==============================] - 3s 293ms/step - loss: 0.5843 - accuracy: 0.6606 - val_loss: 7.5013 - val_accuracy: 0.5109\n",
      "Epoch 9/1000\n",
      "10/10 [==============================] - 3s 291ms/step - loss: 0.5205 - accuracy: 0.7074 - val_loss: 7.5013 - val_accuracy: 0.5109\n",
      "Epoch 10/1000\n",
      "10/10 [==============================] - 3s 293ms/step - loss: 0.4980 - accuracy: 0.7398 - val_loss: 7.5013 - val_accuracy: 0.5109\n",
      "Epoch 11/1000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.4659 - accuracy: 0.7593 - val_loss: 7.5013 - val_accuracy: 0.5109\n",
      "Epoch 12/1000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.4777 - accuracy: 0.7636 - val_loss: 7.5013 - val_accuracy: 0.5109\n",
      "Epoch 13/1000\n",
      "10/10 [==============================] - 3s 281ms/step - loss: 0.4802 - accuracy: 0.7801 - val_loss: 7.5013 - val_accuracy: 0.5109\n",
      "Epoch 14/1000\n",
      "10/10 [==============================] - 3s 337ms/step - loss: 0.4026 - accuracy: 0.8242 - val_loss: 7.1384 - val_accuracy: 0.5140\n",
      "Epoch 15/1000\n",
      "10/10 [==============================] - 3s 346ms/step - loss: 0.4407 - accuracy: 0.7896 - val_loss: 6.6223 - val_accuracy: 0.5171\n",
      "Epoch 16/1000\n",
      "10/10 [==============================] - 3s 313ms/step - loss: 0.4289 - accuracy: 0.8043 - val_loss: 7.2599 - val_accuracy: 0.5234\n",
      "Epoch 17/1000\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 0.4503 - accuracy: 0.7905 - val_loss: 5.1589 - val_accuracy: 0.5545\n",
      "Epoch 18/1000\n",
      "10/10 [==============================] - 3s 331ms/step - loss: 0.4281 - accuracy: 0.8095 - val_loss: 4.9518 - val_accuracy: 0.5763\n",
      "Epoch 19/1000\n",
      "10/10 [==============================] - 3s 318ms/step - loss: 0.4011 - accuracy: 0.8113 - val_loss: 3.3124 - val_accuracy: 0.6854\n",
      "Epoch 20/1000\n",
      "10/10 [==============================] - 3s 298ms/step - loss: 0.3909 - accuracy: 0.8199 - val_loss: 7.0232 - val_accuracy: 0.5202\n",
      "Epoch 21/1000\n",
      "10/10 [==============================] - 3s 278ms/step - loss: 0.4128 - accuracy: 0.8190 - val_loss: 5.9087 - val_accuracy: 0.5919\n",
      "Epoch 22/1000\n",
      "10/10 [==============================] - 3s 280ms/step - loss: 0.3328 - accuracy: 0.8476 - val_loss: 6.3613 - val_accuracy: 0.5607\n",
      "Epoch 23/1000\n",
      "10/10 [==============================] - 3s 292ms/step - loss: 0.3638 - accuracy: 0.8406 - val_loss: 4.4428 - val_accuracy: 0.6885\n",
      "Epoch 24/1000\n",
      "10/10 [==============================] - 3s 280ms/step - loss: 0.3353 - accuracy: 0.8407 - val_loss: 4.6906 - val_accuracy: 0.6417\n",
      "Epoch 25/1000\n",
      "10/10 [==============================] - 3s 347ms/step - loss: 0.3361 - accuracy: 0.8511 - val_loss: 1.0394 - val_accuracy: 0.8037\n",
      "Epoch 26/1000\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.3262 - accuracy: 0.8476 - val_loss: 1.3682 - val_accuracy: 0.8131\n",
      "Epoch 27/1000\n",
      "10/10 [==============================] - 3s 291ms/step - loss: 0.3237 - accuracy: 0.8570 - val_loss: 1.9530 - val_accuracy: 0.7165\n",
      "Epoch 28/1000\n",
      "10/10 [==============================] - 3s 266ms/step - loss: 0.2872 - accuracy: 0.8753 - val_loss: 6.2017 - val_accuracy: 0.5514\n",
      "Epoch 29/1000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.3054 - accuracy: 0.8648 - val_loss: 3.2352 - val_accuracy: 0.6947\n",
      "Epoch 30/1000\n",
      "10/10 [==============================] - 3s 301ms/step - loss: 0.3202 - accuracy: 0.8589 - val_loss: 2.7540 - val_accuracy: 0.7539\n",
      "Epoch 31/1000\n",
      "10/10 [==============================] - 3s 292ms/step - loss: 0.2879 - accuracy: 0.8766 - val_loss: 1.0449 - val_accuracy: 0.7508\n",
      "Epoch 32/1000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.2932 - accuracy: 0.8684 - val_loss: 1.3483 - val_accuracy: 0.8037\n",
      "Epoch 33/1000\n",
      "10/10 [==============================] - 3s 339ms/step - loss: 0.2923 - accuracy: 0.8745 - val_loss: 4.0535 - val_accuracy: 0.6822\n",
      "Epoch 34/1000\n",
      "10/10 [==============================] - 4s 358ms/step - loss: 0.2958 - accuracy: 0.8753 - val_loss: 3.0852 - val_accuracy: 0.7009\n",
      "Epoch 35/1000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.2797 - accuracy: 0.8805 - val_loss: 1.2572 - val_accuracy: 0.8193\n",
      "Epoch 36/1000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.3064 - accuracy: 0.8701 - val_loss: 1.4677 - val_accuracy: 0.7290\n",
      "Epoch 37/1000\n",
      "10/10 [==============================] - 3s 282ms/step - loss: 0.3447 - accuracy: 0.8597 - val_loss: 2.3816 - val_accuracy: 0.7009\n",
      "Epoch 38/1000\n",
      "10/10 [==============================] - 3s 267ms/step - loss: 0.2534 - accuracy: 0.8892 - val_loss: 6.2911 - val_accuracy: 0.4984\n",
      "Epoch 39/1000\n",
      "10/10 [==============================] - 3s 300ms/step - loss: 0.3505 - accuracy: 0.8494 - val_loss: 1.9482 - val_accuracy: 0.7477\n",
      "Epoch 40/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2471 - accuracy: 0.8969\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.2471 - accuracy: 0.8969 - val_loss: 1.2413 - val_accuracy: 0.7850\n",
      "Epoch 41/1000\n",
      "10/10 [==============================] - 3s 280ms/step - loss: 0.2303 - accuracy: 0.8970 - val_loss: 1.2016 - val_accuracy: 0.7819\n",
      "Epoch 42/1000\n",
      "10/10 [==============================] - 3s 346ms/step - loss: 0.2306 - accuracy: 0.9086 - val_loss: 0.7293 - val_accuracy: 0.8100\n",
      "Epoch 43/1000\n",
      "10/10 [==============================] - 3s 297ms/step - loss: 0.2245 - accuracy: 0.9108 - val_loss: 0.9518 - val_accuracy: 0.8287\n",
      "Epoch 44/1000\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.2526 - accuracy: 0.9030 - val_loss: 0.3360 - val_accuracy: 0.8536\n",
      "Epoch 45/1000\n",
      "10/10 [==============================] - 4s 357ms/step - loss: 0.2366 - accuracy: 0.9039 - val_loss: 0.2330 - val_accuracy: 0.8847\n",
      "Epoch 46/1000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.2304 - accuracy: 0.9065 - val_loss: 0.2143 - val_accuracy: 0.8941\n",
      "Epoch 47/1000\n",
      "10/10 [==============================] - 3s 279ms/step - loss: 0.2271 - accuracy: 0.9048 - val_loss: 0.2268 - val_accuracy: 0.8910\n",
      "Epoch 48/1000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.2283 - accuracy: 0.9082 - val_loss: 0.2889 - val_accuracy: 0.8785\n",
      "Epoch 49/1000\n",
      "10/10 [==============================] - 4s 367ms/step - loss: 0.2276 - accuracy: 0.9091 - val_loss: 0.1931 - val_accuracy: 0.9065\n",
      "Epoch 50/1000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.2288 - accuracy: 0.8996 - val_loss: 0.2062 - val_accuracy: 0.8972\n",
      "Epoch 51/1000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.2276 - accuracy: 0.9013 - val_loss: 0.1989 - val_accuracy: 0.9065\n",
      "Epoch 52/1000\n",
      "10/10 [==============================] - 4s 351ms/step - loss: 0.2243 - accuracy: 0.9100 - val_loss: 0.1999 - val_accuracy: 0.9097\n",
      "Epoch 53/1000\n",
      "10/10 [==============================] - 3s 346ms/step - loss: 0.2257 - accuracy: 0.9091 - val_loss: 0.2028 - val_accuracy: 0.9065\n",
      "Epoch 54/1000\n",
      "10/10 [==============================] - 3s 277ms/step - loss: 0.2353 - accuracy: 0.8996 - val_loss: 0.2059 - val_accuracy: 0.9065\n",
      "Epoch 55/1000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.2137 - accuracy: 0.9074 - val_loss: 0.2121 - val_accuracy: 0.8972\n",
      "Epoch 56/1000\n",
      "10/10 [==============================] - 3s 267ms/step - loss: 0.2260 - accuracy: 0.9082 - val_loss: 0.9738 - val_accuracy: 0.6573\n",
      "Epoch 57/1000\n",
      "10/10 [==============================] - 3s 278ms/step - loss: 0.2186 - accuracy: 0.9117 - val_loss: 0.3339 - val_accuracy: 0.8536\n",
      "Epoch 58/1000\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 0.2273 - accuracy: 0.9030 - val_loss: 0.2442 - val_accuracy: 0.8941\n",
      "Epoch 59/1000\n",
      "10/10 [==============================] - 3s 278ms/step - loss: 0.2332 - accuracy: 0.8987 - val_loss: 0.2171 - val_accuracy: 0.8972\n",
      "Epoch 60/1000\n",
      "10/10 [==============================] - 3s 317ms/step - loss: 0.2184 - accuracy: 0.9143 - val_loss: 0.1924 - val_accuracy: 0.9190\n",
      "Epoch 61/1000\n",
      "10/10 [==============================] - 3s 313ms/step - loss: 0.2216 - accuracy: 0.9091 - val_loss: 0.2003 - val_accuracy: 0.9128\n",
      "Epoch 62/1000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.2308 - accuracy: 0.8978 - val_loss: 0.2697 - val_accuracy: 0.8879\n",
      "Epoch 63/1000\n",
      "10/10 [==============================] - 3s 292ms/step - loss: 0.2097 - accuracy: 0.9164 - val_loss: 0.1978 - val_accuracy: 0.9065\n",
      "Epoch 64/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2137 - accuracy: 0.9134\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.2137 - accuracy: 0.9134 - val_loss: 0.1964 - val_accuracy: 0.9128\n",
      "Epoch 65/1000\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.2023 - accuracy: 0.9195 - val_loss: 0.1893 - val_accuracy: 0.9190\n",
      "Epoch 66/1000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.1987 - accuracy: 0.9221 - val_loss: 0.1895 - val_accuracy: 0.9190\n",
      "Epoch 67/1000\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 0.2061 - accuracy: 0.9160 - val_loss: 0.1896 - val_accuracy: 0.9221\n",
      "Epoch 68/1000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.1982 - accuracy: 0.9221 - val_loss: 0.1910 - val_accuracy: 0.9128\n",
      "Epoch 69/1000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.2128 - accuracy: 0.9126 - val_loss: 0.1899 - val_accuracy: 0.9159\n",
      "Epoch 70/1000\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 0.2144 - accuracy: 0.9203 - val_loss: 0.1863 - val_accuracy: 0.9377\n",
      "Epoch 71/1000\n",
      "10/10 [==============================] - 3s 283ms/step - loss: 0.2129 - accuracy: 0.9134 - val_loss: 0.1904 - val_accuracy: 0.9377\n",
      "Epoch 72/1000\n",
      "10/10 [==============================] - 3s 301ms/step - loss: 0.2051 - accuracy: 0.9195 - val_loss: 0.1886 - val_accuracy: 0.9221\n",
      "Epoch 73/1000\n",
      "10/10 [==============================] - 3s 283ms/step - loss: 0.2009 - accuracy: 0.9264 - val_loss: 0.1868 - val_accuracy: 0.9283\n",
      "Epoch 74/1000\n",
      "10/10 [==============================] - 3s 338ms/step - loss: 0.2009 - accuracy: 0.9203 - val_loss: 0.1860 - val_accuracy: 0.9190\n",
      "Epoch 75/1000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.2081 - accuracy: 0.9177 - val_loss: 0.1895 - val_accuracy: 0.9097\n",
      "Epoch 76/1000\n",
      "10/10 [==============================] - 3s 281ms/step - loss: 0.1855 - accuracy: 0.9325 - val_loss: 0.1896 - val_accuracy: 0.9097\n",
      "Epoch 77/1000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.2019 - accuracy: 0.9143 - val_loss: 0.1884 - val_accuracy: 0.9128\n",
      "Epoch 78/1000\n",
      "10/10 [==============================] - 3s 297ms/step - loss: 0.2042 - accuracy: 0.9169 - val_loss: 0.1868 - val_accuracy: 0.9128\n",
      "Epoch 79/1000\n",
      "10/10 [==============================] - 3s 282ms/step - loss: 0.2056 - accuracy: 0.9169 - val_loss: 0.1947 - val_accuracy: 0.9128\n",
      "Epoch 80/1000\n",
      "10/10 [==============================] - 3s 319ms/step - loss: 0.1976 - accuracy: 0.9227 - val_loss: 0.1966 - val_accuracy: 0.9128\n",
      "Epoch 81/1000\n",
      "10/10 [==============================] - 3s 319ms/step - loss: 0.2007 - accuracy: 0.9169 - val_loss: 0.1919 - val_accuracy: 0.9190\n",
      "Epoch 82/1000\n",
      "10/10 [==============================] - 3s 279ms/step - loss: 0.1915 - accuracy: 0.9186 - val_loss: 0.2225 - val_accuracy: 0.9283\n",
      "Epoch 83/1000\n",
      "10/10 [==============================] - 3s 299ms/step - loss: 0.2007 - accuracy: 0.9212 - val_loss: 0.2093 - val_accuracy: 0.9377\n",
      "Epoch 84/1000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 0.1934 - accuracy: 0.9160 - val_loss: 0.2003 - val_accuracy: 0.9346\n",
      "Epoch 85/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1928 - accuracy: 0.9227\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "10/10 [==============================] - 3s 313ms/step - loss: 0.1928 - accuracy: 0.9227 - val_loss: 0.1987 - val_accuracy: 0.9252\n",
      "Epoch 86/1000\n",
      "10/10 [==============================] - 3s 299ms/step - loss: 0.1928 - accuracy: 0.9203 - val_loss: 0.1958 - val_accuracy: 0.9190\n",
      "Epoch 87/1000\n",
      "10/10 [==============================] - 3s 298ms/step - loss: 0.1866 - accuracy: 0.9316 - val_loss: 0.1938 - val_accuracy: 0.9221\n",
      "Epoch 88/1000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.1835 - accuracy: 0.9255 - val_loss: 0.1942 - val_accuracy: 0.9252\n",
      "Epoch 89/1000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.1943 - accuracy: 0.9212 - val_loss: 0.1909 - val_accuracy: 0.9221\n",
      "Epoch 90/1000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.1870 - accuracy: 0.9203 - val_loss: 0.1971 - val_accuracy: 0.9221\n",
      "Epoch 91/1000\n",
      "10/10 [==============================] - 3s 313ms/step - loss: 0.1951 - accuracy: 0.9234 - val_loss: 0.1951 - val_accuracy: 0.9159\n",
      "Epoch 92/1000\n",
      "10/10 [==============================] - 3s 280ms/step - loss: 0.1981 - accuracy: 0.9126 - val_loss: 0.1914 - val_accuracy: 0.9221\n",
      "Epoch 93/1000\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.1963 - accuracy: 0.9229 - val_loss: 0.1894 - val_accuracy: 0.9221\n",
      "Epoch 94/1000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.1945 - accuracy: 0.9212 - val_loss: 0.1906 - val_accuracy: 0.9190\n",
      "Epoch 95/1000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.1664 - accuracy: 0.9307 - val_loss: 0.1891 - val_accuracy: 0.9221\n",
      "Epoch 96/1000\n",
      "10/10 [==============================] - 3s 334ms/step - loss: 0.1825 - accuracy: 0.9342 - val_loss: 0.1910 - val_accuracy: 0.9190\n",
      "Epoch 97/1000\n",
      "10/10 [==============================] - 3s 283ms/step - loss: 0.1919 - accuracy: 0.9221 - val_loss: 0.1867 - val_accuracy: 0.9252\n",
      "Epoch 98/1000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.1956 - accuracy: 0.9186 - val_loss: 0.1883 - val_accuracy: 0.9377\n",
      "Epoch 99/1000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.1885 - accuracy: 0.9229 - val_loss: 0.1879 - val_accuracy: 0.9346\n",
      "Epoch 100/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1874 - accuracy: 0.9247\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 0.1874 - accuracy: 0.9247 - val_loss: 0.1890 - val_accuracy: 0.9252\n",
      "Epoch 101/1000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.1943 - accuracy: 0.9264 - val_loss: 0.1880 - val_accuracy: 0.9221\n",
      "Epoch 102/1000\n",
      "10/10 [==============================] - 3s 347ms/step - loss: 0.1784 - accuracy: 0.9273 - val_loss: 0.1888 - val_accuracy: 0.9252\n",
      "Epoch 103/1000\n",
      "10/10 [==============================] - 3s 281ms/step - loss: 0.1815 - accuracy: 0.9325 - val_loss: 0.1868 - val_accuracy: 0.9252\n",
      "Epoch 104/1000\n",
      "10/10 [==============================] - 3s 347ms/step - loss: 0.1897 - accuracy: 0.9255 - val_loss: 0.1847 - val_accuracy: 0.9221\n",
      "Epoch 105/1000\n",
      "10/10 [==============================] - 3s 342ms/step - loss: 0.1789 - accuracy: 0.9368 - val_loss: 0.1843 - val_accuracy: 0.9221\n",
      "Epoch 106/1000\n",
      "10/10 [==============================] - 3s 314ms/step - loss: 0.1886 - accuracy: 0.9221 - val_loss: 0.1851 - val_accuracy: 0.9221\n",
      "Epoch 107/1000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.1951 - accuracy: 0.9290 - val_loss: 0.1849 - val_accuracy: 0.9190\n",
      "Epoch 108/1000\n",
      "10/10 [==============================] - 3s 319ms/step - loss: 0.1873 - accuracy: 0.9250 - val_loss: 0.1848 - val_accuracy: 0.9221\n",
      "Epoch 109/1000\n",
      "10/10 [==============================] - 3s 317ms/step - loss: 0.1876 - accuracy: 0.9255 - val_loss: 0.1850 - val_accuracy: 0.9252\n",
      "Epoch 110/1000\n",
      "10/10 [==============================] - 3s 315ms/step - loss: 0.1871 - accuracy: 0.9299 - val_loss: 0.1838 - val_accuracy: 0.9283\n",
      "Epoch 111/1000\n",
      "10/10 [==============================] - 3s 335ms/step - loss: 0.1869 - accuracy: 0.9195 - val_loss: 0.1833 - val_accuracy: 0.9283\n",
      "Epoch 112/1000\n",
      "10/10 [==============================] - 3s 278ms/step - loss: 0.1861 - accuracy: 0.9299 - val_loss: 0.1837 - val_accuracy: 0.9283\n",
      "Epoch 113/1000\n",
      "10/10 [==============================] - 3s 301ms/step - loss: 0.1949 - accuracy: 0.9169 - val_loss: 0.1839 - val_accuracy: 0.9283\n",
      "Epoch 114/1000\n",
      "10/10 [==============================] - 3s 334ms/step - loss: 0.1870 - accuracy: 0.9342 - val_loss: 0.1829 - val_accuracy: 0.9315\n",
      "Epoch 115/1000\n",
      "10/10 [==============================] - 3s 316ms/step - loss: 0.1976 - accuracy: 0.9177 - val_loss: 0.1825 - val_accuracy: 0.9283\n",
      "Epoch 116/1000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.1796 - accuracy: 0.9307 - val_loss: 0.1832 - val_accuracy: 0.9252\n",
      "Epoch 117/1000\n",
      "10/10 [==============================] - 3s 291ms/step - loss: 0.1768 - accuracy: 0.9325 - val_loss: 0.1829 - val_accuracy: 0.9221\n",
      "Epoch 118/1000\n",
      "10/10 [==============================] - 4s 383ms/step - loss: 0.1876 - accuracy: 0.9238 - val_loss: 0.1824 - val_accuracy: 0.9190\n",
      "Epoch 119/1000\n",
      "10/10 [==============================] - 3s 294ms/step - loss: 0.1894 - accuracy: 0.9238 - val_loss: 0.1827 - val_accuracy: 0.9190\n",
      "Epoch 120/1000\n",
      "10/10 [==============================] - 3s 342ms/step - loss: 0.1843 - accuracy: 0.9273 - val_loss: 0.1823 - val_accuracy: 0.9221\n",
      "Epoch 121/1000\n",
      "10/10 [==============================] - 3s 281ms/step - loss: 0.1872 - accuracy: 0.9273 - val_loss: 0.1824 - val_accuracy: 0.9221\n",
      "Epoch 122/1000\n",
      "10/10 [==============================] - 3s 346ms/step - loss: 0.1854 - accuracy: 0.9242 - val_loss: 0.1822 - val_accuracy: 0.9190\n",
      "Epoch 123/1000\n",
      "10/10 [==============================] - 3s 298ms/step - loss: 0.1827 - accuracy: 0.9195 - val_loss: 0.1823 - val_accuracy: 0.9221\n",
      "Epoch 124/1000\n",
      "10/10 [==============================] - 3s 278ms/step - loss: 0.1845 - accuracy: 0.9221 - val_loss: 0.1828 - val_accuracy: 0.9190\n",
      "Epoch 125/1000\n",
      "10/10 [==============================] - 3s 278ms/step - loss: 0.1720 - accuracy: 0.9325 - val_loss: 0.1824 - val_accuracy: 0.9190\n",
      "Epoch 126/1000\n",
      "10/10 [==============================] - 3s 278ms/step - loss: 0.1947 - accuracy: 0.9134 - val_loss: 0.1822 - val_accuracy: 0.9159\n",
      "Epoch 127/1000\n",
      "10/10 [==============================] - 3s 301ms/step - loss: 0.1859 - accuracy: 0.9238 - val_loss: 0.1832 - val_accuracy: 0.9190\n",
      "Epoch 128/1000\n",
      "10/10 [==============================] - 4s 355ms/step - loss: 0.1859 - accuracy: 0.9255 - val_loss: 0.1836 - val_accuracy: 0.9190\n",
      "Epoch 129/1000\n",
      "10/10 [==============================] - 3s 279ms/step - loss: 0.1963 - accuracy: 0.9281 - val_loss: 0.1842 - val_accuracy: 0.9252\n",
      "Epoch 130/1000\n",
      "10/10 [==============================] - 3s 292ms/step - loss: 0.1806 - accuracy: 0.9316 - val_loss: 0.1844 - val_accuracy: 0.9221\n",
      "Epoch 131/1000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.1963 - accuracy: 0.9299 - val_loss: 0.1850 - val_accuracy: 0.9221\n",
      "Epoch 132/1000\n",
      "10/10 [==============================] - 3s 278ms/step - loss: 0.1838 - accuracy: 0.9351 - val_loss: 0.1839 - val_accuracy: 0.9190\n",
      "Epoch 133/1000\n",
      "10/10 [==============================] - 3s 296ms/step - loss: 0.1784 - accuracy: 0.9290 - val_loss: 0.1840 - val_accuracy: 0.9190\n",
      "Epoch 134/1000\n",
      "10/10 [==============================] - 3s 282ms/step - loss: 0.1894 - accuracy: 0.9273 - val_loss: 0.1828 - val_accuracy: 0.9190\n",
      "Epoch 135/1000\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.1872 - accuracy: 0.9281 - val_loss: 0.1829 - val_accuracy: 0.9190\n",
      "Epoch 136/1000\n",
      "10/10 [==============================] - 3s 334ms/step - loss: 0.1853 - accuracy: 0.9203 - val_loss: 0.1839 - val_accuracy: 0.9190\n",
      "Epoch 137/1000\n",
      "10/10 [==============================] - 3s 332ms/step - loss: 0.1913 - accuracy: 0.9290 - val_loss: 0.1841 - val_accuracy: 0.9159\n",
      "Epoch 138/1000\n",
      "10/10 [==============================] - 3s 281ms/step - loss: 0.1943 - accuracy: 0.9203 - val_loss: 0.1842 - val_accuracy: 0.9190\n",
      "Epoch 139/1000\n",
      "10/10 [==============================] - 3s 302ms/step - loss: 0.1903 - accuracy: 0.9238 - val_loss: 0.1837 - val_accuracy: 0.9190\n",
      "Epoch 140/1000\n",
      "10/10 [==============================] - 3s 298ms/step - loss: 0.1805 - accuracy: 0.9385 - val_loss: 0.1833 - val_accuracy: 0.9159\n",
      "Epoch 141/1000\n",
      "10/10 [==============================] - 3s 282ms/step - loss: 0.1928 - accuracy: 0.9247 - val_loss: 0.1834 - val_accuracy: 0.9159\n",
      "Epoch 142/1000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.1896 - accuracy: 0.9238 - val_loss: 0.1835 - val_accuracy: 0.9190\n",
      "Epoch 143/1000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.1852 - accuracy: 0.9234 - val_loss: 0.1839 - val_accuracy: 0.9221\n",
      "Epoch 144/1000\n",
      "10/10 [==============================] - 3s 276ms/step - loss: 0.1839 - accuracy: 0.9247 - val_loss: 0.1842 - val_accuracy: 0.9283\n",
      "Epoch 145/1000\n",
      "10/10 [==============================] - 3s 278ms/step - loss: 0.1919 - accuracy: 0.9238 - val_loss: 0.1840 - val_accuracy: 0.9283\n",
      "Epoch 146/1000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.1805 - accuracy: 0.9299 - val_loss: 0.1836 - val_accuracy: 0.9283\n",
      "Epoch 147/1000\n",
      "10/10 [==============================] - 3s 349ms/step - loss: 0.1750 - accuracy: 0.9325 - val_loss: 0.1832 - val_accuracy: 0.9252\n",
      "Epoch 148/1000\n",
      "10/10 [==============================] - 3s 280ms/step - loss: 0.1839 - accuracy: 0.9281 - val_loss: 0.1835 - val_accuracy: 0.9252\n",
      "Epoch 149/1000\n",
      "10/10 [==============================] - 3s 341ms/step - loss: 0.1958 - accuracy: 0.9169 - val_loss: 0.1830 - val_accuracy: 0.9190\n",
      "Epoch 150/1000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.1879 - accuracy: 0.9264 - val_loss: 0.1829 - val_accuracy: 0.9221\n",
      "Epoch 151/1000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.1986 - accuracy: 0.9264 - val_loss: 0.1827 - val_accuracy: 0.9190\n",
      "Epoch 152/1000\n",
      "10/10 [==============================] - 3s 334ms/step - loss: 0.1869 - accuracy: 0.9203 - val_loss: 0.1829 - val_accuracy: 0.9190\n",
      "Epoch 153/1000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.1958 - accuracy: 0.9229 - val_loss: 0.1833 - val_accuracy: 0.9190\n",
      "Epoch 154/1000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.1948 - accuracy: 0.9264 - val_loss: 0.1835 - val_accuracy: 0.9159\n",
      "Epoch 155/1000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.1801 - accuracy: 0.9255 - val_loss: 0.1834 - val_accuracy: 0.9159\n",
      "Epoch 156/1000\n",
      "10/10 [==============================] - 3s 314ms/step - loss: 0.1884 - accuracy: 0.9264 - val_loss: 0.1831 - val_accuracy: 0.9159\n",
      "Epoch 157/1000\n",
      "10/10 [==============================] - 3s 278ms/step - loss: 0.1875 - accuracy: 0.9290 - val_loss: 0.1845 - val_accuracy: 0.9159\n",
      "Epoch 158/1000\n",
      "10/10 [==============================] - 3s 313ms/step - loss: 0.1791 - accuracy: 0.9316 - val_loss: 0.1852 - val_accuracy: 0.9221\n",
      "Epoch 159/1000\n",
      "10/10 [==============================] - 3s 282ms/step - loss: 0.1910 - accuracy: 0.9203 - val_loss: 0.1865 - val_accuracy: 0.9221\n",
      "Epoch 160/1000\n",
      "10/10 [==============================] - 3s 282ms/step - loss: 0.1902 - accuracy: 0.9212 - val_loss: 0.1866 - val_accuracy: 0.9252\n",
      "Epoch 161/1000\n",
      "10/10 [==============================] - 3s 278ms/step - loss: 0.1730 - accuracy: 0.9429 - val_loss: 0.1859 - val_accuracy: 0.9221\n",
      "Epoch 162/1000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 0.1910 - accuracy: 0.9281 - val_loss: 0.1867 - val_accuracy: 0.9221\n",
      "Epoch 163/1000\n",
      "10/10 [==============================] - 3s 283ms/step - loss: 0.1853 - accuracy: 0.9316 - val_loss: 0.1871 - val_accuracy: 0.9283\n",
      "Epoch 164/1000\n",
      "10/10 [==============================] - 3s 283ms/step - loss: 0.1927 - accuracy: 0.9247 - val_loss: 0.1857 - val_accuracy: 0.9252\n",
      "Epoch 165/1000\n",
      "10/10 [==============================] - 3s 295ms/step - loss: 0.1864 - accuracy: 0.9255 - val_loss: 0.1843 - val_accuracy: 0.9252\n",
      "Epoch 166/1000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.1899 - accuracy: 0.9221 - val_loss: 0.1846 - val_accuracy: 0.9252\n",
      "Epoch 167/1000\n",
      "10/10 [==============================] - 3s 298ms/step - loss: 0.1737 - accuracy: 0.9359 - val_loss: 0.1845 - val_accuracy: 0.9283\n",
      "Loss:\n",
      "Mean: 0.182235\n",
      "Std: 0.000000\n",
      "Min: 0.182235\n",
      "Max: 0.182235\n",
      "\n",
      "\n",
      "Acc:\n",
      "Mean: 0.919003\n",
      "Std: 0.000000\n",
      "Min: 0.919003\n",
      "Max: 0.919003\n",
      "\n",
      "\n",
      "ROC AUC:\n",
      "Mean: 0.981979\n",
      "Std: 0.000000\n",
      "Min: 0.981979\n",
      "Max: 0.981979\n",
      "\n",
      "\n",
      "mAP:\n",
      "Mean: 0.982835\n",
      "Std: 0.000000\n",
      "Min: 0.982835\n",
      "Max: 0.982835\n",
      "\n",
      "\n",
      "Model: \"resnext\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 75, 75, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_38 (Lambda)              (None, 75, 75, 2)    0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_39 (Lambda)              (None, 75, 75, 1)    0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_2 (GaussianNoise (None, 75, 75, 2)    0           lambda_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_3 (GaussianNoise (None, 75, 75, 1)    0           lambda_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 75, 75, 3)    0           gaussian_noise_2[0][0]           \n",
      "                                                                 gaussian_noise_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 75, 75, 32)   896         concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 75, 75, 32)   128         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 75, 75, 32)   0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 75, 75, 32)   1024        activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 75, 75, 32)   128         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 75, 75, 32)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_40 (Lambda)              (None, 75, 75, 8)    0           activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_41 (Lambda)              (None, 75, 75, 8)    0           activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_42 (Lambda)              (None, 75, 75, 8)    0           activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_43 (Lambda)              (None, 75, 75, 8)    0           activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 75, 75, 8)    584         lambda_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 75, 75, 8)    584         lambda_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 75, 75, 8)    584         lambda_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 75, 75, 8)    584         lambda_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 75, 75, 32)   0           conv2d_61[0][0]                  \n",
      "                                                                 conv2d_62[0][0]                  \n",
      "                                                                 conv2d_63[0][0]                  \n",
      "                                                                 conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 75, 75, 32)   128         concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 75, 75, 32)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 75, 75, 64)   2112        activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 75, 75, 64)   2112        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 75, 75, 64)   256         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 75, 75, 64)   256         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 75, 75, 64)   0           batch_normalization_32[0][0]     \n",
      "                                                                 batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 75, 75, 64)   0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 75, 75, 32)   2048        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 75, 75, 32)   128         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 75, 75, 32)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_44 (Lambda)              (None, 75, 75, 8)    0           activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_45 (Lambda)              (None, 75, 75, 8)    0           activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_46 (Lambda)              (None, 75, 75, 8)    0           activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_47 (Lambda)              (None, 75, 75, 8)    0           activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 75, 75, 8)    584         lambda_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 75, 75, 8)    584         lambda_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 75, 75, 8)    584         lambda_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 75, 75, 8)    584         lambda_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 75, 75, 32)   0           conv2d_67[0][0]                  \n",
      "                                                                 conv2d_68[0][0]                  \n",
      "                                                                 conv2d_69[0][0]                  \n",
      "                                                                 conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 75, 75, 32)   128         concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 75, 75, 32)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 75, 75, 64)   2112        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 75, 75, 64)   256         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 75, 75, 64)   0           activation_31[0][0]              \n",
      "                                                                 batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 75, 75, 64)   0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 75, 75, 32)   2048        activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 75, 75, 32)   128         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 75, 75, 32)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_48 (Lambda)              (None, 75, 75, 8)    0           activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_49 (Lambda)              (None, 75, 75, 8)    0           activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_50 (Lambda)              (None, 75, 75, 8)    0           activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_51 (Lambda)              (None, 75, 75, 8)    0           activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 75, 75, 8)    584         lambda_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 75, 75, 8)    584         lambda_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 75, 75, 8)    584         lambda_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 75, 75, 8)    584         lambda_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 75, 75, 32)   0           conv2d_73[0][0]                  \n",
      "                                                                 conv2d_74[0][0]                  \n",
      "                                                                 conv2d_75[0][0]                  \n",
      "                                                                 conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 75, 75, 32)   128         concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 75, 75, 32)   0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 75, 75, 64)   2112        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 75, 75, 64)   256         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 75, 75, 64)   0           activation_34[0][0]              \n",
      "                                                                 batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 75, 75, 64)   0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 75, 75, 64)   4096        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 75, 75, 64)   256         conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 75, 75, 64)   0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_52 (Lambda)              (None, 75, 75, 16)   0           activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_53 (Lambda)              (None, 75, 75, 16)   0           activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_54 (Lambda)              (None, 75, 75, 16)   0           activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_55 (Lambda)              (None, 75, 75, 16)   0           activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 38, 38, 16)   2320        lambda_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 38, 38, 16)   2320        lambda_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 38, 38, 16)   2320        lambda_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 38, 38, 16)   2320        lambda_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 38, 38, 64)   0           conv2d_80[0][0]                  \n",
      "                                                                 conv2d_81[0][0]                  \n",
      "                                                                 conv2d_82[0][0]                  \n",
      "                                                                 conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 38, 38, 64)   256         concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 38, 38, 64)   0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 38, 38, 128)  8320        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 38, 38, 128)  8320        activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 38, 38, 128)  512         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 38, 38, 128)  512         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 38, 38, 128)  0           batch_normalization_42[0][0]     \n",
      "                                                                 batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 38, 38, 128)  0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 38, 38, 64)   8192        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 38, 38, 64)   256         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 38, 38, 64)   0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_56 (Lambda)              (None, 38, 38, 16)   0           activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_57 (Lambda)              (None, 38, 38, 16)   0           activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_58 (Lambda)              (None, 38, 38, 16)   0           activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_59 (Lambda)              (None, 38, 38, 16)   0           activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 38, 38, 16)   2320        lambda_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 38, 38, 16)   2320        lambda_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 38, 38, 16)   2320        lambda_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 38, 38, 16)   2320        lambda_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 38, 38, 64)   0           conv2d_86[0][0]                  \n",
      "                                                                 conv2d_87[0][0]                  \n",
      "                                                                 conv2d_88[0][0]                  \n",
      "                                                                 conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 38, 38, 64)   256         concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 38, 38, 64)   0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 38, 38, 128)  8320        activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 38, 38, 128)  512         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 38, 38, 128)  0           activation_40[0][0]              \n",
      "                                                                 batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 38, 38, 128)  0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 38, 38, 64)   8192        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 38, 38, 64)   256         conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 38, 38, 64)   0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_60 (Lambda)              (None, 38, 38, 16)   0           activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_61 (Lambda)              (None, 38, 38, 16)   0           activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_62 (Lambda)              (None, 38, 38, 16)   0           activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_63 (Lambda)              (None, 38, 38, 16)   0           activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 38, 38, 16)   2320        lambda_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 38, 38, 16)   2320        lambda_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 38, 38, 16)   2320        lambda_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 38, 38, 16)   2320        lambda_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 38, 38, 64)   0           conv2d_92[0][0]                  \n",
      "                                                                 conv2d_93[0][0]                  \n",
      "                                                                 conv2d_94[0][0]                  \n",
      "                                                                 conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 38, 38, 64)   256         concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 38, 38, 64)   0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 38, 38, 128)  8320        activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 38, 38, 128)  512         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 38, 38, 128)  0           activation_43[0][0]              \n",
      "                                                                 batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 38, 38, 128)  0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 38, 38, 128)  16384       activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 38, 38, 128)  512         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 38, 38, 128)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_64 (Lambda)              (None, 38, 38, 32)   0           activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_65 (Lambda)              (None, 38, 38, 32)   0           activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_66 (Lambda)              (None, 38, 38, 32)   0           activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_67 (Lambda)              (None, 38, 38, 32)   0           activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 19, 19, 32)   9248        lambda_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 19, 19, 32)   9248        lambda_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 19, 19, 32)   9248        lambda_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 19, 19, 32)   9248        lambda_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 19, 19, 128)  0           conv2d_99[0][0]                  \n",
      "                                                                 conv2d_100[0][0]                 \n",
      "                                                                 conv2d_101[0][0]                 \n",
      "                                                                 conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 19, 19, 128)  512         concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 19, 19, 128)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 19, 19, 256)  33024       activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 19, 19, 256)  33024       activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 19, 19, 256)  1024        conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 19, 19, 256)  1024        conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 19, 19, 256)  0           batch_normalization_52[0][0]     \n",
      "                                                                 batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 19, 19, 256)  0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 19, 19, 128)  32768       activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 19, 19, 128)  512         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 19, 19, 128)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_68 (Lambda)              (None, 19, 19, 32)   0           activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_69 (Lambda)              (None, 19, 19, 32)   0           activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_70 (Lambda)              (None, 19, 19, 32)   0           activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_71 (Lambda)              (None, 19, 19, 32)   0           activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 19, 19, 32)   9248        lambda_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 19, 19, 32)   9248        lambda_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 19, 19, 32)   9248        lambda_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 19, 19, 32)   9248        lambda_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 19, 19, 128)  0           conv2d_105[0][0]                 \n",
      "                                                                 conv2d_106[0][0]                 \n",
      "                                                                 conv2d_107[0][0]                 \n",
      "                                                                 conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 19, 19, 128)  512         concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 19, 19, 128)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 19, 19, 256)  33024       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 19, 19, 256)  1024        conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 19, 19, 256)  0           activation_49[0][0]              \n",
      "                                                                 batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 19, 19, 256)  0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 19, 19, 128)  32768       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 19, 19, 128)  512         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 19, 19, 128)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_72 (Lambda)              (None, 19, 19, 32)   0           activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_73 (Lambda)              (None, 19, 19, 32)   0           activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_74 (Lambda)              (None, 19, 19, 32)   0           activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_75 (Lambda)              (None, 19, 19, 32)   0           activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 19, 19, 32)   9248        lambda_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 19, 19, 32)   9248        lambda_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 19, 19, 32)   9248        lambda_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 19, 19, 32)   9248        lambda_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 19, 19, 128)  0           conv2d_111[0][0]                 \n",
      "                                                                 conv2d_112[0][0]                 \n",
      "                                                                 conv2d_113[0][0]                 \n",
      "                                                                 conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 19, 19, 128)  512         concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 19, 19, 128)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 19, 19, 256)  33024       activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 19, 19, 256)  1024        conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 19, 19, 256)  0           activation_52[0][0]              \n",
      "                                                                 batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 19, 19, 256)  0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 256)          0           activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            514         global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 441,250\n",
      "Trainable params: 434,914\n",
      "Non-trainable params: 6,336\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/1000\n",
      "10/10 [==============================] - 5s 548ms/step - loss: 1.1894 - accuracy: 0.6000 - val_loss: 7.0713 - val_accuracy: 0.5389\n",
      "Epoch 2/1000\n",
      "10/10 [==============================] - 3s 298ms/step - loss: 0.7300 - accuracy: 0.6052 - val_loss: 7.0713 - val_accuracy: 0.5389\n",
      "Epoch 3/1000\n",
      "10/10 [==============================] - 3s 278ms/step - loss: 0.6403 - accuracy: 0.6329 - val_loss: 7.0713 - val_accuracy: 0.5389\n",
      "Epoch 4/1000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.6495 - accuracy: 0.6571 - val_loss: 7.0713 - val_accuracy: 0.5389\n",
      "Epoch 5/1000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.5774 - accuracy: 0.6589 - val_loss: 7.0713 - val_accuracy: 0.5389\n",
      "Epoch 6/1000\n",
      "10/10 [==============================] - 4s 390ms/step - loss: 0.5804 - accuracy: 0.6961 - val_loss: 7.0713 - val_accuracy: 0.5389\n",
      "Epoch 7/1000\n",
      "10/10 [==============================] - 3s 270ms/step - loss: 0.5211 - accuracy: 0.7082 - val_loss: 7.0713 - val_accuracy: 0.5389\n",
      "Epoch 8/1000\n",
      "10/10 [==============================] - 4s 366ms/step - loss: 0.5065 - accuracy: 0.7516 - val_loss: 7.0713 - val_accuracy: 0.5389\n",
      "Epoch 9/1000\n",
      "10/10 [==============================] - 3s 298ms/step - loss: 0.4432 - accuracy: 0.7844 - val_loss: 7.0713 - val_accuracy: 0.5389\n",
      "Epoch 10/1000\n",
      "10/10 [==============================] - 3s 300ms/step - loss: 0.5545 - accuracy: 0.7411 - val_loss: 7.0713 - val_accuracy: 0.5389\n",
      "Epoch 11/1000\n",
      "10/10 [==============================] - 3s 301ms/step - loss: 0.4140 - accuracy: 0.8139 - val_loss: 7.0713 - val_accuracy: 0.5389\n",
      "Epoch 12/1000\n",
      "10/10 [==============================] - 3s 280ms/step - loss: 0.4232 - accuracy: 0.8000 - val_loss: 7.0713 - val_accuracy: 0.5389\n",
      "Epoch 13/1000\n",
      "10/10 [==============================] - 3s 281ms/step - loss: 0.4090 - accuracy: 0.8156 - val_loss: 7.0713 - val_accuracy: 0.5389\n",
      "Epoch 14/1000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.3484 - accuracy: 0.8398 - val_loss: 7.0713 - val_accuracy: 0.5389\n",
      "Epoch 15/1000\n",
      "10/10 [==============================] - 4s 390ms/step - loss: 0.3867 - accuracy: 0.8381 - val_loss: 6.8890 - val_accuracy: 0.5389\n",
      "Epoch 16/1000\n",
      "10/10 [==============================] - 3s 316ms/step - loss: 0.3191 - accuracy: 0.8502 - val_loss: 4.2406 - val_accuracy: 0.6386\n",
      "Epoch 17/1000\n",
      "10/10 [==============================] - 3s 300ms/step - loss: 0.3947 - accuracy: 0.7991 - val_loss: 6.0935 - val_accuracy: 0.5639\n",
      "Epoch 18/1000\n",
      "10/10 [==============================] - 3s 268ms/step - loss: 0.2922 - accuracy: 0.8779 - val_loss: 7.6477 - val_accuracy: 0.4829\n",
      "Epoch 19/1000\n",
      "10/10 [==============================] - 3s 316ms/step - loss: 0.6517 - accuracy: 0.7558 - val_loss: 2.6230 - val_accuracy: 0.7477\n",
      "Epoch 20/1000\n",
      "10/10 [==============================] - 3s 331ms/step - loss: 0.3730 - accuracy: 0.8355 - val_loss: 2.6022 - val_accuracy: 0.6168\n",
      "Epoch 21/1000\n",
      "10/10 [==============================] - 3s 279ms/step - loss: 0.3224 - accuracy: 0.8580 - val_loss: 2.8036 - val_accuracy: 0.6106\n",
      "Epoch 22/1000\n",
      "10/10 [==============================] - 3s 279ms/step - loss: 0.3670 - accuracy: 0.8442 - val_loss: 2.6246 - val_accuracy: 0.6075\n",
      "Epoch 23/1000\n",
      "10/10 [==============================] - 3s 283ms/step - loss: 0.3588 - accuracy: 0.8346 - val_loss: 5.3294 - val_accuracy: 0.5389\n",
      "Epoch 24/1000\n",
      "10/10 [==============================] - 4s 353ms/step - loss: 0.3042 - accuracy: 0.8623 - val_loss: 4.7009 - val_accuracy: 0.5794\n",
      "Epoch 25/1000\n",
      "10/10 [==============================] - 4s 380ms/step - loss: 0.3068 - accuracy: 0.8711 - val_loss: 0.8096 - val_accuracy: 0.8255\n",
      "Epoch 26/1000\n",
      "10/10 [==============================] - 3s 337ms/step - loss: 0.3026 - accuracy: 0.8693 - val_loss: 4.0277 - val_accuracy: 0.7040\n",
      "Epoch 27/1000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3219 - accuracy: 0.8623 - val_loss: 3.0057 - val_accuracy: 0.6885\n",
      "Epoch 28/1000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.2914 - accuracy: 0.8684 - val_loss: 3.9265 - val_accuracy: 0.6822\n",
      "Epoch 29/1000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.2925 - accuracy: 0.8710 - val_loss: 1.1617 - val_accuracy: 0.7352\n",
      "Epoch 30/1000\n",
      "10/10 [==============================] - 3s 298ms/step - loss: 0.2895 - accuracy: 0.8771 - val_loss: 2.2210 - val_accuracy: 0.7414\n",
      "Epoch 31/1000\n",
      "10/10 [==============================] - 3s 280ms/step - loss: 0.3179 - accuracy: 0.8667 - val_loss: 2.5775 - val_accuracy: 0.7259\n",
      "Epoch 32/1000\n",
      "10/10 [==============================] - 3s 270ms/step - loss: 0.2603 - accuracy: 0.8840 - val_loss: 4.2972 - val_accuracy: 0.5389\n",
      "Epoch 33/1000\n",
      "10/10 [==============================] - 3s 339ms/step - loss: 0.3249 - accuracy: 0.8571 - val_loss: 1.0348 - val_accuracy: 0.7508\n",
      "Epoch 34/1000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.2672 - accuracy: 0.8970 - val_loss: 6.9339 - val_accuracy: 0.5421\n",
      "Epoch 35/1000\n",
      "10/10 [==============================] - 3s 282ms/step - loss: 0.2695 - accuracy: 0.8866 - val_loss: 7.0653 - val_accuracy: 0.5389\n",
      "Epoch 36/1000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.2450 - accuracy: 0.8961 - val_loss: 7.0144 - val_accuracy: 0.5389\n",
      "Epoch 37/1000\n",
      "10/10 [==============================] - 3s 278ms/step - loss: 0.2604 - accuracy: 0.8892 - val_loss: 7.0713 - val_accuracy: 0.5389\n",
      "Epoch 38/1000\n",
      "10/10 [==============================] - 3s 277ms/step - loss: 0.2591 - accuracy: 0.8840 - val_loss: 4.3509 - val_accuracy: 0.6417\n",
      "Epoch 39/1000\n",
      "10/10 [==============================] - 3s 281ms/step - loss: 0.2727 - accuracy: 0.8909 - val_loss: 5.6414 - val_accuracy: 0.5670\n",
      "Epoch 40/1000\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2563 - accuracy: 0.8976\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "10/10 [==============================] - 3s 265ms/step - loss: 0.2565 - accuracy: 0.8970 - val_loss: 1.7313 - val_accuracy: 0.6417\n",
      "Epoch 41/1000\n",
      "10/10 [==============================] - 3s 343ms/step - loss: 0.2730 - accuracy: 0.8840 - val_loss: 0.3728 - val_accuracy: 0.8567\n",
      "Epoch 42/1000\n",
      "10/10 [==============================] - 4s 376ms/step - loss: 0.2219 - accuracy: 0.9152 - val_loss: 0.7832 - val_accuracy: 0.7570\n",
      "Epoch 43/1000\n",
      "10/10 [==============================] - 4s 371ms/step - loss: 0.2405 - accuracy: 0.9082 - val_loss: 0.3410 - val_accuracy: 0.8692\n",
      "Epoch 44/1000\n",
      "10/10 [==============================] - 3s 319ms/step - loss: 0.2419 - accuracy: 0.9091 - val_loss: 0.3101 - val_accuracy: 0.8629\n",
      "Epoch 45/1000\n",
      "10/10 [==============================] - 3s 349ms/step - loss: 0.2341 - accuracy: 0.8938 - val_loss: 0.2500 - val_accuracy: 0.8879\n",
      "Epoch 46/1000\n",
      "10/10 [==============================] - 3s 282ms/step - loss: 0.2255 - accuracy: 0.9065 - val_loss: 0.3556 - val_accuracy: 0.8723\n",
      "Epoch 47/1000\n",
      "10/10 [==============================] - 3s 270ms/step - loss: 0.2153 - accuracy: 0.9100 - val_loss: 0.5236 - val_accuracy: 0.8536\n",
      "Epoch 48/1000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.2172 - accuracy: 0.9056 - val_loss: 0.4600 - val_accuracy: 0.8660\n",
      "Epoch 49/1000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.2142 - accuracy: 0.9133 - val_loss: 1.4462 - val_accuracy: 0.7165\n",
      "Epoch 50/1000\n",
      "10/10 [==============================] - 3s 279ms/step - loss: 0.2126 - accuracy: 0.9143 - val_loss: 0.3182 - val_accuracy: 0.8941\n",
      "Epoch 51/1000\n",
      "10/10 [==============================] - 3s 317ms/step - loss: 0.2171 - accuracy: 0.9134 - val_loss: 0.2734 - val_accuracy: 0.8972\n",
      "Epoch 52/1000\n",
      "10/10 [==============================] - 3s 296ms/step - loss: 0.2150 - accuracy: 0.9195 - val_loss: 0.6926 - val_accuracy: 0.8287\n",
      "Epoch 53/1000\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.2011 - accuracy: 0.9152 - val_loss: 0.6509 - val_accuracy: 0.8255\n",
      "Epoch 54/1000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.2107 - accuracy: 0.9212 - val_loss: 0.3995 - val_accuracy: 0.8598\n",
      "Epoch 55/1000\n",
      "10/10 [==============================] - 3s 318ms/step - loss: 0.2035 - accuracy: 0.9195 - val_loss: 0.2887 - val_accuracy: 0.8785\n",
      "Epoch 56/1000\n",
      "10/10 [==============================] - 3s 279ms/step - loss: 0.1917 - accuracy: 0.9247 - val_loss: 0.3381 - val_accuracy: 0.8910\n",
      "Epoch 57/1000\n",
      "10/10 [==============================] - 3s 280ms/step - loss: 0.1992 - accuracy: 0.9160 - val_loss: 0.6633 - val_accuracy: 0.8318\n",
      "Epoch 58/1000\n",
      "10/10 [==============================] - 3s 344ms/step - loss: 0.2076 - accuracy: 0.9186 - val_loss: 0.2414 - val_accuracy: 0.9003\n",
      "Epoch 59/1000\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 0.2001 - accuracy: 0.9203 - val_loss: 0.4908 - val_accuracy: 0.8037\n",
      "Epoch 60/1000\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.2045 - accuracy: 0.9221 - val_loss: 0.2773 - val_accuracy: 0.8879\n",
      "Epoch 61/1000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.2044 - accuracy: 0.9160 - val_loss: 0.2437 - val_accuracy: 0.8972\n",
      "Epoch 62/1000\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.2097 - accuracy: 0.9126 - val_loss: 0.2633 - val_accuracy: 0.8879\n",
      "Epoch 63/1000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.2025 - accuracy: 0.9177 - val_loss: 0.3203 - val_accuracy: 0.8723\n",
      "Epoch 64/1000\n",
      "10/10 [==============================] - 3s 347ms/step - loss: 0.1944 - accuracy: 0.9247 - val_loss: 0.2366 - val_accuracy: 0.9065\n",
      "Epoch 65/1000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.2112 - accuracy: 0.9177 - val_loss: 0.2593 - val_accuracy: 0.8910\n",
      "Epoch 66/1000\n",
      "10/10 [==============================] - 3s 332ms/step - loss: 0.1825 - accuracy: 0.9195 - val_loss: 0.2307 - val_accuracy: 0.8941\n",
      "Epoch 67/1000\n",
      "10/10 [==============================] - 3s 316ms/step - loss: 0.1875 - accuracy: 0.9281 - val_loss: 0.3179 - val_accuracy: 0.8816\n",
      "Epoch 68/1000\n",
      "10/10 [==============================] - 3s 283ms/step - loss: 0.1954 - accuracy: 0.9238 - val_loss: 0.2541 - val_accuracy: 0.8941\n",
      "Epoch 69/1000\n",
      "10/10 [==============================] - 3s 297ms/step - loss: 0.1933 - accuracy: 0.9160 - val_loss: 0.6728 - val_accuracy: 0.7632\n",
      "Epoch 70/1000\n",
      "10/10 [==============================] - 3s 314ms/step - loss: 0.2099 - accuracy: 0.9186 - val_loss: 0.3249 - val_accuracy: 0.8505\n",
      "Epoch 71/1000\n",
      "10/10 [==============================] - 3s 316ms/step - loss: 0.1833 - accuracy: 0.9299 - val_loss: 0.3724 - val_accuracy: 0.8318\n",
      "Epoch 72/1000\n",
      "10/10 [==============================] - 3s 283ms/step - loss: 0.1966 - accuracy: 0.9290 - val_loss: 0.2459 - val_accuracy: 0.8847\n",
      "Epoch 73/1000\n",
      "10/10 [==============================] - 3s 298ms/step - loss: 0.1889 - accuracy: 0.9307 - val_loss: 0.2665 - val_accuracy: 0.8816\n",
      "Epoch 74/1000\n",
      "10/10 [==============================] - 3s 319ms/step - loss: 0.2020 - accuracy: 0.9143 - val_loss: 0.2198 - val_accuracy: 0.9003\n",
      "Epoch 75/1000\n",
      "10/10 [==============================] - 3s 274ms/step - loss: 0.1737 - accuracy: 0.9377 - val_loss: 0.2440 - val_accuracy: 0.8879\n",
      "Epoch 76/1000\n",
      "10/10 [==============================] - 3s 315ms/step - loss: 0.1915 - accuracy: 0.9221 - val_loss: 0.2751 - val_accuracy: 0.8785\n",
      "Epoch 77/1000\n",
      "10/10 [==============================] - 3s 316ms/step - loss: 0.1896 - accuracy: 0.9195 - val_loss: 0.2357 - val_accuracy: 0.8941\n",
      "Epoch 78/1000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.2011 - accuracy: 0.9195 - val_loss: 0.2502 - val_accuracy: 0.8879\n",
      "Epoch 79/1000\n",
      "10/10 [==============================] - 3s 292ms/step - loss: 0.1721 - accuracy: 0.9377 - val_loss: 0.2989 - val_accuracy: 0.8629\n",
      "Epoch 80/1000\n",
      "10/10 [==============================] - 4s 351ms/step - loss: 0.1851 - accuracy: 0.9221 - val_loss: 0.2084 - val_accuracy: 0.9034\n",
      "Epoch 81/1000\n",
      "10/10 [==============================] - 3s 283ms/step - loss: 0.1822 - accuracy: 0.9325 - val_loss: 0.2346 - val_accuracy: 0.8816\n",
      "Epoch 82/1000\n",
      "10/10 [==============================] - 3s 292ms/step - loss: 0.1733 - accuracy: 0.9377 - val_loss: 0.2776 - val_accuracy: 0.8692\n",
      "Epoch 83/1000\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.1825 - accuracy: 0.9333 - val_loss: 0.2401 - val_accuracy: 0.8847\n",
      "Epoch 84/1000\n",
      "10/10 [==============================] - 3s 282ms/step - loss: 0.1853 - accuracy: 0.9299 - val_loss: 0.8161 - val_accuracy: 0.7445\n",
      "Epoch 85/1000\n",
      "10/10 [==============================] - 3s 280ms/step - loss: 0.1885 - accuracy: 0.9221 - val_loss: 0.2280 - val_accuracy: 0.8847\n",
      "Epoch 86/1000\n",
      "10/10 [==============================] - 3s 302ms/step - loss: 0.1891 - accuracy: 0.9281 - val_loss: 0.3575 - val_accuracy: 0.8536\n",
      "Epoch 87/1000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.1840 - accuracy: 0.9320 - val_loss: 0.2098 - val_accuracy: 0.9034\n",
      "Epoch 88/1000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.1697 - accuracy: 0.9377 - val_loss: 0.2718 - val_accuracy: 0.8816\n",
      "Epoch 89/1000\n",
      "10/10 [==============================] - 3s 300ms/step - loss: 0.1871 - accuracy: 0.9290 - val_loss: 0.3829 - val_accuracy: 0.8318\n",
      "Epoch 90/1000\n",
      "10/10 [==============================] - 3s 334ms/step - loss: 0.1643 - accuracy: 0.9367 - val_loss: 0.2217 - val_accuracy: 0.8972\n",
      "Epoch 91/1000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.1723 - accuracy: 0.9212 - val_loss: 0.1883 - val_accuracy: 0.9003\n",
      "Epoch 92/1000\n",
      "10/10 [==============================] - 3s 300ms/step - loss: 0.1719 - accuracy: 0.9342 - val_loss: 0.2354 - val_accuracy: 0.9003\n",
      "Epoch 93/1000\n",
      "10/10 [==============================] - 3s 313ms/step - loss: 0.1737 - accuracy: 0.9359 - val_loss: 0.2326 - val_accuracy: 0.8910\n",
      "Epoch 94/1000\n",
      "10/10 [==============================] - 3s 293ms/step - loss: 0.1766 - accuracy: 0.9325 - val_loss: 0.2814 - val_accuracy: 0.8754\n",
      "Epoch 95/1000\n",
      "10/10 [==============================] - 3s 338ms/step - loss: 0.1842 - accuracy: 0.9152 - val_loss: 0.5214 - val_accuracy: 0.8442\n",
      "Epoch 96/1000\n",
      "10/10 [==============================] - 3s 300ms/step - loss: 0.1724 - accuracy: 0.9325 - val_loss: 0.2805 - val_accuracy: 0.8847\n",
      "Epoch 97/1000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.1773 - accuracy: 0.9307 - val_loss: 0.3494 - val_accuracy: 0.8629\n",
      "Epoch 98/1000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 0.1850 - accuracy: 0.9247 - val_loss: 0.3845 - val_accuracy: 0.8536\n",
      "Epoch 99/1000\n",
      "10/10 [==============================] - 4s 351ms/step - loss: 0.1976 - accuracy: 0.9212 - val_loss: 0.3451 - val_accuracy: 0.8629\n",
      "Epoch 100/1000\n",
      "10/10 [==============================] - 3s 295ms/step - loss: 0.1672 - accuracy: 0.9352 - val_loss: 0.4146 - val_accuracy: 0.8474\n",
      "Epoch 101/1000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.1699 - accuracy: 0.9333 - val_loss: 0.2942 - val_accuracy: 0.8879\n",
      "Epoch 102/1000\n",
      "10/10 [==============================] - 3s 279ms/step - loss: 0.1706 - accuracy: 0.9385 - val_loss: 0.2846 - val_accuracy: 0.8847\n",
      "Epoch 103/1000\n",
      "10/10 [==============================] - 3s 280ms/step - loss: 0.1758 - accuracy: 0.9307 - val_loss: 0.2361 - val_accuracy: 0.8879\n",
      "Epoch 104/1000\n",
      "10/10 [==============================] - 3s 280ms/step - loss: 0.1767 - accuracy: 0.9325 - val_loss: 0.5919 - val_accuracy: 0.8069\n",
      "Epoch 105/1000\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 0.1747 - accuracy: 0.9394 - val_loss: 1.1265 - val_accuracy: 0.7383\n",
      "Epoch 106/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1857 - accuracy: 0.9255\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "10/10 [==============================] - 3s 283ms/step - loss: 0.1857 - accuracy: 0.9255 - val_loss: 1.3205 - val_accuracy: 0.7570\n",
      "Epoch 107/1000\n",
      "10/10 [==============================] - 3s 279ms/step - loss: 0.1567 - accuracy: 0.9420 - val_loss: 0.9252 - val_accuracy: 0.7913\n",
      "Epoch 108/1000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.1718 - accuracy: 0.9368 - val_loss: 0.3140 - val_accuracy: 0.8879\n",
      "Epoch 109/1000\n",
      "10/10 [==============================] - 3s 302ms/step - loss: 0.1608 - accuracy: 0.9411 - val_loss: 0.3339 - val_accuracy: 0.8879\n",
      "Epoch 110/1000\n",
      "10/10 [==============================] - 3s 338ms/step - loss: 0.1694 - accuracy: 0.9351 - val_loss: 0.3083 - val_accuracy: 0.8941\n",
      "Epoch 111/1000\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.1593 - accuracy: 0.9437 - val_loss: 0.2870 - val_accuracy: 0.8910\n",
      "Epoch 112/1000\n",
      "10/10 [==============================] - 3s 280ms/step - loss: 0.1625 - accuracy: 0.9411 - val_loss: 0.2237 - val_accuracy: 0.9003\n",
      "Epoch 113/1000\n",
      "10/10 [==============================] - 3s 283ms/step - loss: 0.1451 - accuracy: 0.9446 - val_loss: 0.3193 - val_accuracy: 0.8785\n",
      "Epoch 114/1000\n",
      "10/10 [==============================] - 4s 376ms/step - loss: 0.1551 - accuracy: 0.9394 - val_loss: 0.2914 - val_accuracy: 0.8879\n",
      "Epoch 115/1000\n",
      "10/10 [==============================] - 3s 282ms/step - loss: 0.1558 - accuracy: 0.9394 - val_loss: 0.2376 - val_accuracy: 0.8941\n",
      "Epoch 116/1000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.1557 - accuracy: 0.9342 - val_loss: 0.2390 - val_accuracy: 0.8972\n",
      "Epoch 117/1000\n",
      "10/10 [==============================] - 3s 313ms/step - loss: 0.1644 - accuracy: 0.9385 - val_loss: 0.2886 - val_accuracy: 0.8847\n",
      "Epoch 118/1000\n",
      "10/10 [==============================] - 3s 348ms/step - loss: 0.1762 - accuracy: 0.9307 - val_loss: 0.2809 - val_accuracy: 0.8879\n",
      "Epoch 119/1000\n",
      "10/10 [==============================] - 3s 279ms/step - loss: 0.1643 - accuracy: 0.9359 - val_loss: 0.3184 - val_accuracy: 0.8723\n",
      "Epoch 120/1000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.1540 - accuracy: 0.9455 - val_loss: 0.2741 - val_accuracy: 0.8910\n",
      "Epoch 121/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1522 - accuracy: 0.9463\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.1522 - accuracy: 0.9463 - val_loss: 0.2370 - val_accuracy: 0.8941\n",
      "Epoch 122/1000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.1568 - accuracy: 0.9403 - val_loss: 0.2414 - val_accuracy: 0.9003\n",
      "Epoch 123/1000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.1514 - accuracy: 0.9453 - val_loss: 0.2508 - val_accuracy: 0.8910\n",
      "Epoch 124/1000\n",
      "10/10 [==============================] - 3s 294ms/step - loss: 0.1405 - accuracy: 0.9515 - val_loss: 0.2413 - val_accuracy: 0.8972\n",
      "Epoch 125/1000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.1555 - accuracy: 0.9411 - val_loss: 0.2532 - val_accuracy: 0.8941\n",
      "Epoch 126/1000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.1394 - accuracy: 0.9481 - val_loss: 0.2404 - val_accuracy: 0.8972\n",
      "Epoch 127/1000\n",
      "10/10 [==============================] - 3s 337ms/step - loss: 0.1558 - accuracy: 0.9446 - val_loss: 0.2366 - val_accuracy: 0.9003\n",
      "Epoch 128/1000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.1465 - accuracy: 0.9515 - val_loss: 0.2424 - val_accuracy: 0.9003\n",
      "Epoch 129/1000\n",
      "10/10 [==============================] - 3s 298ms/step - loss: 0.1501 - accuracy: 0.9368 - val_loss: 0.2448 - val_accuracy: 0.9003\n",
      "Epoch 130/1000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.1531 - accuracy: 0.9455 - val_loss: 0.2419 - val_accuracy: 0.9003\n",
      "Epoch 131/1000\n",
      "10/10 [==============================] - 3s 270ms/step - loss: 0.1547 - accuracy: 0.9437 - val_loss: 0.2224 - val_accuracy: 0.9097\n",
      "Epoch 132/1000\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.1370 - accuracy: 0.9463 - val_loss: 0.2212 - val_accuracy: 0.9034\n",
      "Epoch 133/1000\n",
      "10/10 [==============================] - 4s 371ms/step - loss: 0.1484 - accuracy: 0.9461 - val_loss: 0.2257 - val_accuracy: 0.9003\n",
      "Epoch 134/1000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.1511 - accuracy: 0.9472 - val_loss: 0.2322 - val_accuracy: 0.9003\n",
      "Epoch 135/1000\n",
      "10/10 [==============================] - 3s 312ms/step - loss: 0.1426 - accuracy: 0.9472 - val_loss: 0.2293 - val_accuracy: 0.9034\n",
      "Epoch 136/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1501 - accuracy: 0.9463\n",
      "Epoch 00136: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.1501 - accuracy: 0.9463 - val_loss: 0.2372 - val_accuracy: 0.8941\n",
      "Loss:\n",
      "Mean: 0.185259\n",
      "Std: 0.003023\n",
      "Min: 0.182235\n",
      "Max: 0.188282\n",
      "\n",
      "\n",
      "Acc:\n",
      "Mean: 0.909657\n",
      "Std: 0.009346\n",
      "Min: 0.900312\n",
      "Max: 0.919003\n",
      "\n",
      "\n",
      "ROC AUC:\n",
      "Mean: 0.980210\n",
      "Std: 0.001769\n",
      "Min: 0.978441\n",
      "Max: 0.981979\n",
      "\n",
      "\n",
      "mAP:\n",
      "Mean: 0.977894\n",
      "Std: 0.004940\n",
      "Min: 0.972954\n",
      "Max: 0.982835\n",
      "\n",
      "\n",
      "Model: \"resnext\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 75, 75, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_76 (Lambda)              (None, 75, 75, 2)    0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_77 (Lambda)              (None, 75, 75, 1)    0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_4 (GaussianNoise (None, 75, 75, 2)    0           lambda_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_5 (GaussianNoise (None, 75, 75, 1)    0           lambda_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 75, 75, 3)    0           gaussian_noise_4[0][0]           \n",
      "                                                                 gaussian_noise_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 75, 75, 32)   896         concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 75, 75, 32)   128         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 75, 75, 32)   0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 75, 75, 32)   1024        activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 75, 75, 32)   128         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 75, 75, 32)   0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_78 (Lambda)              (None, 75, 75, 8)    0           activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_79 (Lambda)              (None, 75, 75, 8)    0           activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_80 (Lambda)              (None, 75, 75, 8)    0           activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_81 (Lambda)              (None, 75, 75, 8)    0           activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 75, 75, 8)    584         lambda_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 75, 75, 8)    584         lambda_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 75, 75, 8)    584         lambda_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 75, 75, 8)    584         lambda_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 75, 75, 32)   0           conv2d_119[0][0]                 \n",
      "                                                                 conv2d_120[0][0]                 \n",
      "                                                                 conv2d_121[0][0]                 \n",
      "                                                                 conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 75, 75, 32)   128         concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 75, 75, 32)   0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 75, 75, 64)   2112        activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 75, 75, 64)   2112        activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 75, 75, 64)   256         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 75, 75, 64)   256         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 75, 75, 64)   0           batch_normalization_63[0][0]     \n",
      "                                                                 batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 75, 75, 64)   0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 75, 75, 32)   2048        activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 75, 75, 32)   128         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 75, 75, 32)   0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_82 (Lambda)              (None, 75, 75, 8)    0           activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_83 (Lambda)              (None, 75, 75, 8)    0           activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_84 (Lambda)              (None, 75, 75, 8)    0           activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_85 (Lambda)              (None, 75, 75, 8)    0           activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 75, 75, 8)    584         lambda_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 75, 75, 8)    584         lambda_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 75, 75, 8)    584         lambda_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 75, 75, 8)    584         lambda_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 75, 75, 32)   0           conv2d_125[0][0]                 \n",
      "                                                                 conv2d_126[0][0]                 \n",
      "                                                                 conv2d_127[0][0]                 \n",
      "                                                                 conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 75, 75, 32)   128         concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 75, 75, 32)   0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 75, 75, 64)   2112        activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 75, 75, 64)   256         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 75, 75, 64)   0           activation_59[0][0]              \n",
      "                                                                 batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 75, 75, 64)   0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 75, 75, 32)   2048        activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 75, 75, 32)   128         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 75, 75, 32)   0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_86 (Lambda)              (None, 75, 75, 8)    0           activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_87 (Lambda)              (None, 75, 75, 8)    0           activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_88 (Lambda)              (None, 75, 75, 8)    0           activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_89 (Lambda)              (None, 75, 75, 8)    0           activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 75, 75, 8)    584         lambda_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 75, 75, 8)    584         lambda_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 75, 75, 8)    584         lambda_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 75, 75, 8)    584         lambda_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 75, 75, 32)   0           conv2d_131[0][0]                 \n",
      "                                                                 conv2d_132[0][0]                 \n",
      "                                                                 conv2d_133[0][0]                 \n",
      "                                                                 conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 75, 75, 32)   128         concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 75, 75, 32)   0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 75, 75, 64)   2112        activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 75, 75, 64)   256         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 75, 75, 64)   0           activation_62[0][0]              \n",
      "                                                                 batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 75, 75, 64)   0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 75, 75, 64)   4096        activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 75, 75, 64)   256         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 75, 75, 64)   0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_90 (Lambda)              (None, 75, 75, 16)   0           activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_91 (Lambda)              (None, 75, 75, 16)   0           activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_92 (Lambda)              (None, 75, 75, 16)   0           activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_93 (Lambda)              (None, 75, 75, 16)   0           activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 38, 38, 16)   2320        lambda_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 38, 38, 16)   2320        lambda_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 38, 38, 16)   2320        lambda_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 38, 38, 16)   2320        lambda_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 38, 38, 64)   0           conv2d_138[0][0]                 \n",
      "                                                                 conv2d_139[0][0]                 \n",
      "                                                                 conv2d_140[0][0]                 \n",
      "                                                                 conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 38, 38, 64)   256         concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 38, 38, 64)   0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 38, 38, 128)  8320        activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 38, 38, 128)  8320        activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 38, 38, 128)  512         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 38, 38, 128)  512         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 38, 38, 128)  0           batch_normalization_73[0][0]     \n",
      "                                                                 batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 38, 38, 128)  0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 38, 38, 64)   8192        activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 38, 38, 64)   256         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 38, 38, 64)   0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_94 (Lambda)              (None, 38, 38, 16)   0           activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_95 (Lambda)              (None, 38, 38, 16)   0           activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_96 (Lambda)              (None, 38, 38, 16)   0           activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_97 (Lambda)              (None, 38, 38, 16)   0           activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 38, 38, 16)   2320        lambda_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 38, 38, 16)   2320        lambda_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 38, 38, 16)   2320        lambda_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 38, 38, 16)   2320        lambda_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 38, 38, 64)   0           conv2d_144[0][0]                 \n",
      "                                                                 conv2d_145[0][0]                 \n",
      "                                                                 conv2d_146[0][0]                 \n",
      "                                                                 conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 38, 38, 64)   256         concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 38, 38, 64)   0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 38, 38, 128)  8320        activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 38, 38, 128)  512         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 38, 38, 128)  0           activation_68[0][0]              \n",
      "                                                                 batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 38, 38, 128)  0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 38, 38, 64)   8192        activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 38, 38, 64)   256         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 38, 38, 64)   0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_98 (Lambda)              (None, 38, 38, 16)   0           activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_99 (Lambda)              (None, 38, 38, 16)   0           activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_100 (Lambda)             (None, 38, 38, 16)   0           activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_101 (Lambda)             (None, 38, 38, 16)   0           activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 38, 38, 16)   2320        lambda_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 38, 38, 16)   2320        lambda_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 38, 38, 16)   2320        lambda_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 38, 38, 16)   2320        lambda_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 38, 38, 64)   0           conv2d_150[0][0]                 \n",
      "                                                                 conv2d_151[0][0]                 \n",
      "                                                                 conv2d_152[0][0]                 \n",
      "                                                                 conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 38, 38, 64)   256         concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 38, 38, 64)   0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 38, 38, 128)  8320        activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 38, 38, 128)  512         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 38, 38, 128)  0           activation_71[0][0]              \n",
      "                                                                 batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 38, 38, 128)  0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 38, 38, 128)  16384       activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 38, 38, 128)  512         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 38, 38, 128)  0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_102 (Lambda)             (None, 38, 38, 32)   0           activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_103 (Lambda)             (None, 38, 38, 32)   0           activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_104 (Lambda)             (None, 38, 38, 32)   0           activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_105 (Lambda)             (None, 38, 38, 32)   0           activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 19, 19, 32)   9248        lambda_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 19, 19, 32)   9248        lambda_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 19, 19, 32)   9248        lambda_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 19, 19, 32)   9248        lambda_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 19, 19, 128)  0           conv2d_157[0][0]                 \n",
      "                                                                 conv2d_158[0][0]                 \n",
      "                                                                 conv2d_159[0][0]                 \n",
      "                                                                 conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 19, 19, 128)  512         concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 19, 19, 128)  0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 19, 19, 256)  33024       activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 19, 19, 256)  33024       activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 19, 19, 256)  1024        conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 19, 19, 256)  1024        conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 19, 19, 256)  0           batch_normalization_83[0][0]     \n",
      "                                                                 batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 19, 19, 256)  0           add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 19, 19, 128)  32768       activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 19, 19, 128)  512         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 19, 19, 128)  0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_106 (Lambda)             (None, 19, 19, 32)   0           activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_107 (Lambda)             (None, 19, 19, 32)   0           activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_108 (Lambda)             (None, 19, 19, 32)   0           activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_109 (Lambda)             (None, 19, 19, 32)   0           activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 19, 19, 32)   9248        lambda_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 19, 19, 32)   9248        lambda_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 19, 19, 32)   9248        lambda_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 19, 19, 32)   9248        lambda_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 19, 19, 128)  0           conv2d_163[0][0]                 \n",
      "                                                                 conv2d_164[0][0]                 \n",
      "                                                                 conv2d_165[0][0]                 \n",
      "                                                                 conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 19, 19, 128)  512         concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 19, 19, 128)  0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 19, 19, 256)  33024       activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 19, 19, 256)  1024        conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 19, 19, 256)  0           activation_77[0][0]              \n",
      "                                                                 batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 19, 19, 256)  0           add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 19, 19, 128)  32768       activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 19, 19, 128)  512         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 19, 19, 128)  0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_110 (Lambda)             (None, 19, 19, 32)   0           activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_111 (Lambda)             (None, 19, 19, 32)   0           activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_112 (Lambda)             (None, 19, 19, 32)   0           activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_113 (Lambda)             (None, 19, 19, 32)   0           activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 19, 19, 32)   9248        lambda_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 19, 19, 32)   9248        lambda_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 19, 19, 32)   9248        lambda_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 19, 19, 32)   9248        lambda_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 19, 19, 128)  0           conv2d_169[0][0]                 \n",
      "                                                                 conv2d_170[0][0]                 \n",
      "                                                                 conv2d_171[0][0]                 \n",
      "                                                                 conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 19, 19, 128)  512         concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 19, 19, 128)  0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 19, 19, 256)  33024       activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 19, 19, 256)  1024        conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 19, 19, 256)  0           activation_80[0][0]              \n",
      "                                                                 batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 19, 19, 256)  0           add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 256)          0           activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            514         global_average_pooling2d_2[0][0] \n",
      "==================================================================================================\n",
      "Total params: 441,250\n",
      "Trainable params: 434,914\n",
      "Non-trainable params: 6,336\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/1000\n",
      "10/10 [==============================] - 6s 584ms/step - loss: 1.1920 - accuracy: 0.5463 - val_loss: 7.4058 - val_accuracy: 0.5171\n",
      "Epoch 2/1000\n",
      "10/10 [==============================] - 3s 314ms/step - loss: 0.6638 - accuracy: 0.6329 - val_loss: 7.4058 - val_accuracy: 0.5171\n",
      "Epoch 3/1000\n",
      "10/10 [==============================] - 3s 278ms/step - loss: 0.6153 - accuracy: 0.6424 - val_loss: 7.4058 - val_accuracy: 0.5171\n",
      "Epoch 4/1000\n",
      "10/10 [==============================] - 3s 293ms/step - loss: 0.7511 - accuracy: 0.6043 - val_loss: 7.4058 - val_accuracy: 0.5171\n",
      "Epoch 5/1000\n",
      "10/10 [==============================] - 3s 293ms/step - loss: 0.5655 - accuracy: 0.7160 - val_loss: 7.4058 - val_accuracy: 0.5171\n",
      "Epoch 6/1000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 0.5954 - accuracy: 0.6935 - val_loss: 7.4058 - val_accuracy: 0.5171\n",
      "Epoch 7/1000\n",
      "10/10 [==============================] - 3s 342ms/step - loss: 0.5520 - accuracy: 0.7134 - val_loss: 7.4058 - val_accuracy: 0.5171\n",
      "Epoch 8/1000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 0.5224 - accuracy: 0.7359 - val_loss: 7.4058 - val_accuracy: 0.5171\n",
      "Epoch 9/1000\n",
      "10/10 [==============================] - 3s 282ms/step - loss: 0.4923 - accuracy: 0.7524 - val_loss: 7.4058 - val_accuracy: 0.5171\n",
      "Epoch 10/1000\n",
      "10/10 [==============================] - 3s 314ms/step - loss: 0.5219 - accuracy: 0.7299 - val_loss: 7.4058 - val_accuracy: 0.5171\n",
      "Epoch 11/1000\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.4610 - accuracy: 0.7593 - val_loss: 7.4058 - val_accuracy: 0.5171\n",
      "Epoch 12/1000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.5105 - accuracy: 0.7550 - val_loss: 7.4058 - val_accuracy: 0.5171\n",
      "Epoch 13/1000\n",
      "10/10 [==============================] - 3s 332ms/step - loss: 0.4222 - accuracy: 0.8052 - val_loss: 7.4058 - val_accuracy: 0.5171\n",
      "Epoch 14/1000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.4152 - accuracy: 0.8225 - val_loss: 7.4058 - val_accuracy: 0.5171\n",
      "Epoch 15/1000\n",
      "10/10 [==============================] - 4s 368ms/step - loss: 0.4132 - accuracy: 0.8061 - val_loss: 7.4058 - val_accuracy: 0.5171\n",
      "Epoch 16/1000\n",
      "10/10 [==============================] - 4s 381ms/step - loss: 0.4865 - accuracy: 0.7965 - val_loss: 4.4562 - val_accuracy: 0.5327\n",
      "Epoch 17/1000\n",
      "10/10 [==============================] - 3s 281ms/step - loss: 0.4249 - accuracy: 0.7974 - val_loss: 5.8041 - val_accuracy: 0.5171\n",
      "Epoch 18/1000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.3949 - accuracy: 0.8104 - val_loss: 1.7569 - val_accuracy: 0.7445\n",
      "Epoch 19/1000\n",
      "10/10 [==============================] - 3s 342ms/step - loss: 0.4300 - accuracy: 0.7991 - val_loss: 1.5788 - val_accuracy: 0.6293\n",
      "Epoch 20/1000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.3767 - accuracy: 0.8216 - val_loss: 0.7535 - val_accuracy: 0.8069\n",
      "Epoch 21/1000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.3576 - accuracy: 0.8442 - val_loss: 0.5824 - val_accuracy: 0.8318\n",
      "Epoch 22/1000\n",
      "10/10 [==============================] - 3s 296ms/step - loss: 0.3807 - accuracy: 0.8225 - val_loss: 0.7478 - val_accuracy: 0.7819\n",
      "Epoch 23/1000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3593 - accuracy: 0.8364 - val_loss: 0.6403 - val_accuracy: 0.8193\n",
      "Epoch 24/1000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.3520 - accuracy: 0.8468 - val_loss: 0.9265 - val_accuracy: 0.8037\n",
      "Epoch 25/1000\n",
      "10/10 [==============================] - 4s 353ms/step - loss: 0.3186 - accuracy: 0.8656 - val_loss: 1.6374 - val_accuracy: 0.7757\n",
      "Epoch 26/1000\n",
      "10/10 [==============================] - 3s 266ms/step - loss: 0.3032 - accuracy: 0.8710 - val_loss: 4.1426 - val_accuracy: 0.6822\n",
      "Epoch 27/1000\n",
      "10/10 [==============================] - 3s 276ms/step - loss: 0.3934 - accuracy: 0.8147 - val_loss: 3.1298 - val_accuracy: 0.7040\n",
      "Epoch 28/1000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.2973 - accuracy: 0.8641 - val_loss: 3.9557 - val_accuracy: 0.6760\n",
      "Epoch 29/1000\n",
      "10/10 [==============================] - 3s 278ms/step - loss: 0.3937 - accuracy: 0.8381 - val_loss: 2.7650 - val_accuracy: 0.7695\n",
      "Epoch 30/1000\n",
      "10/10 [==============================] - 3s 342ms/step - loss: 0.3032 - accuracy: 0.8606 - val_loss: 1.0906 - val_accuracy: 0.8162\n",
      "Epoch 31/1000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.2941 - accuracy: 0.8615 - val_loss: 1.2951 - val_accuracy: 0.8131\n",
      "Epoch 32/1000\n",
      "10/10 [==============================] - 4s 374ms/step - loss: 0.3144 - accuracy: 0.8563 - val_loss: 0.5771 - val_accuracy: 0.8349\n",
      "Epoch 33/1000\n",
      "10/10 [==============================] - 4s 351ms/step - loss: 0.4552 - accuracy: 0.8511 - val_loss: 0.4909 - val_accuracy: 0.8474\n",
      "Epoch 34/1000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.2744 - accuracy: 0.8766 - val_loss: 0.5448 - val_accuracy: 0.8255\n",
      "Epoch 35/1000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.3076 - accuracy: 0.8606 - val_loss: 0.6040 - val_accuracy: 0.8224\n",
      "Epoch 36/1000\n",
      "10/10 [==============================] - 3s 275ms/step - loss: 0.2691 - accuracy: 0.8866 - val_loss: 0.5594 - val_accuracy: 0.8318\n",
      "Epoch 37/1000\n",
      "10/10 [==============================] - 3s 275ms/step - loss: 0.2661 - accuracy: 0.8866 - val_loss: 0.5913 - val_accuracy: 0.8131\n",
      "Epoch 38/1000\n",
      "10/10 [==============================] - 3s 297ms/step - loss: 0.2472 - accuracy: 0.8883 - val_loss: 0.9187 - val_accuracy: 0.7539\n",
      "Epoch 39/1000\n",
      "10/10 [==============================] - 3s 299ms/step - loss: 0.2933 - accuracy: 0.8649 - val_loss: 3.2909 - val_accuracy: 0.7009\n",
      "Epoch 40/1000\n",
      "10/10 [==============================] - 3s 276ms/step - loss: 0.2439 - accuracy: 0.8892 - val_loss: 0.6113 - val_accuracy: 0.8567\n",
      "Epoch 41/1000\n",
      "10/10 [==============================] - 3s 293ms/step - loss: 0.2397 - accuracy: 0.8961 - val_loss: 3.4551 - val_accuracy: 0.6947\n",
      "Epoch 42/1000\n",
      "10/10 [==============================] - 3s 338ms/step - loss: 0.2844 - accuracy: 0.8695 - val_loss: 2.3570 - val_accuracy: 0.7477\n",
      "Epoch 43/1000\n",
      "10/10 [==============================] - 3s 276ms/step - loss: 0.2878 - accuracy: 0.8658 - val_loss: 2.6772 - val_accuracy: 0.7414\n",
      "Epoch 44/1000\n",
      "10/10 [==============================] - 4s 352ms/step - loss: 0.3964 - accuracy: 0.8165 - val_loss: 6.6413 - val_accuracy: 0.5670\n",
      "Epoch 45/1000\n",
      "10/10 [==============================] - 3s 275ms/step - loss: 0.2884 - accuracy: 0.8693 - val_loss: 3.1694 - val_accuracy: 0.7103\n",
      "Epoch 46/1000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.2913 - accuracy: 0.8745 - val_loss: 0.3771 - val_accuracy: 0.8660\n",
      "Epoch 47/1000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.2827 - accuracy: 0.8667 - val_loss: 0.7302 - val_accuracy: 0.7601\n",
      "Epoch 48/1000\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 0.2368 - accuracy: 0.8857 - val_loss: 0.2565 - val_accuracy: 0.8910\n",
      "Epoch 49/1000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.2974 - accuracy: 0.8554 - val_loss: 0.9574 - val_accuracy: 0.7664\n",
      "Epoch 50/1000\n",
      "10/10 [==============================] - 3s 282ms/step - loss: 0.2912 - accuracy: 0.8719 - val_loss: 0.7664 - val_accuracy: 0.7788\n",
      "Epoch 51/1000\n",
      "10/10 [==============================] - 4s 355ms/step - loss: 0.2605 - accuracy: 0.8805 - val_loss: 0.2302 - val_accuracy: 0.9159\n",
      "Epoch 52/1000\n",
      "10/10 [==============================] - 3s 275ms/step - loss: 0.2658 - accuracy: 0.8814 - val_loss: 0.2804 - val_accuracy: 0.8785\n",
      "Epoch 53/1000\n",
      "10/10 [==============================] - 3s 267ms/step - loss: 0.2276 - accuracy: 0.9039 - val_loss: 0.5129 - val_accuracy: 0.8474\n",
      "Epoch 54/1000\n",
      "10/10 [==============================] - 3s 326ms/step - loss: 0.2539 - accuracy: 0.8984 - val_loss: 1.5715 - val_accuracy: 0.7227\n",
      "Epoch 55/1000\n",
      "10/10 [==============================] - 3s 299ms/step - loss: 0.2449 - accuracy: 0.8944 - val_loss: 0.7351 - val_accuracy: 0.7570\n",
      "Epoch 56/1000\n",
      "10/10 [==============================] - 3s 274ms/step - loss: 0.2722 - accuracy: 0.8831 - val_loss: 0.4194 - val_accuracy: 0.8723\n",
      "Epoch 57/1000\n",
      "10/10 [==============================] - 3s 298ms/step - loss: 0.2115 - accuracy: 0.9143 - val_loss: 0.3703 - val_accuracy: 0.8847\n",
      "Epoch 58/1000\n",
      "10/10 [==============================] - 3s 269ms/step - loss: 0.2526 - accuracy: 0.8918 - val_loss: 0.6665 - val_accuracy: 0.8660\n",
      "Epoch 59/1000\n",
      "10/10 [==============================] - 3s 276ms/step - loss: 0.2970 - accuracy: 0.8831 - val_loss: 1.2275 - val_accuracy: 0.7165\n",
      "Epoch 60/1000\n",
      "10/10 [==============================] - 3s 295ms/step - loss: 0.2366 - accuracy: 0.8935 - val_loss: 0.6873 - val_accuracy: 0.8069\n",
      "Epoch 61/1000\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 0.2324 - accuracy: 0.9004 - val_loss: 1.7635 - val_accuracy: 0.7445\n",
      "Epoch 62/1000\n",
      "10/10 [==============================] - 3s 274ms/step - loss: 0.3105 - accuracy: 0.8580 - val_loss: 0.5476 - val_accuracy: 0.8100\n",
      "Epoch 63/1000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.2824 - accuracy: 0.8762 - val_loss: 1.1402 - val_accuracy: 0.8037\n",
      "Epoch 64/1000\n",
      "10/10 [==============================] - 3s 313ms/step - loss: 0.2201 - accuracy: 0.9109 - val_loss: 0.3984 - val_accuracy: 0.8847\n",
      "Epoch 65/1000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.2278 - accuracy: 0.9004 - val_loss: 0.4143 - val_accuracy: 0.8785\n",
      "Epoch 66/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3319 - accuracy: 0.8528\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.3319 - accuracy: 0.8528 - val_loss: 0.6964 - val_accuracy: 0.8287\n",
      "Epoch 67/1000\n",
      "10/10 [==============================] - 3s 272ms/step - loss: 0.2189 - accuracy: 0.9100 - val_loss: 0.3603 - val_accuracy: 0.8910\n",
      "Epoch 68/1000\n",
      "10/10 [==============================] - 3s 278ms/step - loss: 0.2331 - accuracy: 0.9108 - val_loss: 0.2363 - val_accuracy: 0.9159\n",
      "Epoch 69/1000\n",
      "10/10 [==============================] - 3s 276ms/step - loss: 0.2348 - accuracy: 0.8978 - val_loss: 0.2473 - val_accuracy: 0.9003\n",
      "Epoch 70/1000\n",
      "10/10 [==============================] - 3s 349ms/step - loss: 0.2308 - accuracy: 0.8970 - val_loss: 0.2572 - val_accuracy: 0.8879\n",
      "Epoch 71/1000\n",
      "10/10 [==============================] - 3s 283ms/step - loss: 0.2218 - accuracy: 0.9091 - val_loss: 0.2354 - val_accuracy: 0.9128\n",
      "Epoch 72/1000\n",
      "10/10 [==============================] - 3s 273ms/step - loss: 0.2047 - accuracy: 0.9212 - val_loss: 0.2480 - val_accuracy: 0.9097\n",
      "Epoch 73/1000\n",
      "10/10 [==============================] - 3s 318ms/step - loss: 0.2086 - accuracy: 0.9143 - val_loss: 0.2621 - val_accuracy: 0.8941\n",
      "Epoch 74/1000\n",
      "10/10 [==============================] - 3s 274ms/step - loss: 0.2048 - accuracy: 0.9238 - val_loss: 0.2444 - val_accuracy: 0.9003\n",
      "Epoch 75/1000\n",
      "10/10 [==============================] - 3s 277ms/step - loss: 0.2022 - accuracy: 0.9143 - val_loss: 0.2470 - val_accuracy: 0.9190\n",
      "Epoch 76/1000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.1959 - accuracy: 0.9160 - val_loss: 0.2581 - val_accuracy: 0.8941\n",
      "Epoch 77/1000\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.1970 - accuracy: 0.9211 - val_loss: 0.2737 - val_accuracy: 0.8879\n",
      "Epoch 78/1000\n",
      "10/10 [==============================] - 3s 274ms/step - loss: 0.1984 - accuracy: 0.9177 - val_loss: 0.2595 - val_accuracy: 0.8910\n",
      "Epoch 79/1000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.2006 - accuracy: 0.9203 - val_loss: 0.2363 - val_accuracy: 0.9283\n",
      "Epoch 80/1000\n",
      "10/10 [==============================] - 4s 365ms/step - loss: 0.2120 - accuracy: 0.9108 - val_loss: 0.2644 - val_accuracy: 0.8972\n",
      "Epoch 81/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1907 - accuracy: 0.9242\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.1907 - accuracy: 0.9242 - val_loss: 0.2726 - val_accuracy: 0.8941\n",
      "Epoch 82/1000\n",
      "10/10 [==============================] - 3s 280ms/step - loss: 0.1792 - accuracy: 0.9359 - val_loss: 0.2661 - val_accuracy: 0.8910\n",
      "Epoch 83/1000\n",
      "10/10 [==============================] - 4s 385ms/step - loss: 0.1858 - accuracy: 0.9325 - val_loss: 0.2697 - val_accuracy: 0.9034\n",
      "Epoch 84/1000\n",
      "10/10 [==============================] - 3s 280ms/step - loss: 0.2018 - accuracy: 0.9186 - val_loss: 0.2575 - val_accuracy: 0.8972\n",
      "Epoch 85/1000\n",
      "10/10 [==============================] - 3s 281ms/step - loss: 0.1939 - accuracy: 0.9299 - val_loss: 0.2478 - val_accuracy: 0.9034\n",
      "Epoch 86/1000\n",
      "10/10 [==============================] - 3s 292ms/step - loss: 0.1867 - accuracy: 0.9290 - val_loss: 0.2400 - val_accuracy: 0.9159\n",
      "Epoch 87/1000\n",
      "10/10 [==============================] - 3s 274ms/step - loss: 0.1818 - accuracy: 0.9273 - val_loss: 0.2322 - val_accuracy: 0.9252\n",
      "Epoch 88/1000\n",
      "10/10 [==============================] - 3s 262ms/step - loss: 0.1742 - accuracy: 0.9359 - val_loss: 0.2322 - val_accuracy: 0.9221\n",
      "Epoch 89/1000\n",
      "10/10 [==============================] - 3s 295ms/step - loss: 0.1905 - accuracy: 0.9316 - val_loss: 0.2380 - val_accuracy: 0.9190\n",
      "Epoch 90/1000\n",
      "10/10 [==============================] - 3s 316ms/step - loss: 0.1813 - accuracy: 0.9325 - val_loss: 0.2369 - val_accuracy: 0.9159\n",
      "Epoch 91/1000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.1866 - accuracy: 0.9242 - val_loss: 0.2406 - val_accuracy: 0.9065\n",
      "Epoch 92/1000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.1779 - accuracy: 0.9316 - val_loss: 0.2447 - val_accuracy: 0.8972\n",
      "Epoch 93/1000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 0.1901 - accuracy: 0.9177 - val_loss: 0.2496 - val_accuracy: 0.8941\n",
      "Epoch 94/1000\n",
      "10/10 [==============================] - 3s 277ms/step - loss: 0.1850 - accuracy: 0.9273 - val_loss: 0.2413 - val_accuracy: 0.9003\n",
      "Epoch 95/1000\n",
      "10/10 [==============================] - 3s 274ms/step - loss: 0.1797 - accuracy: 0.9299 - val_loss: 0.2475 - val_accuracy: 0.8941\n",
      "Epoch 96/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1886 - accuracy: 0.9255\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.1886 - accuracy: 0.9255 - val_loss: 0.2666 - val_accuracy: 0.8785\n",
      "Loss:\n",
      "Mean: 0.200231\n",
      "Std: 0.021318\n",
      "Min: 0.182235\n",
      "Max: 0.230176\n",
      "\n",
      "\n",
      "Acc:\n",
      "Mean: 0.911734\n",
      "Std: 0.008177\n",
      "Min: 0.900312\n",
      "Max: 0.919003\n",
      "\n",
      "\n",
      "ROC AUC:\n",
      "Mean: 0.976443\n",
      "Std: 0.005520\n",
      "Min: 0.968908\n",
      "Max: 0.981979\n",
      "\n",
      "\n",
      "mAP:\n",
      "Mean: 0.972277\n",
      "Std: 0.008909\n",
      "Min: 0.961043\n",
      "Max: 0.982835\n",
      "\n",
      "\n",
      "Model: \"resnext\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 75, 75, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_114 (Lambda)             (None, 75, 75, 2)    0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_115 (Lambda)             (None, 75, 75, 1)    0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_6 (GaussianNoise (None, 75, 75, 2)    0           lambda_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_7 (GaussianNoise (None, 75, 75, 1)    0           lambda_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 75, 75, 3)    0           gaussian_noise_6[0][0]           \n",
      "                                                                 gaussian_noise_7[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 75, 75, 32)   896         concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 75, 75, 32)   128         conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 75, 75, 32)   0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 75, 75, 32)   1024        activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 75, 75, 32)   128         conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 75, 75, 32)   0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_116 (Lambda)             (None, 75, 75, 8)    0           activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_117 (Lambda)             (None, 75, 75, 8)    0           activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_118 (Lambda)             (None, 75, 75, 8)    0           activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_119 (Lambda)             (None, 75, 75, 8)    0           activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 75, 75, 8)    584         lambda_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 75, 75, 8)    584         lambda_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 75, 75, 8)    584         lambda_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 75, 75, 8)    584         lambda_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 75, 75, 32)   0           conv2d_177[0][0]                 \n",
      "                                                                 conv2d_178[0][0]                 \n",
      "                                                                 conv2d_179[0][0]                 \n",
      "                                                                 conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 75, 75, 32)   128         concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 75, 75, 32)   0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 75, 75, 64)   2112        activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 75, 75, 64)   2112        activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 75, 75, 64)   256         conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 75, 75, 64)   256         conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 75, 75, 64)   0           batch_normalization_94[0][0]     \n",
      "                                                                 batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 75, 75, 64)   0           add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 75, 75, 32)   2048        activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 75, 75, 32)   128         conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 75, 75, 32)   0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_120 (Lambda)             (None, 75, 75, 8)    0           activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_121 (Lambda)             (None, 75, 75, 8)    0           activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_122 (Lambda)             (None, 75, 75, 8)    0           activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_123 (Lambda)             (None, 75, 75, 8)    0           activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 75, 75, 8)    584         lambda_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 75, 75, 8)    584         lambda_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 75, 75, 8)    584         lambda_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 75, 75, 8)    584         lambda_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 75, 75, 32)   0           conv2d_183[0][0]                 \n",
      "                                                                 conv2d_184[0][0]                 \n",
      "                                                                 conv2d_185[0][0]                 \n",
      "                                                                 conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 75, 75, 32)   128         concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 75, 75, 32)   0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 75, 75, 64)   2112        activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 75, 75, 64)   256         conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 75, 75, 64)   0           activation_87[0][0]              \n",
      "                                                                 batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 75, 75, 64)   0           add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 75, 75, 32)   2048        activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 75, 75, 32)   128         conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 75, 75, 32)   0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_124 (Lambda)             (None, 75, 75, 8)    0           activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_125 (Lambda)             (None, 75, 75, 8)    0           activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_126 (Lambda)             (None, 75, 75, 8)    0           activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_127 (Lambda)             (None, 75, 75, 8)    0           activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 75, 75, 8)    584         lambda_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 75, 75, 8)    584         lambda_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 75, 75, 8)    584         lambda_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 75, 75, 8)    584         lambda_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 75, 75, 32)   0           conv2d_189[0][0]                 \n",
      "                                                                 conv2d_190[0][0]                 \n",
      "                                                                 conv2d_191[0][0]                 \n",
      "                                                                 conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 75, 75, 32)   128         concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 75, 75, 32)   0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 75, 75, 64)   2112        activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 75, 75, 64)   256         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 75, 75, 64)   0           activation_90[0][0]              \n",
      "                                                                 batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 75, 75, 64)   0           add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 75, 75, 64)   4096        activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 75, 75, 64)   256         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 75, 75, 64)   0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_128 (Lambda)             (None, 75, 75, 16)   0           activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_129 (Lambda)             (None, 75, 75, 16)   0           activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_130 (Lambda)             (None, 75, 75, 16)   0           activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_131 (Lambda)             (None, 75, 75, 16)   0           activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 38, 38, 16)   2320        lambda_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 38, 38, 16)   2320        lambda_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 38, 38, 16)   2320        lambda_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 38, 38, 16)   2320        lambda_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 38, 38, 64)   0           conv2d_196[0][0]                 \n",
      "                                                                 conv2d_197[0][0]                 \n",
      "                                                                 conv2d_198[0][0]                 \n",
      "                                                                 conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 38, 38, 64)   256         concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 38, 38, 64)   0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 38, 38, 128)  8320        activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 38, 38, 128)  8320        activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 38, 38, 128)  512         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 38, 38, 128)  512         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 38, 38, 128)  0           batch_normalization_104[0][0]    \n",
      "                                                                 batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 38, 38, 128)  0           add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 38, 38, 64)   8192        activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 38, 38, 64)   256         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 38, 38, 64)   0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_132 (Lambda)             (None, 38, 38, 16)   0           activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_133 (Lambda)             (None, 38, 38, 16)   0           activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_134 (Lambda)             (None, 38, 38, 16)   0           activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_135 (Lambda)             (None, 38, 38, 16)   0           activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 38, 38, 16)   2320        lambda_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 38, 38, 16)   2320        lambda_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 38, 38, 16)   2320        lambda_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 38, 38, 16)   2320        lambda_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 38, 38, 64)   0           conv2d_202[0][0]                 \n",
      "                                                                 conv2d_203[0][0]                 \n",
      "                                                                 conv2d_204[0][0]                 \n",
      "                                                                 conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 38, 38, 64)   256         concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 38, 38, 64)   0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 38, 38, 128)  8320        activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 38, 38, 128)  512         conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 38, 38, 128)  0           activation_96[0][0]              \n",
      "                                                                 batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 38, 38, 128)  0           add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 38, 38, 64)   8192        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 38, 38, 64)   256         conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 38, 38, 64)   0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_136 (Lambda)             (None, 38, 38, 16)   0           activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_137 (Lambda)             (None, 38, 38, 16)   0           activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_138 (Lambda)             (None, 38, 38, 16)   0           activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_139 (Lambda)             (None, 38, 38, 16)   0           activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 38, 38, 16)   2320        lambda_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 38, 38, 16)   2320        lambda_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 38, 38, 16)   2320        lambda_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 38, 38, 16)   2320        lambda_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 38, 38, 64)   0           conv2d_208[0][0]                 \n",
      "                                                                 conv2d_209[0][0]                 \n",
      "                                                                 conv2d_210[0][0]                 \n",
      "                                                                 conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 38, 38, 64)   256         concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 38, 38, 64)   0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 38, 38, 128)  8320        activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 38, 38, 128)  512         conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 38, 38, 128)  0           activation_99[0][0]              \n",
      "                                                                 batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 38, 38, 128)  0           add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 38, 38, 128)  16384       activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 38, 38, 128)  512         conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 38, 38, 128)  0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_140 (Lambda)             (None, 38, 38, 32)   0           activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_141 (Lambda)             (None, 38, 38, 32)   0           activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_142 (Lambda)             (None, 38, 38, 32)   0           activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_143 (Lambda)             (None, 38, 38, 32)   0           activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 19, 19, 32)   9248        lambda_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 19, 19, 32)   9248        lambda_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 19, 19, 32)   9248        lambda_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 19, 19, 32)   9248        lambda_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)    (None, 19, 19, 128)  0           conv2d_215[0][0]                 \n",
      "                                                                 conv2d_216[0][0]                 \n",
      "                                                                 conv2d_217[0][0]                 \n",
      "                                                                 conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 19, 19, 128)  512         concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 19, 19, 128)  0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 19, 19, 256)  33024       activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 19, 19, 256)  33024       activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 19, 19, 256)  1024        conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 19, 19, 256)  1024        conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 19, 19, 256)  0           batch_normalization_114[0][0]    \n",
      "                                                                 batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 19, 19, 256)  0           add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, 19, 19, 128)  32768       activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 19, 19, 128)  512         conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 19, 19, 128)  0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_144 (Lambda)             (None, 19, 19, 32)   0           activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_145 (Lambda)             (None, 19, 19, 32)   0           activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_146 (Lambda)             (None, 19, 19, 32)   0           activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_147 (Lambda)             (None, 19, 19, 32)   0           activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 19, 19, 32)   9248        lambda_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 19, 19, 32)   9248        lambda_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 19, 19, 32)   9248        lambda_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 19, 19, 32)   9248        lambda_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)    (None, 19, 19, 128)  0           conv2d_221[0][0]                 \n",
      "                                                                 conv2d_222[0][0]                 \n",
      "                                                                 conv2d_223[0][0]                 \n",
      "                                                                 conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 19, 19, 128)  512         concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 19, 19, 128)  0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 19, 19, 256)  33024       activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 19, 19, 256)  1024        conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, 19, 19, 256)  0           activation_105[0][0]             \n",
      "                                                                 batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 19, 19, 256)  0           add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 19, 19, 128)  32768       activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 19, 19, 128)  512         conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 19, 19, 128)  0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_148 (Lambda)             (None, 19, 19, 32)   0           activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_149 (Lambda)             (None, 19, 19, 32)   0           activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_150 (Lambda)             (None, 19, 19, 32)   0           activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_151 (Lambda)             (None, 19, 19, 32)   0           activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 19, 19, 32)   9248        lambda_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 19, 19, 32)   9248        lambda_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, 19, 19, 32)   9248        lambda_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)             (None, 19, 19, 32)   9248        lambda_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 19, 19, 128)  0           conv2d_227[0][0]                 \n",
      "                                                                 conv2d_228[0][0]                 \n",
      "                                                                 conv2d_229[0][0]                 \n",
      "                                                                 conv2d_230[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 19, 19, 128)  512         concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 19, 19, 128)  0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, 19, 19, 256)  33024       activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 19, 19, 256)  1024        conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_35 (Add)                    (None, 19, 19, 256)  0           activation_108[0][0]             \n",
      "                                                                 batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 19, 19, 256)  0           add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 256)          0           activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            514         global_average_pooling2d_3[0][0] \n",
      "==================================================================================================\n",
      "Total params: 441,250\n",
      "Trainable params: 434,914\n",
      "Non-trainable params: 6,336\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/1000\n",
      "10/10 [==============================] - 5s 549ms/step - loss: 1.1203 - accuracy: 0.5377 - val_loss: 7.4535 - val_accuracy: 0.5140\n",
      "Epoch 2/1000\n",
      "10/10 [==============================] - 3s 274ms/step - loss: 0.7123 - accuracy: 0.6061 - val_loss: 7.4535 - val_accuracy: 0.5140\n",
      "Epoch 3/1000\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.5640 - accuracy: 0.7008 - val_loss: 7.4535 - val_accuracy: 0.5140\n",
      "Epoch 4/1000\n",
      "10/10 [==============================] - 4s 365ms/step - loss: 0.6089 - accuracy: 0.6753 - val_loss: 7.4535 - val_accuracy: 0.5140\n",
      "Epoch 5/1000\n",
      "10/10 [==============================] - 3s 262ms/step - loss: 0.5389 - accuracy: 0.7039 - val_loss: 7.4535 - val_accuracy: 0.5140\n",
      "Epoch 6/1000\n",
      "10/10 [==============================] - 3s 300ms/step - loss: 0.6408 - accuracy: 0.6779 - val_loss: 7.4535 - val_accuracy: 0.5140\n",
      "Epoch 7/1000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.5292 - accuracy: 0.7264 - val_loss: 7.4535 - val_accuracy: 0.5140\n",
      "Epoch 8/1000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5077 - accuracy: 0.7242 - val_loss: 7.4535 - val_accuracy: 0.5140\n",
      "Epoch 9/1000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4891 - accuracy: 0.7203 - val_loss: 7.4535 - val_accuracy: 0.5140\n",
      "Epoch 10/1000\n",
      "10/10 [==============================] - 3s 341ms/step - loss: 0.5137 - accuracy: 0.7186 - val_loss: 7.4535 - val_accuracy: 0.5140\n",
      "Epoch 11/1000\n",
      "10/10 [==============================] - 3s 293ms/step - loss: 0.4936 - accuracy: 0.7429 - val_loss: 7.4535 - val_accuracy: 0.5140\n",
      "Epoch 12/1000\n",
      "10/10 [==============================] - 3s 313ms/step - loss: 0.4360 - accuracy: 0.7948 - val_loss: 7.3668 - val_accuracy: 0.5140\n",
      "Epoch 13/1000\n",
      "10/10 [==============================] - 3s 280ms/step - loss: 0.5426 - accuracy: 0.7662 - val_loss: 7.4535 - val_accuracy: 0.5140\n",
      "Epoch 14/1000\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 0.3817 - accuracy: 0.8416 - val_loss: 7.1773 - val_accuracy: 0.5171\n",
      "Epoch 15/1000\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 0.4631 - accuracy: 0.7879 - val_loss: 6.6378 - val_accuracy: 0.5234\n",
      "Epoch 16/1000\n",
      "10/10 [==============================] - 4s 354ms/step - loss: 0.3635 - accuracy: 0.8329 - val_loss: 6.0685 - val_accuracy: 0.5452\n",
      "Epoch 17/1000\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.3369 - accuracy: 0.8562 - val_loss: 2.8321 - val_accuracy: 0.7009\n",
      "Epoch 18/1000\n",
      "10/10 [==============================] - 3s 273ms/step - loss: 0.3612 - accuracy: 0.8294 - val_loss: 3.6798 - val_accuracy: 0.6667\n",
      "Epoch 19/1000\n",
      "10/10 [==============================] - 3s 266ms/step - loss: 0.3438 - accuracy: 0.8398 - val_loss: 3.4808 - val_accuracy: 0.7321\n",
      "Epoch 20/1000\n",
      "10/10 [==============================] - 3s 275ms/step - loss: 0.3604 - accuracy: 0.8424 - val_loss: 3.2543 - val_accuracy: 0.6075\n",
      "Epoch 21/1000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.4028 - accuracy: 0.8147 - val_loss: 1.7429 - val_accuracy: 0.7601\n",
      "Epoch 22/1000\n",
      "10/10 [==============================] - 3s 274ms/step - loss: 0.3419 - accuracy: 0.8502 - val_loss: 2.4656 - val_accuracy: 0.6480\n",
      "Epoch 23/1000\n",
      "10/10 [==============================] - 3s 334ms/step - loss: 0.2996 - accuracy: 0.8623 - val_loss: 2.6876 - val_accuracy: 0.7414\n",
      "Epoch 24/1000\n",
      "10/10 [==============================] - 3s 272ms/step - loss: 0.4218 - accuracy: 0.8069 - val_loss: 1.7752 - val_accuracy: 0.7383\n",
      "Epoch 25/1000\n",
      "10/10 [==============================] - 3s 334ms/step - loss: 0.3251 - accuracy: 0.8571 - val_loss: 3.7798 - val_accuracy: 0.4735\n",
      "Epoch 26/1000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.3518 - accuracy: 0.8398 - val_loss: 2.6379 - val_accuracy: 0.5358\n",
      "Epoch 27/1000\n",
      "10/10 [==============================] - 3s 297ms/step - loss: 0.3344 - accuracy: 0.8589 - val_loss: 3.5965 - val_accuracy: 0.5421\n",
      "Epoch 28/1000\n",
      "10/10 [==============================] - 3s 298ms/step - loss: 0.2795 - accuracy: 0.8687 - val_loss: 3.6659 - val_accuracy: 0.5327\n",
      "Epoch 29/1000\n",
      "10/10 [==============================] - 3s 296ms/step - loss: 0.3226 - accuracy: 0.8545 - val_loss: 2.0523 - val_accuracy: 0.6729\n",
      "Epoch 30/1000\n",
      "10/10 [==============================] - 3s 273ms/step - loss: 0.3315 - accuracy: 0.8485 - val_loss: 1.8929 - val_accuracy: 0.7259\n",
      "Epoch 31/1000\n",
      "10/10 [==============================] - 3s 266ms/step - loss: 0.3126 - accuracy: 0.8623 - val_loss: 1.9061 - val_accuracy: 0.6449\n",
      "Epoch 32/1000\n",
      "10/10 [==============================] - 4s 351ms/step - loss: 0.3031 - accuracy: 0.8580 - val_loss: 0.6189 - val_accuracy: 0.7913\n",
      "Epoch 33/1000\n",
      "10/10 [==============================] - 3s 275ms/step - loss: 0.2892 - accuracy: 0.8745 - val_loss: 0.7307 - val_accuracy: 0.7383\n",
      "Epoch 34/1000\n",
      "10/10 [==============================] - 3s 316ms/step - loss: 0.2730 - accuracy: 0.8771 - val_loss: 0.8957 - val_accuracy: 0.7726\n",
      "Epoch 35/1000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.2561 - accuracy: 0.8866 - val_loss: 0.6493 - val_accuracy: 0.8474\n",
      "Epoch 36/1000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.3456 - accuracy: 0.8450 - val_loss: 0.5120 - val_accuracy: 0.7850\n",
      "Epoch 37/1000\n",
      "10/10 [==============================] - 3s 301ms/step - loss: 0.3055 - accuracy: 0.8485 - val_loss: 0.7429 - val_accuracy: 0.7601\n",
      "Epoch 38/1000\n",
      "10/10 [==============================] - 3s 273ms/step - loss: 0.2922 - accuracy: 0.8797 - val_loss: 0.5970 - val_accuracy: 0.7477\n",
      "Epoch 39/1000\n",
      "10/10 [==============================] - 3s 319ms/step - loss: 0.2957 - accuracy: 0.8649 - val_loss: 0.5159 - val_accuracy: 0.7913\n",
      "Epoch 40/1000\n",
      "10/10 [==============================] - 3s 273ms/step - loss: 0.2586 - accuracy: 0.8883 - val_loss: 0.7584 - val_accuracy: 0.7321\n",
      "Epoch 41/1000\n",
      "10/10 [==============================] - 3s 277ms/step - loss: 0.2549 - accuracy: 0.8952 - val_loss: 1.4243 - val_accuracy: 0.7259\n",
      "Epoch 42/1000\n",
      "10/10 [==============================] - 4s 368ms/step - loss: 0.3085 - accuracy: 0.8667 - val_loss: 0.3724 - val_accuracy: 0.8318\n",
      "Epoch 43/1000\n",
      "10/10 [==============================] - 3s 273ms/step - loss: 0.2583 - accuracy: 0.8866 - val_loss: 0.6034 - val_accuracy: 0.7445\n",
      "Epoch 44/1000\n",
      "10/10 [==============================] - 4s 377ms/step - loss: 0.2552 - accuracy: 0.8909 - val_loss: 0.4194 - val_accuracy: 0.8474\n",
      "Epoch 45/1000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 0.2808 - accuracy: 0.8831 - val_loss: 2.2000 - val_accuracy: 0.5670\n",
      "Epoch 46/1000\n",
      "10/10 [==============================] - 3s 276ms/step - loss: 0.2745 - accuracy: 0.8649 - val_loss: 0.7029 - val_accuracy: 0.7975\n",
      "Epoch 47/1000\n",
      "10/10 [==============================] - 3s 279ms/step - loss: 0.2470 - accuracy: 0.8900 - val_loss: 0.9105 - val_accuracy: 0.7477\n",
      "Epoch 48/1000\n",
      "10/10 [==============================] - 3s 293ms/step - loss: 0.2384 - accuracy: 0.8857 - val_loss: 2.1768 - val_accuracy: 0.6854\n",
      "Epoch 49/1000\n",
      "10/10 [==============================] - 3s 299ms/step - loss: 0.2875 - accuracy: 0.8788 - val_loss: 2.7007 - val_accuracy: 0.7913\n",
      "Epoch 50/1000\n",
      "10/10 [==============================] - 3s 277ms/step - loss: 0.2484 - accuracy: 0.9082 - val_loss: 2.8849 - val_accuracy: 0.7196\n",
      "Epoch 51/1000\n",
      "10/10 [==============================] - 3s 277ms/step - loss: 0.2650 - accuracy: 0.8874 - val_loss: 1.6937 - val_accuracy: 0.8100\n",
      "Epoch 52/1000\n",
      "10/10 [==============================] - 3s 319ms/step - loss: 0.2507 - accuracy: 0.8987 - val_loss: 0.7248 - val_accuracy: 0.7944\n",
      "Epoch 53/1000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.2515 - accuracy: 0.8944 - val_loss: 0.6519 - val_accuracy: 0.7477\n",
      "Epoch 54/1000\n",
      "10/10 [==============================] - 3s 316ms/step - loss: 0.2966 - accuracy: 0.8710 - val_loss: 0.8411 - val_accuracy: 0.8193\n",
      "Epoch 55/1000\n",
      "10/10 [==============================] - 3s 300ms/step - loss: 0.2716 - accuracy: 0.8762 - val_loss: 1.3170 - val_accuracy: 0.7882\n",
      "Epoch 56/1000\n",
      "10/10 [==============================] - 3s 275ms/step - loss: 0.2713 - accuracy: 0.8814 - val_loss: 0.5667 - val_accuracy: 0.7882\n",
      "Epoch 57/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2576 - accuracy: 0.8813\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.2576 - accuracy: 0.8813 - val_loss: 0.3734 - val_accuracy: 0.8442\n",
      "Epoch 58/1000\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.2134 - accuracy: 0.9143 - val_loss: 0.3481 - val_accuracy: 0.8847\n",
      "Epoch 59/1000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 0.2076 - accuracy: 0.9100 - val_loss: 0.2730 - val_accuracy: 0.8972\n",
      "Epoch 60/1000\n",
      "10/10 [==============================] - 3s 276ms/step - loss: 0.2078 - accuracy: 0.9143 - val_loss: 0.3060 - val_accuracy: 0.8629\n",
      "Epoch 61/1000\n",
      "10/10 [==============================] - 4s 365ms/step - loss: 0.2053 - accuracy: 0.9074 - val_loss: 0.2649 - val_accuracy: 0.8879\n",
      "Epoch 62/1000\n",
      "10/10 [==============================] - 3s 313ms/step - loss: 0.2101 - accuracy: 0.9126 - val_loss: 0.2673 - val_accuracy: 0.9034\n",
      "Epoch 63/1000\n",
      "10/10 [==============================] - 4s 368ms/step - loss: 0.2102 - accuracy: 0.9152 - val_loss: 0.3243 - val_accuracy: 0.8692\n",
      "Epoch 64/1000\n",
      "10/10 [==============================] - 4s 368ms/step - loss: 0.1986 - accuracy: 0.9221 - val_loss: 0.2566 - val_accuracy: 0.9003\n",
      "Epoch 65/1000\n",
      "10/10 [==============================] - 3s 299ms/step - loss: 0.1900 - accuracy: 0.9273 - val_loss: 0.3016 - val_accuracy: 0.8847\n",
      "Epoch 66/1000\n",
      "10/10 [==============================] - 3s 275ms/step - loss: 0.2053 - accuracy: 0.9039 - val_loss: 0.3000 - val_accuracy: 0.8879\n",
      "Epoch 67/1000\n",
      "10/10 [==============================] - 3s 283ms/step - loss: 0.1827 - accuracy: 0.9264 - val_loss: 0.3824 - val_accuracy: 0.8442\n",
      "Epoch 68/1000\n",
      "10/10 [==============================] - 3s 267ms/step - loss: 0.1981 - accuracy: 0.9247 - val_loss: 0.3285 - val_accuracy: 0.8785\n",
      "Epoch 69/1000\n",
      "10/10 [==============================] - 3s 298ms/step - loss: 0.1862 - accuracy: 0.9299 - val_loss: 0.3003 - val_accuracy: 0.8910\n",
      "Epoch 70/1000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.1978 - accuracy: 0.9203 - val_loss: 0.2536 - val_accuracy: 0.9034\n",
      "Epoch 71/1000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.2181 - accuracy: 0.9177 - val_loss: 0.3155 - val_accuracy: 0.8598\n",
      "Epoch 72/1000\n",
      "10/10 [==============================] - 3s 300ms/step - loss: 0.1897 - accuracy: 0.9264 - val_loss: 0.3455 - val_accuracy: 0.8474\n",
      "Epoch 73/1000\n",
      "10/10 [==============================] - 4s 358ms/step - loss: 0.1938 - accuracy: 0.9229 - val_loss: 0.2476 - val_accuracy: 0.9159\n",
      "Epoch 74/1000\n",
      "10/10 [==============================] - 3s 280ms/step - loss: 0.1927 - accuracy: 0.9281 - val_loss: 0.2813 - val_accuracy: 0.8941\n",
      "Epoch 75/1000\n",
      "10/10 [==============================] - 3s 273ms/step - loss: 0.1951 - accuracy: 0.9203 - val_loss: 0.2739 - val_accuracy: 0.8910\n",
      "Epoch 76/1000\n",
      "10/10 [==============================] - 3s 297ms/step - loss: 0.1779 - accuracy: 0.9394 - val_loss: 0.2753 - val_accuracy: 0.8910\n",
      "Epoch 77/1000\n",
      "10/10 [==============================] - 3s 295ms/step - loss: 0.2008 - accuracy: 0.9255 - val_loss: 0.2558 - val_accuracy: 0.8910\n",
      "Epoch 78/1000\n",
      "10/10 [==============================] - 3s 300ms/step - loss: 0.1757 - accuracy: 0.9385 - val_loss: 0.2422 - val_accuracy: 0.8879\n",
      "Epoch 79/1000\n",
      "10/10 [==============================] - 4s 355ms/step - loss: 0.1834 - accuracy: 0.9273 - val_loss: 0.2375 - val_accuracy: 0.8972\n",
      "Epoch 80/1000\n",
      "10/10 [==============================] - 4s 377ms/step - loss: 0.1968 - accuracy: 0.9238 - val_loss: 0.2902 - val_accuracy: 0.8567\n",
      "Epoch 81/1000\n",
      "10/10 [==============================] - 3s 280ms/step - loss: 0.1865 - accuracy: 0.9342 - val_loss: 0.2408 - val_accuracy: 0.9034\n",
      "Epoch 82/1000\n",
      "10/10 [==============================] - 3s 336ms/step - loss: 0.1841 - accuracy: 0.9342 - val_loss: 0.3994 - val_accuracy: 0.8380\n",
      "Epoch 83/1000\n",
      "10/10 [==============================] - 3s 295ms/step - loss: 0.1921 - accuracy: 0.9247 - val_loss: 0.2624 - val_accuracy: 0.8816\n",
      "Epoch 84/1000\n",
      "10/10 [==============================] - 3s 273ms/step - loss: 0.1927 - accuracy: 0.9307 - val_loss: 0.2581 - val_accuracy: 0.8847\n",
      "Epoch 85/1000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.1794 - accuracy: 0.9305 - val_loss: 0.2414 - val_accuracy: 0.9128\n",
      "Epoch 86/1000\n",
      "10/10 [==============================] - 3s 335ms/step - loss: 0.1683 - accuracy: 0.9325 - val_loss: 0.2358 - val_accuracy: 0.8941\n",
      "Epoch 87/1000\n",
      "10/10 [==============================] - 3s 298ms/step - loss: 0.1999 - accuracy: 0.9264 - val_loss: 0.2665 - val_accuracy: 0.8879\n",
      "Epoch 88/1000\n",
      "10/10 [==============================] - 3s 263ms/step - loss: 0.1932 - accuracy: 0.9212 - val_loss: 0.2463 - val_accuracy: 0.9034\n",
      "Epoch 89/1000\n",
      "10/10 [==============================] - 3s 275ms/step - loss: 0.1884 - accuracy: 0.9186 - val_loss: 0.2514 - val_accuracy: 0.9128\n",
      "Epoch 90/1000\n",
      "10/10 [==============================] - 3s 300ms/step - loss: 0.1974 - accuracy: 0.9247 - val_loss: 0.2374 - val_accuracy: 0.9128\n",
      "Epoch 91/1000\n",
      "10/10 [==============================] - 3s 277ms/step - loss: 0.1808 - accuracy: 0.9238 - val_loss: 0.2806 - val_accuracy: 0.8972\n",
      "Epoch 92/1000\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 0.1912 - accuracy: 0.9368 - val_loss: 0.3342 - val_accuracy: 0.8536\n",
      "Epoch 93/1000\n",
      "10/10 [==============================] - 3s 272ms/step - loss: 0.1843 - accuracy: 0.9290 - val_loss: 0.2882 - val_accuracy: 0.8723\n",
      "Epoch 94/1000\n",
      "10/10 [==============================] - 3s 273ms/step - loss: 0.1749 - accuracy: 0.9264 - val_loss: 0.2717 - val_accuracy: 0.8910\n",
      "Epoch 95/1000\n",
      "10/10 [==============================] - 3s 278ms/step - loss: 0.1812 - accuracy: 0.9316 - val_loss: 0.3051 - val_accuracy: 0.8692\n",
      "Epoch 96/1000\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 0.1966 - accuracy: 0.9273 - val_loss: 0.3060 - val_accuracy: 0.8692\n",
      "Epoch 97/1000\n",
      "10/10 [==============================] - 3s 276ms/step - loss: 0.1876 - accuracy: 0.9264 - val_loss: 0.2491 - val_accuracy: 0.9034\n",
      "Epoch 98/1000\n",
      "10/10 [==============================] - 3s 299ms/step - loss: 0.1834 - accuracy: 0.9290 - val_loss: 0.2455 - val_accuracy: 0.9097\n",
      "Epoch 99/1000\n",
      "10/10 [==============================] - 3s 338ms/step - loss: 0.1698 - accuracy: 0.9316 - val_loss: 0.2555 - val_accuracy: 0.8879\n",
      "Epoch 100/1000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.1822 - accuracy: 0.9333 - val_loss: 0.2350 - val_accuracy: 0.9159\n",
      "Epoch 101/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1912 - accuracy: 0.9195\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "10/10 [==============================] - 3s 314ms/step - loss: 0.1912 - accuracy: 0.9195 - val_loss: 0.2417 - val_accuracy: 0.9097\n",
      "Epoch 102/1000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.1796 - accuracy: 0.9325 - val_loss: 0.2351 - val_accuracy: 0.9128\n",
      "Epoch 103/1000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.1723 - accuracy: 0.9359 - val_loss: 0.2265 - val_accuracy: 0.9190\n",
      "Epoch 104/1000\n",
      "10/10 [==============================] - 3s 277ms/step - loss: 0.1755 - accuracy: 0.9264 - val_loss: 0.2266 - val_accuracy: 0.9097\n",
      "Epoch 105/1000\n",
      "10/10 [==============================] - 3s 348ms/step - loss: 0.1583 - accuracy: 0.9403 - val_loss: 0.2254 - val_accuracy: 0.9065\n",
      "Epoch 106/1000\n",
      "10/10 [==============================] - 3s 277ms/step - loss: 0.1579 - accuracy: 0.9411 - val_loss: 0.2288 - val_accuracy: 0.9065\n",
      "Epoch 107/1000\n",
      "10/10 [==============================] - 3s 273ms/step - loss: 0.1581 - accuracy: 0.9455 - val_loss: 0.2265 - val_accuracy: 0.9034\n",
      "Epoch 108/1000\n",
      "10/10 [==============================] - 4s 415ms/step - loss: 0.1548 - accuracy: 0.9453 - val_loss: 0.2230 - val_accuracy: 0.9221\n",
      "Epoch 109/1000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.1671 - accuracy: 0.9312 - val_loss: 0.2259 - val_accuracy: 0.9065\n",
      "Epoch 110/1000\n",
      "10/10 [==============================] - 4s 355ms/step - loss: 0.1622 - accuracy: 0.9342 - val_loss: 0.2220 - val_accuracy: 0.9221\n",
      "Epoch 111/1000\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 0.1612 - accuracy: 0.9429 - val_loss: 0.2326 - val_accuracy: 0.9221\n",
      "Epoch 112/1000\n",
      "10/10 [==============================] - 3s 273ms/step - loss: 0.1603 - accuracy: 0.9377 - val_loss: 0.2237 - val_accuracy: 0.9221\n",
      "Epoch 113/1000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 0.1652 - accuracy: 0.9437 - val_loss: 0.2251 - val_accuracy: 0.9221\n",
      "Epoch 114/1000\n",
      "10/10 [==============================] - 3s 282ms/step - loss: 0.1565 - accuracy: 0.9394 - val_loss: 0.2279 - val_accuracy: 0.9190\n",
      "Epoch 115/1000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.1505 - accuracy: 0.9455 - val_loss: 0.2299 - val_accuracy: 0.9159\n",
      "Epoch 116/1000\n",
      "10/10 [==============================] - 3s 314ms/step - loss: 0.1685 - accuracy: 0.9247 - val_loss: 0.2204 - val_accuracy: 0.9283\n",
      "Epoch 117/1000\n",
      "10/10 [==============================] - 3s 316ms/step - loss: 0.1613 - accuracy: 0.9316 - val_loss: 0.2251 - val_accuracy: 0.9221\n",
      "Epoch 118/1000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.1606 - accuracy: 0.9445 - val_loss: 0.2233 - val_accuracy: 0.9315\n",
      "Epoch 119/1000\n",
      "10/10 [==============================] - 3s 274ms/step - loss: 0.1619 - accuracy: 0.9403 - val_loss: 0.2290 - val_accuracy: 0.9159\n",
      "Epoch 120/1000\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 0.1571 - accuracy: 0.9377 - val_loss: 0.2299 - val_accuracy: 0.9159\n",
      "Epoch 121/1000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.1649 - accuracy: 0.9368 - val_loss: 0.2378 - val_accuracy: 0.9128\n",
      "Epoch 122/1000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.1506 - accuracy: 0.9406 - val_loss: 0.2355 - val_accuracy: 0.9128\n",
      "Epoch 123/1000\n",
      "10/10 [==============================] - 3s 275ms/step - loss: 0.1586 - accuracy: 0.9351 - val_loss: 0.2346 - val_accuracy: 0.9128\n",
      "Epoch 124/1000\n",
      "10/10 [==============================] - 3s 292ms/step - loss: 0.1522 - accuracy: 0.9446 - val_loss: 0.2311 - val_accuracy: 0.9159\n",
      "Epoch 125/1000\n",
      "10/10 [==============================] - 3s 275ms/step - loss: 0.1502 - accuracy: 0.9437 - val_loss: 0.2327 - val_accuracy: 0.9221\n",
      "Epoch 126/1000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.1621 - accuracy: 0.9385 - val_loss: 0.2400 - val_accuracy: 0.9065\n",
      "Epoch 127/1000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.1608 - accuracy: 0.9420 - val_loss: 0.2326 - val_accuracy: 0.9221\n",
      "Epoch 128/1000\n",
      "10/10 [==============================] - 3s 273ms/step - loss: 0.1487 - accuracy: 0.9437 - val_loss: 0.2360 - val_accuracy: 0.9097\n",
      "Epoch 129/1000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.1539 - accuracy: 0.9430 - val_loss: 0.2350 - val_accuracy: 0.9128\n",
      "Epoch 130/1000\n",
      "10/10 [==============================] - 4s 383ms/step - loss: 0.1577 - accuracy: 0.9385 - val_loss: 0.2389 - val_accuracy: 0.9190\n",
      "Epoch 131/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1495 - accuracy: 0.9385\n",
      "Epoch 00131: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.1495 - accuracy: 0.9385 - val_loss: 0.2372 - val_accuracy: 0.9190\n",
      "Epoch 132/1000\n",
      "10/10 [==============================] - 3s 280ms/step - loss: 0.1537 - accuracy: 0.9359 - val_loss: 0.2332 - val_accuracy: 0.9190\n",
      "Epoch 133/1000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.1582 - accuracy: 0.9342 - val_loss: 0.2319 - val_accuracy: 0.9190\n",
      "Epoch 134/1000\n",
      "10/10 [==============================] - 3s 273ms/step - loss: 0.1541 - accuracy: 0.9403 - val_loss: 0.2331 - val_accuracy: 0.9159\n",
      "Epoch 135/1000\n",
      "10/10 [==============================] - 3s 279ms/step - loss: 0.1619 - accuracy: 0.9325 - val_loss: 0.2304 - val_accuracy: 0.9190\n",
      "Epoch 136/1000\n",
      "10/10 [==============================] - 3s 291ms/step - loss: 0.1568 - accuracy: 0.9385 - val_loss: 0.2295 - val_accuracy: 0.9252\n",
      "Epoch 137/1000\n",
      "10/10 [==============================] - 3s 296ms/step - loss: 0.1529 - accuracy: 0.9333 - val_loss: 0.2300 - val_accuracy: 0.9221\n",
      "Epoch 138/1000\n",
      "10/10 [==============================] - 3s 274ms/step - loss: 0.1568 - accuracy: 0.9420 - val_loss: 0.2312 - val_accuracy: 0.9128\n",
      "Epoch 139/1000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.1588 - accuracy: 0.9446 - val_loss: 0.2354 - val_accuracy: 0.9159\n",
      "Epoch 140/1000\n",
      "10/10 [==============================] - 3s 346ms/step - loss: 0.1521 - accuracy: 0.9377 - val_loss: 0.2356 - val_accuracy: 0.9159\n",
      "Epoch 141/1000\n",
      "10/10 [==============================] - 3s 275ms/step - loss: 0.1448 - accuracy: 0.9481 - val_loss: 0.2371 - val_accuracy: 0.9128\n",
      "Epoch 142/1000\n",
      "10/10 [==============================] - 3s 273ms/step - loss: 0.1521 - accuracy: 0.9429 - val_loss: 0.2362 - val_accuracy: 0.9097\n",
      "Epoch 143/1000\n",
      "10/10 [==============================] - 3s 283ms/step - loss: 0.1420 - accuracy: 0.9498 - val_loss: 0.2369 - val_accuracy: 0.9128\n",
      "Epoch 144/1000\n",
      "10/10 [==============================] - 3s 273ms/step - loss: 0.1560 - accuracy: 0.9403 - val_loss: 0.2387 - val_accuracy: 0.9097\n",
      "Epoch 145/1000\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.1509 - accuracy: 0.9367 - val_loss: 0.2370 - val_accuracy: 0.9159\n",
      "Epoch 146/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1398 - accuracy: 0.9532\n",
      "Epoch 00146: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "10/10 [==============================] - 3s 281ms/step - loss: 0.1398 - accuracy: 0.9532 - val_loss: 0.2377 - val_accuracy: 0.9097\n",
      "Epoch 147/1000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.1525 - accuracy: 0.9367 - val_loss: 0.2377 - val_accuracy: 0.9097\n",
      "Epoch 148/1000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.1579 - accuracy: 0.9446 - val_loss: 0.2358 - val_accuracy: 0.9159\n",
      "Epoch 149/1000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.1529 - accuracy: 0.9420 - val_loss: 0.2358 - val_accuracy: 0.9128\n",
      "Epoch 150/1000\n",
      "10/10 [==============================] - 3s 346ms/step - loss: 0.1535 - accuracy: 0.9411 - val_loss: 0.2360 - val_accuracy: 0.9097\n",
      "Epoch 151/1000\n",
      "10/10 [==============================] - 3s 274ms/step - loss: 0.1503 - accuracy: 0.9481 - val_loss: 0.2354 - val_accuracy: 0.9190\n",
      "Epoch 152/1000\n",
      "10/10 [==============================] - 3s 277ms/step - loss: 0.1529 - accuracy: 0.9455 - val_loss: 0.2355 - val_accuracy: 0.9190\n",
      "Epoch 153/1000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.1508 - accuracy: 0.9422 - val_loss: 0.2357 - val_accuracy: 0.9190\n",
      "Epoch 154/1000\n",
      "10/10 [==============================] - 3s 300ms/step - loss: 0.1432 - accuracy: 0.9429 - val_loss: 0.2357 - val_accuracy: 0.9221\n",
      "Epoch 155/1000\n",
      "10/10 [==============================] - 3s 274ms/step - loss: 0.1541 - accuracy: 0.9377 - val_loss: 0.2357 - val_accuracy: 0.9221\n",
      "Epoch 156/1000\n",
      "10/10 [==============================] - 3s 301ms/step - loss: 0.1425 - accuracy: 0.9446 - val_loss: 0.2361 - val_accuracy: 0.9190\n",
      "Epoch 157/1000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.1460 - accuracy: 0.9422 - val_loss: 0.2364 - val_accuracy: 0.9190\n",
      "Epoch 158/1000\n",
      "10/10 [==============================] - 3s 276ms/step - loss: 0.1495 - accuracy: 0.9411 - val_loss: 0.2379 - val_accuracy: 0.9159\n",
      "Epoch 159/1000\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 0.1518 - accuracy: 0.9420 - val_loss: 0.2385 - val_accuracy: 0.9097\n",
      "Epoch 160/1000\n",
      "10/10 [==============================] - 3s 315ms/step - loss: 0.1479 - accuracy: 0.9429 - val_loss: 0.2368 - val_accuracy: 0.9159\n",
      "Epoch 161/1000\n",
      "10/10 [==============================] - 3s 274ms/step - loss: 0.1547 - accuracy: 0.9385 - val_loss: 0.2372 - val_accuracy: 0.9128\n",
      "Loss:\n",
      "Mean: 0.205274\n",
      "Std: 0.020423\n",
      "Min: 0.182235\n",
      "Max: 0.230176\n",
      "\n",
      "\n",
      "Acc:\n",
      "Mean: 0.915888\n",
      "Std: 0.010095\n",
      "Min: 0.900312\n",
      "Max: 0.928349\n",
      "\n",
      "\n",
      "ROC AUC:\n",
      "Mean: 0.975232\n",
      "Std: 0.005220\n",
      "Min: 0.968908\n",
      "Max: 0.981979\n",
      "\n",
      "\n",
      "mAP:\n",
      "Mean: 0.971043\n",
      "Std: 0.008006\n",
      "Min: 0.961043\n",
      "Max: 0.982835\n",
      "\n",
      "\n",
      "Model: \"resnext\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 75, 75, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_152 (Lambda)             (None, 75, 75, 2)    0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_153 (Lambda)             (None, 75, 75, 1)    0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_8 (GaussianNoise (None, 75, 75, 2)    0           lambda_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_9 (GaussianNoise (None, 75, 75, 1)    0           lambda_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 75, 75, 3)    0           gaussian_noise_8[0][0]           \n",
      "                                                                 gaussian_noise_9[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, 75, 75, 32)   896         concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 75, 75, 32)   128         conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 75, 75, 32)   0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)             (None, 75, 75, 32)   1024        activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 75, 75, 32)   128         conv2d_234[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 75, 75, 32)   0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_154 (Lambda)             (None, 75, 75, 8)    0           activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_155 (Lambda)             (None, 75, 75, 8)    0           activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_156 (Lambda)             (None, 75, 75, 8)    0           activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_157 (Lambda)             (None, 75, 75, 8)    0           activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)             (None, 75, 75, 8)    584         lambda_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, 75, 75, 8)    584         lambda_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, 75, 75, 8)    584         lambda_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)             (None, 75, 75, 8)    584         lambda_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 75, 75, 32)   0           conv2d_235[0][0]                 \n",
      "                                                                 conv2d_236[0][0]                 \n",
      "                                                                 conv2d_237[0][0]                 \n",
      "                                                                 conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 75, 75, 32)   128         concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 75, 75, 32)   0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, 75, 75, 64)   2112        activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)             (None, 75, 75, 64)   2112        activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 75, 75, 64)   256         conv2d_233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 75, 75, 64)   256         conv2d_239[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, 75, 75, 64)   0           batch_normalization_125[0][0]    \n",
      "                                                                 batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 75, 75, 64)   0           add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)             (None, 75, 75, 32)   2048        activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 75, 75, 32)   128         conv2d_240[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 75, 75, 32)   0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_158 (Lambda)             (None, 75, 75, 8)    0           activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_159 (Lambda)             (None, 75, 75, 8)    0           activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_160 (Lambda)             (None, 75, 75, 8)    0           activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_161 (Lambda)             (None, 75, 75, 8)    0           activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_241 (Conv2D)             (None, 75, 75, 8)    584         lambda_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_242 (Conv2D)             (None, 75, 75, 8)    584         lambda_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_243 (Conv2D)             (None, 75, 75, 8)    584         lambda_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_244 (Conv2D)             (None, 75, 75, 8)    584         lambda_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)    (None, 75, 75, 32)   0           conv2d_241[0][0]                 \n",
      "                                                                 conv2d_242[0][0]                 \n",
      "                                                                 conv2d_243[0][0]                 \n",
      "                                                                 conv2d_244[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 75, 75, 32)   128         concatenate_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 75, 75, 32)   0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_245 (Conv2D)             (None, 75, 75, 64)   2112        activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 75, 75, 64)   256         conv2d_245[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_37 (Add)                    (None, 75, 75, 64)   0           activation_115[0][0]             \n",
      "                                                                 batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 75, 75, 64)   0           add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_246 (Conv2D)             (None, 75, 75, 32)   2048        activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 75, 75, 32)   128         conv2d_246[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 75, 75, 32)   0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_162 (Lambda)             (None, 75, 75, 8)    0           activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_163 (Lambda)             (None, 75, 75, 8)    0           activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_164 (Lambda)             (None, 75, 75, 8)    0           activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_165 (Lambda)             (None, 75, 75, 8)    0           activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_247 (Conv2D)             (None, 75, 75, 8)    584         lambda_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_248 (Conv2D)             (None, 75, 75, 8)    584         lambda_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_249 (Conv2D)             (None, 75, 75, 8)    584         lambda_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_250 (Conv2D)             (None, 75, 75, 8)    584         lambda_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 75, 75, 32)   0           conv2d_247[0][0]                 \n",
      "                                                                 conv2d_248[0][0]                 \n",
      "                                                                 conv2d_249[0][0]                 \n",
      "                                                                 conv2d_250[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 75, 75, 32)   128         concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 75, 75, 32)   0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_251 (Conv2D)             (None, 75, 75, 64)   2112        activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 75, 75, 64)   256         conv2d_251[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_38 (Add)                    (None, 75, 75, 64)   0           activation_118[0][0]             \n",
      "                                                                 batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 75, 75, 64)   0           add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_253 (Conv2D)             (None, 75, 75, 64)   4096        activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 75, 75, 64)   256         conv2d_253[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 75, 75, 64)   0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_166 (Lambda)             (None, 75, 75, 16)   0           activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_167 (Lambda)             (None, 75, 75, 16)   0           activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_168 (Lambda)             (None, 75, 75, 16)   0           activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_169 (Lambda)             (None, 75, 75, 16)   0           activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_254 (Conv2D)             (None, 38, 38, 16)   2320        lambda_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_255 (Conv2D)             (None, 38, 38, 16)   2320        lambda_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_256 (Conv2D)             (None, 38, 38, 16)   2320        lambda_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_257 (Conv2D)             (None, 38, 38, 16)   2320        lambda_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 38, 38, 64)   0           conv2d_254[0][0]                 \n",
      "                                                                 conv2d_255[0][0]                 \n",
      "                                                                 conv2d_256[0][0]                 \n",
      "                                                                 conv2d_257[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 38, 38, 64)   256         concatenate_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 38, 38, 64)   0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_252 (Conv2D)             (None, 38, 38, 128)  8320        activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_258 (Conv2D)             (None, 38, 38, 128)  8320        activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 38, 38, 128)  512         conv2d_252[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 38, 38, 128)  512         conv2d_258[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_39 (Add)                    (None, 38, 38, 128)  0           batch_normalization_135[0][0]    \n",
      "                                                                 batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 38, 38, 128)  0           add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_259 (Conv2D)             (None, 38, 38, 64)   8192        activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 38, 38, 64)   256         conv2d_259[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 38, 38, 64)   0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_170 (Lambda)             (None, 38, 38, 16)   0           activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_171 (Lambda)             (None, 38, 38, 16)   0           activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_172 (Lambda)             (None, 38, 38, 16)   0           activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_173 (Lambda)             (None, 38, 38, 16)   0           activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_260 (Conv2D)             (None, 38, 38, 16)   2320        lambda_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_261 (Conv2D)             (None, 38, 38, 16)   2320        lambda_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_262 (Conv2D)             (None, 38, 38, 16)   2320        lambda_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_263 (Conv2D)             (None, 38, 38, 16)   2320        lambda_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 38, 38, 64)   0           conv2d_260[0][0]                 \n",
      "                                                                 conv2d_261[0][0]                 \n",
      "                                                                 conv2d_262[0][0]                 \n",
      "                                                                 conv2d_263[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 38, 38, 64)   256         concatenate_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 38, 38, 64)   0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_264 (Conv2D)             (None, 38, 38, 128)  8320        activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 38, 38, 128)  512         conv2d_264[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_40 (Add)                    (None, 38, 38, 128)  0           activation_124[0][0]             \n",
      "                                                                 batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 38, 38, 128)  0           add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_265 (Conv2D)             (None, 38, 38, 64)   8192        activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 38, 38, 64)   256         conv2d_265[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 38, 38, 64)   0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_174 (Lambda)             (None, 38, 38, 16)   0           activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_175 (Lambda)             (None, 38, 38, 16)   0           activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_176 (Lambda)             (None, 38, 38, 16)   0           activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_177 (Lambda)             (None, 38, 38, 16)   0           activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_266 (Conv2D)             (None, 38, 38, 16)   2320        lambda_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_267 (Conv2D)             (None, 38, 38, 16)   2320        lambda_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_268 (Conv2D)             (None, 38, 38, 16)   2320        lambda_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_269 (Conv2D)             (None, 38, 38, 16)   2320        lambda_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 38, 38, 64)   0           conv2d_266[0][0]                 \n",
      "                                                                 conv2d_267[0][0]                 \n",
      "                                                                 conv2d_268[0][0]                 \n",
      "                                                                 conv2d_269[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 38, 38, 64)   256         concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 38, 38, 64)   0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_270 (Conv2D)             (None, 38, 38, 128)  8320        activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 38, 38, 128)  512         conv2d_270[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_41 (Add)                    (None, 38, 38, 128)  0           activation_127[0][0]             \n",
      "                                                                 batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 38, 38, 128)  0           add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_272 (Conv2D)             (None, 38, 38, 128)  16384       activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 38, 38, 128)  512         conv2d_272[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 38, 38, 128)  0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_178 (Lambda)             (None, 38, 38, 32)   0           activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_179 (Lambda)             (None, 38, 38, 32)   0           activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_180 (Lambda)             (None, 38, 38, 32)   0           activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_181 (Lambda)             (None, 38, 38, 32)   0           activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_273 (Conv2D)             (None, 19, 19, 32)   9248        lambda_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_274 (Conv2D)             (None, 19, 19, 32)   9248        lambda_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_275 (Conv2D)             (None, 19, 19, 32)   9248        lambda_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_276 (Conv2D)             (None, 19, 19, 32)   9248        lambda_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 19, 19, 128)  0           conv2d_273[0][0]                 \n",
      "                                                                 conv2d_274[0][0]                 \n",
      "                                                                 conv2d_275[0][0]                 \n",
      "                                                                 conv2d_276[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 19, 19, 128)  512         concatenate_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 19, 19, 128)  0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_271 (Conv2D)             (None, 19, 19, 256)  33024       activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_277 (Conv2D)             (None, 19, 19, 256)  33024       activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 19, 19, 256)  1024        conv2d_271[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 19, 19, 256)  1024        conv2d_277[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_42 (Add)                    (None, 19, 19, 256)  0           batch_normalization_145[0][0]    \n",
      "                                                                 batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 19, 19, 256)  0           add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_278 (Conv2D)             (None, 19, 19, 128)  32768       activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 19, 19, 128)  512         conv2d_278[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 19, 19, 128)  0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_182 (Lambda)             (None, 19, 19, 32)   0           activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_183 (Lambda)             (None, 19, 19, 32)   0           activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_184 (Lambda)             (None, 19, 19, 32)   0           activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_185 (Lambda)             (None, 19, 19, 32)   0           activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_279 (Conv2D)             (None, 19, 19, 32)   9248        lambda_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_280 (Conv2D)             (None, 19, 19, 32)   9248        lambda_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_281 (Conv2D)             (None, 19, 19, 32)   9248        lambda_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_282 (Conv2D)             (None, 19, 19, 32)   9248        lambda_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_48 (Concatenate)    (None, 19, 19, 128)  0           conv2d_279[0][0]                 \n",
      "                                                                 conv2d_280[0][0]                 \n",
      "                                                                 conv2d_281[0][0]                 \n",
      "                                                                 conv2d_282[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 19, 19, 128)  512         concatenate_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 19, 19, 128)  0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_283 (Conv2D)             (None, 19, 19, 256)  33024       activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 19, 19, 256)  1024        conv2d_283[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_43 (Add)                    (None, 19, 19, 256)  0           activation_133[0][0]             \n",
      "                                                                 batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 19, 19, 256)  0           add_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_284 (Conv2D)             (None, 19, 19, 128)  32768       activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 19, 19, 128)  512         conv2d_284[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 19, 19, 128)  0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_186 (Lambda)             (None, 19, 19, 32)   0           activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_187 (Lambda)             (None, 19, 19, 32)   0           activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_188 (Lambda)             (None, 19, 19, 32)   0           activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_189 (Lambda)             (None, 19, 19, 32)   0           activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_285 (Conv2D)             (None, 19, 19, 32)   9248        lambda_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_286 (Conv2D)             (None, 19, 19, 32)   9248        lambda_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_287 (Conv2D)             (None, 19, 19, 32)   9248        lambda_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_288 (Conv2D)             (None, 19, 19, 32)   9248        lambda_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_49 (Concatenate)    (None, 19, 19, 128)  0           conv2d_285[0][0]                 \n",
      "                                                                 conv2d_286[0][0]                 \n",
      "                                                                 conv2d_287[0][0]                 \n",
      "                                                                 conv2d_288[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 19, 19, 128)  512         concatenate_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 19, 19, 128)  0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_289 (Conv2D)             (None, 19, 19, 256)  33024       activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 19, 19, 256)  1024        conv2d_289[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_44 (Add)                    (None, 19, 19, 256)  0           activation_136[0][0]             \n",
      "                                                                 batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 19, 19, 256)  0           add_44[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_4 (Glo (None, 256)          0           activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            514         global_average_pooling2d_4[0][0] \n",
      "==================================================================================================\n",
      "Total params: 441,250\n",
      "Trainable params: 434,914\n",
      "Non-trainable params: 6,336\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/1000\n",
      "10/10 [==============================] - 5s 547ms/step - loss: 1.2298 - accuracy: 0.5701 - val_loss: 6.5662 - val_accuracy: 0.5719\n",
      "Epoch 2/1000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.6743 - accuracy: 0.6168 - val_loss: 6.5662 - val_accuracy: 0.5719\n",
      "Epoch 3/1000\n",
      "10/10 [==============================] - 3s 272ms/step - loss: 0.6127 - accuracy: 0.6600 - val_loss: 6.5662 - val_accuracy: 0.5719\n",
      "Epoch 4/1000\n",
      "10/10 [==============================] - 3s 274ms/step - loss: 0.6999 - accuracy: 0.6557 - val_loss: 6.5662 - val_accuracy: 0.5719\n",
      "Epoch 5/1000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.6176 - accuracy: 0.6626 - val_loss: 6.5662 - val_accuracy: 0.5719\n",
      "Epoch 6/1000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.5706 - accuracy: 0.6635 - val_loss: 6.5662 - val_accuracy: 0.5719\n",
      "Epoch 7/1000\n",
      "10/10 [==============================] - 3s 299ms/step - loss: 0.5386 - accuracy: 0.7258 - val_loss: 6.5662 - val_accuracy: 0.5719\n",
      "Epoch 8/1000\n",
      "10/10 [==============================] - 3s 314ms/step - loss: 0.5230 - accuracy: 0.7379 - val_loss: 6.5662 - val_accuracy: 0.5719\n",
      "Epoch 9/1000\n",
      "10/10 [==============================] - 3s 279ms/step - loss: 0.5705 - accuracy: 0.6998 - val_loss: 6.5662 - val_accuracy: 0.5719\n",
      "Epoch 10/1000\n",
      "10/10 [==============================] - 3s 318ms/step - loss: 0.4561 - accuracy: 0.7924 - val_loss: 6.5662 - val_accuracy: 0.5719\n",
      "Epoch 11/1000\n",
      "10/10 [==============================] - 3s 331ms/step - loss: 0.4801 - accuracy: 0.7595 - val_loss: 5.3357 - val_accuracy: 0.5719\n",
      "Epoch 12/1000\n",
      "10/10 [==============================] - 3s 273ms/step - loss: 0.4427 - accuracy: 0.7924 - val_loss: 6.5662 - val_accuracy: 0.5719\n",
      "Epoch 13/1000\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.4206 - accuracy: 0.8141 - val_loss: 6.5662 - val_accuracy: 0.5719\n",
      "Epoch 14/1000\n",
      "10/10 [==============================] - 3s 272ms/step - loss: 0.4123 - accuracy: 0.8227 - val_loss: 6.5076 - val_accuracy: 0.5719\n",
      "Epoch 15/1000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.4020 - accuracy: 0.8086 - val_loss: 4.1613 - val_accuracy: 0.5719\n",
      "Epoch 16/1000\n",
      "10/10 [==============================] - 4s 413ms/step - loss: 0.4312 - accuracy: 0.7855 - val_loss: 2.0722 - val_accuracy: 0.7156\n",
      "Epoch 17/1000\n",
      "10/10 [==============================] - 3s 278ms/step - loss: 0.3669 - accuracy: 0.8382 - val_loss: 3.0760 - val_accuracy: 0.7031\n",
      "Epoch 18/1000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.3959 - accuracy: 0.8261 - val_loss: 5.9545 - val_accuracy: 0.5594\n",
      "Epoch 19/1000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.3442 - accuracy: 0.8469 - val_loss: 6.0304 - val_accuracy: 0.5562\n",
      "Epoch 20/1000\n",
      "10/10 [==============================] - 3s 261ms/step - loss: 0.3572 - accuracy: 0.8434 - val_loss: 4.1497 - val_accuracy: 0.6219\n",
      "Epoch 21/1000\n",
      "10/10 [==============================] - 3s 293ms/step - loss: 0.3789 - accuracy: 0.8279 - val_loss: 6.3794 - val_accuracy: 0.5594\n",
      "Epoch 22/1000\n",
      "10/10 [==============================] - 3s 271ms/step - loss: 0.3574 - accuracy: 0.8512 - val_loss: 4.8693 - val_accuracy: 0.5938\n",
      "Epoch 23/1000\n",
      "10/10 [==============================] - 3s 272ms/step - loss: 0.3725 - accuracy: 0.8330 - val_loss: 5.6005 - val_accuracy: 0.5188\n",
      "Epoch 24/1000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.3531 - accuracy: 0.8453 - val_loss: 4.6592 - val_accuracy: 0.6219\n",
      "Epoch 25/1000\n",
      "10/10 [==============================] - 3s 271ms/step - loss: 0.3454 - accuracy: 0.8478 - val_loss: 5.6041 - val_accuracy: 0.5469\n",
      "Epoch 26/1000\n",
      "10/10 [==============================] - 4s 354ms/step - loss: 0.3424 - accuracy: 0.8478 - val_loss: 4.9771 - val_accuracy: 0.6406\n",
      "Epoch 27/1000\n",
      "10/10 [==============================] - 3s 300ms/step - loss: 0.3064 - accuracy: 0.8642 - val_loss: 2.6486 - val_accuracy: 0.7000\n",
      "Epoch 28/1000\n",
      "10/10 [==============================] - 3s 300ms/step - loss: 0.2889 - accuracy: 0.8676 - val_loss: 4.9636 - val_accuracy: 0.6469\n",
      "Epoch 29/1000\n",
      "10/10 [==============================] - 3s 346ms/step - loss: 0.3183 - accuracy: 0.8547 - val_loss: 1.8685 - val_accuracy: 0.7625\n",
      "Epoch 30/1000\n",
      "10/10 [==============================] - 3s 273ms/step - loss: 0.2613 - accuracy: 0.8901 - val_loss: 6.2461 - val_accuracy: 0.5750\n",
      "Epoch 31/1000\n",
      "10/10 [==============================] - 3s 272ms/step - loss: 0.4036 - accuracy: 0.8469 - val_loss: 6.4210 - val_accuracy: 0.5562\n",
      "Epoch 32/1000\n",
      "10/10 [==============================] - 3s 258ms/step - loss: 0.2917 - accuracy: 0.8720 - val_loss: 7.0251 - val_accuracy: 0.5312\n",
      "Epoch 33/1000\n",
      "10/10 [==============================] - 3s 270ms/step - loss: 0.3335 - accuracy: 0.8529 - val_loss: 4.9546 - val_accuracy: 0.5938\n",
      "Epoch 34/1000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.2563 - accuracy: 0.8832 - val_loss: 4.5454 - val_accuracy: 0.6094\n",
      "Epoch 35/1000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.2616 - accuracy: 0.8922 - val_loss: 1.9787 - val_accuracy: 0.7188\n",
      "Epoch 36/1000\n",
      "10/10 [==============================] - 4s 419ms/step - loss: 0.2870 - accuracy: 0.8763 - val_loss: 1.0289 - val_accuracy: 0.7906\n",
      "Epoch 37/1000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.3221 - accuracy: 0.8702 - val_loss: 0.3638 - val_accuracy: 0.8562\n",
      "Epoch 38/1000\n",
      "10/10 [==============================] - 3s 343ms/step - loss: 0.2800 - accuracy: 0.8702 - val_loss: 0.3459 - val_accuracy: 0.8719\n",
      "Epoch 39/1000\n",
      "10/10 [==============================] - 3s 272ms/step - loss: 0.2664 - accuracy: 0.8789 - val_loss: 0.3965 - val_accuracy: 0.8406\n",
      "Epoch 40/1000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.2311 - accuracy: 0.9014 - val_loss: 0.4536 - val_accuracy: 0.8562\n",
      "Epoch 41/1000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.2891 - accuracy: 0.8625 - val_loss: 0.2864 - val_accuracy: 0.8938\n",
      "Epoch 42/1000\n",
      "10/10 [==============================] - 3s 271ms/step - loss: 0.3363 - accuracy: 0.8521 - val_loss: 0.6715 - val_accuracy: 0.7656\n",
      "Epoch 43/1000\n",
      "10/10 [==============================] - 3s 298ms/step - loss: 0.2515 - accuracy: 0.8720 - val_loss: 0.7226 - val_accuracy: 0.7906\n",
      "Epoch 44/1000\n",
      "10/10 [==============================] - 3s 297ms/step - loss: 0.2639 - accuracy: 0.8832 - val_loss: 1.5807 - val_accuracy: 0.7063\n",
      "Epoch 45/1000\n",
      "10/10 [==============================] - 3s 336ms/step - loss: 0.2622 - accuracy: 0.8832 - val_loss: 3.8807 - val_accuracy: 0.6531\n",
      "Epoch 46/1000\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 0.2458 - accuracy: 0.8884 - val_loss: 5.3603 - val_accuracy: 0.5719\n",
      "Epoch 47/1000\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.2525 - accuracy: 0.8867 - val_loss: 1.3666 - val_accuracy: 0.7969\n",
      "Epoch 48/1000\n",
      "10/10 [==============================] - 3s 270ms/step - loss: 0.2639 - accuracy: 0.8746 - val_loss: 0.9452 - val_accuracy: 0.7844\n",
      "Epoch 49/1000\n",
      "10/10 [==============================] - 3s 281ms/step - loss: 0.2407 - accuracy: 0.8962 - val_loss: 0.8794 - val_accuracy: 0.7812\n",
      "Epoch 50/1000\n",
      "10/10 [==============================] - 3s 276ms/step - loss: 0.2384 - accuracy: 0.8979 - val_loss: 0.5033 - val_accuracy: 0.8375\n",
      "Epoch 51/1000\n",
      "10/10 [==============================] - 3s 271ms/step - loss: 0.2330 - accuracy: 0.9040 - val_loss: 0.7741 - val_accuracy: 0.7812\n",
      "Epoch 52/1000\n",
      "10/10 [==============================] - 3s 260ms/step - loss: 0.2269 - accuracy: 0.9014 - val_loss: 3.6309 - val_accuracy: 0.5688\n",
      "Epoch 53/1000\n",
      "10/10 [==============================] - 3s 280ms/step - loss: 0.2851 - accuracy: 0.8772 - val_loss: 0.8580 - val_accuracy: 0.8031\n",
      "Epoch 54/1000\n",
      "10/10 [==============================] - 3s 271ms/step - loss: 0.3833 - accuracy: 0.8244 - val_loss: 0.3201 - val_accuracy: 0.8562\n",
      "Epoch 55/1000\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 0.2481 - accuracy: 0.8979 - val_loss: 0.2637 - val_accuracy: 0.8781\n",
      "Epoch 56/1000\n",
      "10/10 [==============================] - 4s 386ms/step - loss: 0.2289 - accuracy: 0.9066 - val_loss: 0.2468 - val_accuracy: 0.8906\n",
      "Epoch 57/1000\n",
      "10/10 [==============================] - 3s 291ms/step - loss: 0.2197 - accuracy: 0.9005 - val_loss: 0.4429 - val_accuracy: 0.7625\n",
      "Epoch 58/1000\n",
      "10/10 [==============================] - 3s 262ms/step - loss: 0.2245 - accuracy: 0.9031 - val_loss: 0.8073 - val_accuracy: 0.6812\n",
      "Epoch 59/1000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.2842 - accuracy: 0.8867 - val_loss: 0.2272 - val_accuracy: 0.9250\n",
      "Epoch 60/1000\n",
      "10/10 [==============================] - 3s 283ms/step - loss: 0.2322 - accuracy: 0.9000 - val_loss: 0.2369 - val_accuracy: 0.8969\n",
      "Epoch 61/1000\n",
      "10/10 [==============================] - 3s 276ms/step - loss: 0.2183 - accuracy: 0.8997 - val_loss: 0.2822 - val_accuracy: 0.8562\n",
      "Epoch 62/1000\n",
      "10/10 [==============================] - 3s 281ms/step - loss: 0.2981 - accuracy: 0.8919 - val_loss: 0.5375 - val_accuracy: 0.7969\n",
      "Epoch 63/1000\n",
      "10/10 [==============================] - 3s 299ms/step - loss: 0.2579 - accuracy: 0.8832 - val_loss: 1.8370 - val_accuracy: 0.7312\n",
      "Epoch 64/1000\n",
      "10/10 [==============================] - 3s 273ms/step - loss: 0.2243 - accuracy: 0.9048 - val_loss: 0.6301 - val_accuracy: 0.8281\n",
      "Epoch 65/1000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.2084 - accuracy: 0.9204 - val_loss: 1.4442 - val_accuracy: 0.6031\n",
      "Epoch 66/1000\n",
      "10/10 [==============================] - 4s 388ms/step - loss: 0.2264 - accuracy: 0.9047 - val_loss: 0.3311 - val_accuracy: 0.8594\n",
      "Epoch 67/1000\n",
      "10/10 [==============================] - 3s 272ms/step - loss: 0.2443 - accuracy: 0.8988 - val_loss: 0.4350 - val_accuracy: 0.7625\n",
      "Epoch 68/1000\n",
      "10/10 [==============================] - 3s 265ms/step - loss: 0.2104 - accuracy: 0.9152 - val_loss: 2.1154 - val_accuracy: 0.5813\n",
      "Epoch 69/1000\n",
      "10/10 [==============================] - 3s 273ms/step - loss: 0.2509 - accuracy: 0.8927 - val_loss: 0.5044 - val_accuracy: 0.7625\n",
      "Epoch 70/1000\n",
      "10/10 [==============================] - 3s 265ms/step - loss: 0.1988 - accuracy: 0.9152 - val_loss: 1.7002 - val_accuracy: 0.4656\n",
      "Epoch 71/1000\n",
      "10/10 [==============================] - 3s 272ms/step - loss: 0.2838 - accuracy: 0.8702 - val_loss: 0.2900 - val_accuracy: 0.8844\n",
      "Epoch 72/1000\n",
      "10/10 [==============================] - 3s 334ms/step - loss: 0.2231 - accuracy: 0.9057 - val_loss: 0.2174 - val_accuracy: 0.9187\n",
      "Epoch 73/1000\n",
      "10/10 [==============================] - 3s 272ms/step - loss: 0.1974 - accuracy: 0.9239 - val_loss: 0.4480 - val_accuracy: 0.8625\n",
      "Epoch 74/1000\n",
      "10/10 [==============================] - 3s 272ms/step - loss: 0.2189 - accuracy: 0.9083 - val_loss: 0.2816 - val_accuracy: 0.8938\n",
      "Epoch 75/1000\n",
      "10/10 [==============================] - 3s 301ms/step - loss: 0.2142 - accuracy: 0.9048 - val_loss: 3.1555 - val_accuracy: 0.5625\n",
      "Epoch 76/1000\n",
      "10/10 [==============================] - 4s 379ms/step - loss: 0.2031 - accuracy: 0.9144 - val_loss: 0.3817 - val_accuracy: 0.8844\n",
      "Epoch 77/1000\n",
      "10/10 [==============================] - 3s 276ms/step - loss: 0.2211 - accuracy: 0.9048 - val_loss: 0.5148 - val_accuracy: 0.8687\n",
      "Epoch 78/1000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.2526 - accuracy: 0.8927 - val_loss: 0.5165 - val_accuracy: 0.8313\n",
      "Epoch 79/1000\n",
      "10/10 [==============================] - 3s 302ms/step - loss: 0.2302 - accuracy: 0.8971 - val_loss: 0.2899 - val_accuracy: 0.8906\n",
      "Epoch 80/1000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.1973 - accuracy: 0.9196 - val_loss: 0.3216 - val_accuracy: 0.9031\n",
      "Epoch 81/1000\n",
      "10/10 [==============================] - 3s 278ms/step - loss: 0.2167 - accuracy: 0.9040 - val_loss: 0.4628 - val_accuracy: 0.8531\n",
      "Epoch 82/1000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.2018 - accuracy: 0.9086 - val_loss: 1.1158 - val_accuracy: 0.7656\n",
      "Epoch 83/1000\n",
      "10/10 [==============================] - 3s 271ms/step - loss: 0.2392 - accuracy: 0.9040 - val_loss: 1.6590 - val_accuracy: 0.7781\n",
      "Epoch 84/1000\n",
      "10/10 [==============================] - 3s 272ms/step - loss: 0.2146 - accuracy: 0.9135 - val_loss: 0.4947 - val_accuracy: 0.8562\n",
      "Epoch 85/1000\n",
      "10/10 [==============================] - 3s 349ms/step - loss: 0.2026 - accuracy: 0.9170 - val_loss: 4.2710 - val_accuracy: 0.5562\n",
      "Epoch 86/1000\n",
      "10/10 [==============================] - 3s 345ms/step - loss: 0.1938 - accuracy: 0.9213 - val_loss: 1.4808 - val_accuracy: 0.7781\n",
      "Epoch 87/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1849 - accuracy: 0.9258\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.1849 - accuracy: 0.9258 - val_loss: 0.7272 - val_accuracy: 0.8531\n",
      "Epoch 88/1000\n",
      "10/10 [==============================] - 3s 283ms/step - loss: 0.1759 - accuracy: 0.9308 - val_loss: 0.4828 - val_accuracy: 0.8719\n",
      "Epoch 89/1000\n",
      "10/10 [==============================] - 3s 272ms/step - loss: 0.1761 - accuracy: 0.9282 - val_loss: 0.2748 - val_accuracy: 0.9219\n",
      "Epoch 90/1000\n",
      "10/10 [==============================] - 3s 272ms/step - loss: 0.1823 - accuracy: 0.9230 - val_loss: 0.2495 - val_accuracy: 0.9250\n",
      "Epoch 91/1000\n",
      "10/10 [==============================] - 3s 292ms/step - loss: 0.1773 - accuracy: 0.9334 - val_loss: 0.2614 - val_accuracy: 0.9250\n",
      "Epoch 92/1000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.1703 - accuracy: 0.9317 - val_loss: 0.2145 - val_accuracy: 0.9344\n",
      "Epoch 93/1000\n",
      "10/10 [==============================] - 3s 319ms/step - loss: 0.1709 - accuracy: 0.9414 - val_loss: 0.2018 - val_accuracy: 0.9344\n",
      "Epoch 94/1000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.1759 - accuracy: 0.9273 - val_loss: 0.2245 - val_accuracy: 0.8938\n",
      "Epoch 95/1000\n",
      "10/10 [==============================] - 3s 299ms/step - loss: 0.1881 - accuracy: 0.9221 - val_loss: 0.2123 - val_accuracy: 0.9125\n",
      "Epoch 96/1000\n",
      "10/10 [==============================] - 4s 402ms/step - loss: 0.1675 - accuracy: 0.9343 - val_loss: 0.1998 - val_accuracy: 0.9250\n",
      "Epoch 97/1000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.1663 - accuracy: 0.9334 - val_loss: 0.2463 - val_accuracy: 0.9031\n",
      "Epoch 98/1000\n",
      "10/10 [==============================] - 3s 266ms/step - loss: 0.1583 - accuracy: 0.9377 - val_loss: 0.2119 - val_accuracy: 0.9094\n",
      "Epoch 99/1000\n",
      "10/10 [==============================] - 3s 274ms/step - loss: 0.1637 - accuracy: 0.9360 - val_loss: 0.2190 - val_accuracy: 0.9125\n",
      "Epoch 100/1000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.1844 - accuracy: 0.9196 - val_loss: 0.2133 - val_accuracy: 0.9344\n",
      "Epoch 101/1000\n",
      "10/10 [==============================] - 3s 271ms/step - loss: 0.1630 - accuracy: 0.9386 - val_loss: 0.2743 - val_accuracy: 0.8844\n",
      "Epoch 102/1000\n",
      "10/10 [==============================] - 3s 271ms/step - loss: 0.1715 - accuracy: 0.9291 - val_loss: 0.2425 - val_accuracy: 0.9000\n",
      "Epoch 103/1000\n",
      "10/10 [==============================] - 3s 296ms/step - loss: 0.1728 - accuracy: 0.9282 - val_loss: 0.2256 - val_accuracy: 0.9156\n",
      "Epoch 104/1000\n",
      "10/10 [==============================] - 4s 362ms/step - loss: 0.1785 - accuracy: 0.9265 - val_loss: 0.2207 - val_accuracy: 0.9250\n",
      "Epoch 105/1000\n",
      "10/10 [==============================] - 3s 275ms/step - loss: 0.1656 - accuracy: 0.9394 - val_loss: 0.2404 - val_accuracy: 0.8969\n",
      "Epoch 106/1000\n",
      "10/10 [==============================] - 3s 341ms/step - loss: 0.1610 - accuracy: 0.9455 - val_loss: 0.3277 - val_accuracy: 0.8344\n",
      "Epoch 107/1000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.1726 - accuracy: 0.9239 - val_loss: 0.2395 - val_accuracy: 0.9187\n",
      "Epoch 108/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1842 - accuracy: 0.9256\n",
      "Epoch 00108: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "10/10 [==============================] - 3s 270ms/step - loss: 0.1842 - accuracy: 0.9256 - val_loss: 0.2238 - val_accuracy: 0.9250\n",
      "Epoch 109/1000\n",
      "10/10 [==============================] - 3s 270ms/step - loss: 0.1642 - accuracy: 0.9334 - val_loss: 0.2131 - val_accuracy: 0.9281\n",
      "Epoch 110/1000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 0.1620 - accuracy: 0.9420 - val_loss: 0.2146 - val_accuracy: 0.9281\n",
      "Epoch 111/1000\n",
      "10/10 [==============================] - 3s 270ms/step - loss: 0.1597 - accuracy: 0.9334 - val_loss: 0.2238 - val_accuracy: 0.9219\n",
      "Epoch 112/1000\n",
      "10/10 [==============================] - 3s 272ms/step - loss: 0.1573 - accuracy: 0.9412 - val_loss: 0.2142 - val_accuracy: 0.9219\n",
      "Epoch 113/1000\n",
      "10/10 [==============================] - 3s 276ms/step - loss: 0.1627 - accuracy: 0.9394 - val_loss: 0.2174 - val_accuracy: 0.9219\n",
      "Epoch 114/1000\n",
      "10/10 [==============================] - 4s 397ms/step - loss: 0.1587 - accuracy: 0.9412 - val_loss: 0.2084 - val_accuracy: 0.9312\n",
      "Epoch 115/1000\n",
      "10/10 [==============================] - 3s 276ms/step - loss: 0.1683 - accuracy: 0.9369 - val_loss: 0.2059 - val_accuracy: 0.9281\n",
      "Epoch 116/1000\n",
      "10/10 [==============================] - 4s 383ms/step - loss: 0.1483 - accuracy: 0.9438 - val_loss: 0.2103 - val_accuracy: 0.9281\n",
      "Epoch 117/1000\n",
      "10/10 [==============================] - 3s 276ms/step - loss: 0.1729 - accuracy: 0.9343 - val_loss: 0.2193 - val_accuracy: 0.9250\n",
      "Epoch 118/1000\n",
      "10/10 [==============================] - 3s 262ms/step - loss: 0.1585 - accuracy: 0.9317 - val_loss: 0.2306 - val_accuracy: 0.9219\n",
      "Epoch 119/1000\n",
      "10/10 [==============================] - 3s 260ms/step - loss: 0.1469 - accuracy: 0.9438 - val_loss: 0.2236 - val_accuracy: 0.9281\n",
      "Epoch 120/1000\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.1633 - accuracy: 0.9282 - val_loss: 0.2116 - val_accuracy: 0.9250\n",
      "Epoch 121/1000\n",
      "10/10 [==============================] - 3s 271ms/step - loss: 0.1564 - accuracy: 0.9386 - val_loss: 0.2082 - val_accuracy: 0.9406\n",
      "Epoch 122/1000\n",
      "10/10 [==============================] - 3s 272ms/step - loss: 0.1629 - accuracy: 0.9308 - val_loss: 0.2049 - val_accuracy: 0.9438\n",
      "Epoch 123/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1519 - accuracy: 0.9386\n",
      "Epoch 00123: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "10/10 [==============================] - 3s 338ms/step - loss: 0.1519 - accuracy: 0.9386 - val_loss: 0.2068 - val_accuracy: 0.9375\n",
      "Epoch 124/1000\n",
      "10/10 [==============================] - 3s 273ms/step - loss: 0.1453 - accuracy: 0.9412 - val_loss: 0.2055 - val_accuracy: 0.9406\n",
      "Epoch 125/1000\n",
      "10/10 [==============================] - 3s 296ms/step - loss: 0.1569 - accuracy: 0.9360 - val_loss: 0.2032 - val_accuracy: 0.9375\n",
      "Epoch 126/1000\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.1421 - accuracy: 0.9472 - val_loss: 0.2059 - val_accuracy: 0.9375\n",
      "Epoch 127/1000\n",
      "10/10 [==============================] - 3s 302ms/step - loss: 0.1423 - accuracy: 0.9455 - val_loss: 0.2081 - val_accuracy: 0.9375\n",
      "Epoch 128/1000\n",
      "10/10 [==============================] - 3s 270ms/step - loss: 0.1523 - accuracy: 0.9438 - val_loss: 0.2086 - val_accuracy: 0.9406\n",
      "Epoch 129/1000\n",
      "10/10 [==============================] - 3s 260ms/step - loss: 0.1605 - accuracy: 0.9369 - val_loss: 0.2077 - val_accuracy: 0.9406\n",
      "Epoch 130/1000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.1509 - accuracy: 0.9446 - val_loss: 0.2061 - val_accuracy: 0.9375\n",
      "Epoch 131/1000\n",
      "10/10 [==============================] - 3s 271ms/step - loss: 0.1534 - accuracy: 0.9438 - val_loss: 0.2067 - val_accuracy: 0.9375\n",
      "Epoch 132/1000\n",
      "10/10 [==============================] - 3s 335ms/step - loss: 0.1547 - accuracy: 0.9394 - val_loss: 0.2083 - val_accuracy: 0.9344\n",
      "Epoch 133/1000\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 0.1353 - accuracy: 0.9533 - val_loss: 0.2060 - val_accuracy: 0.9375\n",
      "Epoch 134/1000\n",
      "10/10 [==============================] - 3s 277ms/step - loss: 0.1441 - accuracy: 0.9420 - val_loss: 0.2050 - val_accuracy: 0.9375\n",
      "Epoch 135/1000\n",
      "10/10 [==============================] - 3s 260ms/step - loss: 0.1519 - accuracy: 0.9429 - val_loss: 0.2086 - val_accuracy: 0.9406\n",
      "Epoch 136/1000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.1460 - accuracy: 0.9507 - val_loss: 0.2088 - val_accuracy: 0.9469\n",
      "Epoch 137/1000\n",
      "10/10 [==============================] - 3s 317ms/step - loss: 0.1562 - accuracy: 0.9403 - val_loss: 0.2135 - val_accuracy: 0.9312\n",
      "Epoch 138/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1540 - accuracy: 0.9438\n",
      "Epoch 00138: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "10/10 [==============================] - 3s 271ms/step - loss: 0.1540 - accuracy: 0.9438 - val_loss: 0.2115 - val_accuracy: 0.9375\n",
      "Epoch 139/1000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.1524 - accuracy: 0.9429 - val_loss: 0.2107 - val_accuracy: 0.9406\n",
      "Epoch 140/1000\n",
      "10/10 [==============================] - 3s 274ms/step - loss: 0.1600 - accuracy: 0.9282 - val_loss: 0.2094 - val_accuracy: 0.9406\n",
      "Epoch 141/1000\n",
      "10/10 [==============================] - 3s 271ms/step - loss: 0.1567 - accuracy: 0.9429 - val_loss: 0.2089 - val_accuracy: 0.9438\n",
      "Loss:\n",
      "Mean: 0.204180\n",
      "Std: 0.018398\n",
      "Min: 0.182235\n",
      "Max: 0.230176\n",
      "\n",
      "\n",
      "Acc:\n",
      "Mean: 0.917710\n",
      "Std: 0.009737\n",
      "Min: 0.900312\n",
      "Max: 0.928349\n",
      "\n",
      "\n",
      "ROC AUC:\n",
      "Mean: 0.975391\n",
      "Std: 0.004680\n",
      "Min: 0.968908\n",
      "Max: 0.981979\n",
      "\n",
      "\n",
      "mAP:\n",
      "Mean: 0.966893\n",
      "Std: 0.010962\n",
      "Min: 0.950293\n",
      "Max: 0.982835\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "def train(experiment_path, plot_results=False):\n",
    "    (kfold_data, X_test) = prepare_data_cv('./data/data/processed')\n",
    "    \n",
    "    models_proba = []\n",
    "    models_proba_train = []\n",
    "    models_acc = []\n",
    "    models_roc = []\n",
    "    models_logloss = []\n",
    "    models_map = []\n",
    "    \n",
    "    for idx, data in enumerate(kfold_data):\n",
    "        X_train, y_train, X_valid, y_valid = data\n",
    "        model = load_model(get_resnext, weights=None)\n",
    "        callbacks = get_model_callbacks(save_dir=os.path.join(experiment_path, 'fold_%02d' % idx))\n",
    "        data_generator = get_data_generator(X_train, y_train, batch_size=128)\n",
    "\n",
    "        model.fit_generator(\n",
    "            data_generator,\n",
    "            steps_per_epoch=10,\n",
    "            epochs=1000,\n",
    "            verbose=True,\n",
    "            validation_data=(X_valid, y_valid),\n",
    "            callbacks=callbacks,\n",
    "            shuffle=True)\n",
    "\n",
    "        model.load_weights(filepath=os.path.join(experiment_path, ('fold_%02d/model/model_weights.hdf5' % idx)))\n",
    "\n",
    "        _, acc_val = model.evaluate(X_valid, y_valid, verbose=False)\n",
    "        proba = model.predict(X_valid)\n",
    "        proba_test = model.predict(X_test)[:, 1]\n",
    "        \n",
    "        ## include the prediction for training\n",
    "        proba_train = model.predict(xtrain)[:, 1]\n",
    "        models_proba_train.append(proba_train)\n",
    "\n",
    "        models_proba.append(proba_test)\n",
    "        models_acc.append(acc_val)\n",
    "        models_roc.append(roc_auc_score(y_valid.argmax(axis=1), proba[:, 1]))\n",
    "        models_map.append(average_precision_score(y_valid.argmax(axis=1), proba[:, 1]))\n",
    "        models_logloss.append(logloss_softmax(y_valid, proba))\n",
    "\n",
    "        prepare_submission([proba_test], os.path.join(experiment_path, 'fold_%02d/prediction.csv' % idx))\n",
    "\n",
    "        if plot_results:\n",
    "            plots_path = os.path.join(experiment_path, 'fold_%02d/plots' % idx)\n",
    "            if not os.path.exists(plots_path):\n",
    "                os.makedirs(plots_path)\n",
    "\n",
    "            plot_precision_recall(proba[:, 1], y_valid.argmax(axis=1),\n",
    "                                  path=os.path.join(plots_path, 'recall_precision.jpg'))\n",
    "\n",
    "            plot_roc(proba[:, 1], y_valid.argmax(axis=1),\n",
    "                     path=os.path.join(plots_path, 'roc.jpg'))\n",
    "\n",
    "            plot_confusion_matrix(proba[:, 1], y_valid.argmax(axis=1),\n",
    "                                  path=os.path.join(plots_path, 'conf.jpg'))\n",
    "\n",
    "        print('Loss:\\nMean: %f\\nStd: %f\\nMin: %f\\nMax: %f\\n\\n' % (np.mean(models_logloss),\n",
    "                                                                  np.std(models_logloss),\n",
    "                                                                  np.min(models_logloss),\n",
    "                                                                  np.max(models_logloss)))\n",
    "\n",
    "        print('Acc:\\nMean: %f\\nStd: %f\\nMin: %f\\nMax: %f\\n\\n' % (np.mean(models_acc),\n",
    "                                                                  np.std(models_acc),\n",
    "                                                                  np.min(models_acc),\n",
    "                                                                  np.max(models_acc)))\n",
    "\n",
    "        print('ROC AUC:\\nMean: %f\\nStd: %f\\nMin: %f\\nMax: %f\\n\\n' % (np.mean(models_roc),\n",
    "                                                                     np.std(models_roc),\n",
    "                                                                     np.min(models_roc),\n",
    "                                                                     np.max(models_roc)))\n",
    "\n",
    "        print('mAP:\\nMean: %f\\nStd: %f\\nMin: %f\\nMax: %f\\n\\n' % (np.mean(models_map),\n",
    "                                                                 np.std(models_map),\n",
    "                                                                 np.min(models_map),\n",
    "                                                                 np.max(models_map)))\n",
    "\n",
    "    prepare_submission(models_proba, os.path.join(experiment_path, 'resnext.csv'))\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    xtrain, ytrain = prepare_data_full('./data/data/processed')\n",
    "    train(experiment_path='./', plot_results=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 2808.187693,
   "end_time": "2020-12-30T11:43:54.248035",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-12-30T10:57:06.060342",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
